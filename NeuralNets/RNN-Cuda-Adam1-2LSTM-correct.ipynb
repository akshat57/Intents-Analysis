{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import psutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/ubuntu/Intents-Analysis/Analysis')\n",
    "#sys.path.insert(1, '/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_vocab import load_data, get_vocab\n",
    "from get_frequency import get_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is True\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Needed Functions\n",
    "def load_data(filename):\n",
    "    a_file = open(filename, \"rb\")\n",
    "    output = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_vocabulary(train_file):\n",
    "    '''This function creates an indexed vocabulary dictionary from the training file'''\n",
    "    \n",
    "    vocab, _ = get_vocab(1, train_file)\n",
    "    \n",
    "    phone_to_idx = {'unk': 1}#Padding indx = 0, unkown_idx = 1, indexing starts from 2\n",
    "    for i, phone in enumerate(vocab):\n",
    "        phone_to_idx[phone] = i + 2\n",
    "        \n",
    "    return phone_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_file, intent_labels, phone_to_idx):\n",
    "        data = load_data(data_file)\n",
    "        self.all_data = []\n",
    "        \n",
    "        for intent in data:\n",
    "            for utterance in data[intent]:\n",
    "                utterance_to_idx = []\n",
    "                \n",
    "                for phone in utterance:\n",
    "                    if phone not in phone_to_idx:\n",
    "                        phone = 'unk'\n",
    "    \n",
    "                    utterance_to_idx.append(phone_to_idx[phone])\n",
    "                \n",
    "                self.all_data.append([utterance_to_idx, intent_labels[intent]])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        input_vector = self.all_data[index][0]\n",
    "        label = self.all_data[index][1]\n",
    "\n",
    "        return input_vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_indic(tuple_lst):\n",
    "\n",
    "    x_lst = [x[0] for x in tuple_lst]\n",
    "    y_lst = [x[1] for x in tuple_lst]\n",
    "\n",
    "    # collate x\n",
    "    B = len(tuple_lst)#Number of training samples\n",
    "    T = max(len(x) for x in x_lst)#Max length of a sentence\n",
    "\n",
    "    # x values\n",
    "    x = torch.zeros([B, T], dtype=torch.int64)\n",
    "    lengths = torch.zeros(B, dtype=torch.int64)\n",
    "\n",
    "    for i, x_np in enumerate(x_lst):\n",
    "        lengths[i] = len(x_np)\n",
    "        x[i,:len(x_np)] = torch.tensor(x_np)\n",
    "\n",
    "    # collate y\n",
    "    y = torch.zeros([B, 6])\n",
    "    for i, y_label in enumerate(y_lst):\n",
    "        y[i][y_label] = 1\n",
    "        \n",
    "    ids = torch.argsort(lengths, descending=True)\n",
    "\n",
    "    return x[ids], lengths[ids], y[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "#Defining constants and labels\n",
    "intent_labels = {'movie-tickets':0, 'auto-repair':1, 'restaurant-table':2, 'pizza-ordering':3, 'uber-lyft':4, 'coffee-ordering':5}\n",
    "train_language = 'hindi'\n",
    "test_language = 'hindi'\n",
    "\n",
    "#Loading data\n",
    "train_file = '/home/ubuntu/Intents-Analysis/TaskMasterData/Get_Phones_Combos/1_lang_train_split/taskmaster_training_' + train_language + '.pkl'\n",
    "test_file = '/home/ubuntu/Intents-Analysis/TaskMasterData/Get_Phones_Combos/1_language/taskmaster_testing_' + test_language + '.pkl'\n",
    "\n",
    "#create vocabulary and phone_to_idx\n",
    "phone_to_idx = create_vocabulary(train_file)\n",
    "print(len(phone_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_file, intent_labels, phone_to_idx)\n",
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=32)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args, collate_fn=collate_indic)\n",
    "\n",
    "test_dataset = MyDataset(test_file, intent_labels, phone_to_idx)\n",
    "test_loader_args = dict(shuffle=False, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "valid_loader = DataLoader(test_dataset, **test_loader_args, collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=63, embed_size=128, hidden_size=128, label_size=6):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "        #self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(embed_size*2)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_size*2, hidden_size, num_layers=2)\n",
    "        self.linear = nn.Linear(hidden_size, label_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "\n",
    "        # B,T,H\n",
    "        input = self.embed(x)\n",
    "\n",
    "        # (B,T,H) -> (B,H,T)\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input)], dim=1)\n",
    "\n",
    "        # (B,H,T)\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n",
    "\n",
    "        output, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        #output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        #output = torch.cat([hn[0], hn[1]], dim=1)\n",
    "        logits = self.linear(hn[-1])\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNClassifier(\n",
       "  (embed): Embedding(63, 128)\n",
       "  (cnn): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (cnn2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lstm): LSTM(256, 128, num_layers=2)\n",
       "  (linear): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNClassifier()\n",
    "opt = optim.Adam(model.parameters(), lr = 0.001)\n",
    "#opt = SGD(model.parameters(), lr=0.05)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hindi hindi\n",
      "train acc:  0.23343527013251783  train loss:  0.4788159132003784 --time: 3.8022496700286865\n",
      "validation:  0.16666666666666666 --max 0.16666666666666666 --time: 4.392596244812012\n",
      "train acc:  0.2419300033978933  train loss:  0.4404257743254952 --time: 3.293397903442383\n",
      "validation:  0.16666666666666666 --max 0.16666666666666666 --time: 3.7509098052978516\n",
      "train acc:  0.2585796805980292  train loss:  0.43909062509951385 --time: 2.7200698852539062\n",
      "validation:  0.21 --max 0.21 --time: 3.166597366333008\n",
      "train acc:  0.29561671763506625  train loss:  0.43451686916144 --time: 2.643951892852783\n",
      "validation:  0.21 --max 0.21 --time: 3.106300115585327\n",
      "train acc:  0.30513081889228677  train loss:  0.42854634445646533 --time: 2.8582305908203125\n",
      "validation:  0.22 --max 0.22 --time: 3.309086799621582\n",
      "train acc:  0.3122663948352022  train loss:  0.4243587423925814 --time: 2.6341984272003174\n",
      "validation:  0.20666666666666667 --max 0.22 --time: 3.0824127197265625\n",
      "train acc:  0.3306150186884132  train loss:  0.418780821820964 --time: 2.7492291927337646\n",
      "validation:  0.22 --max 0.22 --time: 3.049292802810669\n",
      "train acc:  0.33707101597009853  train loss:  0.4147512666557146 --time: 3.172564744949341\n",
      "validation:  0.25666666666666665 --max 0.25666666666666665 --time: 3.610832452774048\n",
      "train acc:  0.33775059463132856  train loss:  0.4118051982444266 --time: 3.0930185317993164\n",
      "validation:  0.24333333333333335 --max 0.25666666666666665 --time: 3.457247734069824\n",
      "train acc:  0.3506625891946993  train loss:  0.40814650188321655 --time: 3.1665964126586914\n",
      "validation:  0.2833333333333333 --max 0.2833333333333333 --time: 3.588385820388794\n",
      "train acc:  0.4091063540604825  train loss:  0.3854251776052558 --time: 3.7470574378967285\n",
      "validation:  0.32 --max 0.32 --time: 4.25852108001709\n",
      "train acc:  0.46041454298335033  train loss:  0.3645963254182235 --time: 3.987900495529175\n",
      "validation:  0.34 --max 0.34 --time: 4.524188756942749\n",
      "train acc:  0.46041454298335033  train loss:  0.36439530745796533 --time: 4.101788282394409\n",
      "validation:  0.3466666666666667 --max 0.3466666666666667 --time: 4.633510112762451\n",
      "train acc:  0.5158002038735984  train loss:  0.33008402715558594 --time: 4.057349681854248\n",
      "validation:  0.37333333333333335 --max 0.37333333333333335 --time: 4.494112730026245\n",
      "train acc:  0.563710499490316  train loss:  0.3099123705988345 --time: 3.907816171646118\n",
      "validation:  0.41 --max 0.41 --time: 4.499099254608154\n",
      "train acc:  0.5739041794087666  train loss:  0.30746269614800165 --time: 3.8991191387176514\n",
      "validation:  0.49333333333333335 --max 0.49333333333333335 --time: 4.46058201789856\n",
      "train acc:  0.6377845735643901  train loss:  0.276410153378611 --time: 3.6129939556121826\n",
      "validation:  0.4866666666666667 --max 0.49333333333333335 --time: 4.196683406829834\n",
      "train acc:  0.6306489976214746  train loss:  0.2747348683035892 --time: 3.712838649749756\n",
      "validation:  0.4866666666666667 --max 0.49333333333333335 --time: 4.303616762161255\n",
      "train acc:  0.6843357118586476  train loss:  0.2444090784891792 --time: 3.8045496940612793\n",
      "validation:  0.5466666666666666 --max 0.5466666666666666 --time: 4.451934814453125\n",
      "train acc:  0.6829765545361876  train loss:  0.23671248684758725 --time: 3.8903167247772217\n",
      "validation:  0.53 --max 0.5466666666666666 --time: 4.3835577964782715\n",
      "train acc:  0.7322460074753653  train loss:  0.20917040887086288 --time: 4.0427772998809814\n",
      "validation:  0.5666666666666667 --max 0.5666666666666667 --time: 4.5766377449035645\n",
      "train acc:  0.7580699966021067  train loss:  0.19180165166440216 --time: 4.005297660827637\n",
      "validation:  0.6033333333333334 --max 0.6033333333333334 --time: 4.534369468688965\n",
      "train acc:  0.782534828406388  train loss:  0.1760046520958776 --time: 4.049006462097168\n",
      "validation:  0.62 --max 0.62 --time: 4.513399124145508\n",
      "train acc:  0.7920489296636085  train loss:  0.17077449935933817 --time: 3.9171769618988037\n",
      "validation:  0.61 --max 0.62 --time: 4.472315788269043\n",
      "train acc:  0.8226299694189603  train loss:  0.14619138642497684 --time: 3.9020330905914307\n",
      "validation:  0.69 --max 0.69 --time: 4.4796624183654785\n",
      "train acc:  0.8511722731906218  train loss:  0.12715823689232703 --time: 3.840986967086792\n",
      "validation:  0.6533333333333333 --max 0.69 --time: 4.409881353378296\n",
      "train acc:  0.8416581719334013  train loss:  0.12906543716140415 --time: 3.715167284011841\n",
      "validation:  0.69 --max 0.69 --time: 4.295677185058594\n",
      "train acc:  0.853550798504927  train loss:  0.11589908211127571 --time: 3.520951509475708\n",
      "validation:  0.69 --max 0.69 --time: 4.080611705780029\n",
      "train acc:  0.871899422358138  train loss:  0.10614781211251798 --time: 3.508211612701416\n",
      "validation:  0.69 --max 0.69 --time: 4.114766597747803\n",
      "train acc:  0.8868501529051988  train loss:  0.09790706926065942 --time: 3.6446478366851807\n",
      "validation:  0.72 --max 0.72 --time: 4.208431720733643\n",
      "train acc:  0.8786952089704383  train loss:  0.10220902024403862 --time: 3.8597805500030518\n",
      "validation:  0.69 --max 0.72 --time: 4.465500116348267\n",
      "train acc:  0.8916072035338091  train loss:  0.09403147337877232 --time: 4.1258556842803955\n",
      "validation:  0.7366666666666667 --max 0.7366666666666667 --time: 4.65789008140564\n",
      "train acc:  0.8973836221542644  train loss:  0.08594167005756627 --time: 3.867997884750366\n",
      "validation:  0.7266666666666667 --max 0.7366666666666667 --time: 4.472020387649536\n",
      "train acc:  0.9126741420319402  train loss:  0.07750522766424262 --time: 4.08890962600708\n",
      "validation:  0.7766666666666666 --max 0.7766666666666666 --time: 4.599226236343384\n",
      "train acc:  0.9235474006116208  train loss:  0.07060322084504625 --time: 4.138925313949585\n",
      "validation:  0.7533333333333333 --max 0.7766666666666666 --time: 4.6050238609313965\n",
      "train acc:  0.928644240570846  train loss:  0.06451573222875595 --time: 4.3787219524383545\n",
      "validation:  0.7566666666666667 --max 0.7766666666666666 --time: 4.7252113819122314\n",
      "train acc:  0.9429153924566769  train loss:  0.05442093426118726 --time: 4.046372175216675\n",
      "validation:  0.7866666666666666 --max 0.7866666666666666 --time: 4.67573094367981\n",
      "train acc:  0.9507305470608223  train loss:  0.05024109796985336 --time: 3.669706106185913\n",
      "validation:  0.8266666666666667 --max 0.8266666666666667 --time: 4.226642847061157\n",
      "train acc:  0.9534488617057424  train loss:  0.04653665455787078 --time: 3.200833797454834\n",
      "validation:  0.81 --max 0.8266666666666667 --time: 3.832817792892456\n",
      "train acc:  0.9765545361875637  train loss:  0.031026740274999454 --time: 3.464826822280884\n",
      "validation:  0.8233333333333334 --max 0.8266666666666667 --time: 4.037482738494873\n",
      "train acc:  0.9751953788651037  train loss:  0.030773311367501385 --time: 3.487938165664673\n",
      "validation:  0.8066666666666666 --max 0.8266666666666667 --time: 4.116000652313232\n",
      "train acc:  0.9405368671423717  train loss:  0.060546759030093315 --time: 3.5720553398132324\n",
      "validation:  0.8266666666666667 --max 0.8266666666666667 --time: 4.070980787277222\n",
      "train acc:  0.962623173632348  train loss:  0.039526720855223095 --time: 4.187227725982666\n",
      "validation:  0.8166666666666667 --max 0.8266666666666667 --time: 4.5312278270721436\n",
      "train acc:  0.9700985389058784  train loss:  0.033480468772999615 --time: 4.338376760482788\n",
      "validation:  0.85 --max 0.85 --time: 4.847659111022949\n",
      "train acc:  0.9714576962283384  train loss:  0.0316140768725587 --time: 4.34626317024231\n",
      "validation:  0.8266666666666667 --max 0.85 --time: 4.849230766296387\n",
      "train acc:  0.9840299014610941  train loss:  0.020306268868886906 --time: 4.411538124084473\n",
      "validation:  0.8233333333333334 --max 0.85 --time: 4.797688961029053\n",
      "train acc:  0.9857288481141692  train loss:  0.018027515656760206 --time: 4.10307765007019\n",
      "validation:  0.8466666666666667 --max 0.85 --time: 4.724024534225464\n",
      "train acc:  0.9949031600407747  train loss:  0.011244297351526178 --time: 3.4469971656799316\n",
      "validation:  0.86 --max 0.86 --time: 4.04112696647644\n",
      "train acc:  0.9972816853550799  train loss:  0.009287491319296152 --time: 3.0761525630950928\n",
      "validation:  0.8466666666666667 --max 0.86 --time: 3.619399309158325\n",
      "train acc:  0.9955827387020048  train loss:  0.00834755635941806 --time: 3.442379951477051\n",
      "validation:  0.8633333333333333 --max 0.8633333333333333 --time: 3.987825632095337\n",
      "train acc:  0.9972816853550799  train loss:  0.006512475291105068 --time: 3.451981544494629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:  0.8533333333333334 --max 0.8633333333333333 --time: 3.953057289123535\n",
      "train acc:  0.9955827387020048  train loss:  0.008450887550640366 --time: 4.085147142410278\n",
      "validation:  0.85 --max 0.8633333333333333 --time: 4.5259788036346436\n",
      "train acc:  0.9986408426775399  train loss:  0.006293009247873788 --time: 4.4410974979400635\n",
      "validation:  0.8633333333333333 --max 0.8633333333333333 --time: 4.944213151931763\n",
      "train acc:  0.9972816853550799  train loss:  0.00698448248895938 --time: 4.368737697601318\n",
      "validation:  0.8366666666666667 --max 0.8633333333333333 --time: 4.913675308227539\n",
      "train acc:  0.9789330615018689  train loss:  0.02276368900809599 --time: 4.4129414558410645\n",
      "validation:  0.82 --max 0.8633333333333333 --time: 4.733643054962158\n",
      "train acc:  0.9836901121304791  train loss:  0.01903149358037373 --time: 4.093639373779297\n",
      "validation:  0.8533333333333334 --max 0.8633333333333333 --time: 4.707723379135132\n",
      "train acc:  0.9945633707101597  train loss:  0.00957376804486241 --time: 3.4820661544799805\n",
      "validation:  0.8566666666666667 --max 0.8633333333333333 --time: 4.031776189804077\n",
      "train acc:  0.9938837920489296  train loss:  0.010578014523438786 --time: 3.6331377029418945\n",
      "validation:  0.86 --max 0.8633333333333333 --time: 4.217180252075195\n",
      "train acc:  0.9955827387020048  train loss:  0.008374904150791142 --time: 3.2936503887176514\n",
      "validation:  0.8333333333333334 --max 0.8633333333333333 --time: 3.874617099761963\n",
      "train acc:  0.9887869520897044  train loss:  0.013876104383202999 --time: 3.7178213596343994\n",
      "validation:  0.86 --max 0.8633333333333333 --time: 4.2987964153289795\n",
      "train acc:  0.9976214746856948  train loss:  0.0065114912070819864 --time: 3.779142379760742\n",
      "validation:  0.8666666666666667 --max 0.8666666666666667 --time: 4.374906778335571\n",
      "train acc:  0.9942235813795447  train loss:  0.0077909571928498535 --time: 3.3214943408966064\n",
      "validation:  0.8766666666666667 --max 0.8766666666666667 --time: 3.621238946914673\n",
      "train acc:  0.9925246347264696  train loss:  0.009967016542087431 --time: 3.391167163848877\n",
      "validation:  0.8633333333333333 --max 0.8766666666666667 --time: 3.7406387329101562\n",
      "train acc:  0.9932042133876996  train loss:  0.010238234328268014 --time: 3.445958375930786\n",
      "validation:  0.8633333333333333 --max 0.8766666666666667 --time: 3.8012566566467285\n",
      "train acc:  0.9969418960244648  train loss:  0.005327406405147327 --time: 4.413720369338989\n",
      "validation:  0.8633333333333333 --max 0.8766666666666667 --time: 4.791590452194214\n",
      "train acc:  0.9870880054366293  train loss:  0.01714536508180849 --time: 4.522374391555786\n",
      "validation:  0.86 --max 0.8766666666666667 --time: 4.843350887298584\n",
      "train acc:  0.9904858987427795  train loss:  0.012751711421119779 --time: 3.2011141777038574\n",
      "validation:  0.8233333333333334 --max 0.8766666666666667 --time: 3.5142629146575928\n",
      "train acc:  0.9979612640163099  train loss:  0.0054750938130461654 --time: 2.8787970542907715\n",
      "validation:  0.8566666666666667 --max 0.8766666666666667 --time: 3.348924160003662\n",
      "train acc:  0.9983010533469249  train loss:  0.003990789268003858 --time: 2.7381644248962402\n",
      "validation:  0.8766666666666667 --max 0.8766666666666667 --time: 3.1907949447631836\n",
      "train acc:  0.9983010533469249  train loss:  0.003478790825718771 --time: 3.309685468673706\n",
      "validation:  0.8633333333333333 --max 0.8766666666666667 --time: 3.8642983436584473\n",
      "train acc:  0.9996602106693849  train loss:  0.0024316790159386787 --time: 3.2348053455352783\n",
      "validation:  0.8633333333333333 --max 0.8766666666666667 --time: 3.6450750827789307\n",
      "train acc:  0.9996602106693849  train loss:  0.0018817344427351718 --time: 2.644404649734497\n",
      "validation:  0.8633333333333333 --max 0.8766666666666667 --time: 3.0954627990722656\n",
      "train acc:  0.9996602106693849  train loss:  0.0016282604723844838 --time: 2.36275315284729\n",
      "validation:  0.8666666666666667 --max 0.8766666666666667 --time: 2.8507566452026367\n",
      "train acc:  0.9996602106693849  train loss:  0.0014227918379575663 --time: 2.660067081451416\n",
      "validation:  0.86 --max 0.8766666666666667 --time: 3.1301517486572266\n",
      "train acc:  0.9996602106693849  train loss:  0.0013282279833219945 --time: 2.9512815475463867\n",
      "validation:  0.8666666666666667 --max 0.8766666666666667 --time: 3.235801935195923\n",
      "train acc:  0.9996602106693849  train loss:  0.0011810128091146116 --time: 3.375185489654541\n",
      "validation:  0.8666666666666667 --max 0.8766666666666667 --time: 3.756683349609375\n",
      "train acc:  1.0  train loss:  0.001073065881981798 --time: 3.446316719055176\n",
      "validation:  0.8666666666666667 --max 0.8766666666666667 --time: 3.809812068939209\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5aab3af95490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(train_language, test_language)\n",
    "max_acc = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    #print(\"epoch \", i)\n",
    "    loss_accum = 0.0\n",
    "    batch_cnt = 0\n",
    "\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch, (x, lengths, y) in enumerate(train_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "        loss_score = loss.cpu().item()\n",
    "\n",
    "        loss_accum += loss_score\n",
    "        batch_cnt += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        target_val, tar_indices = torch.max(y, dim=1)\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    print(\"train acc: \", acc_cnt/(err_cnt+acc_cnt), \" train loss: \", loss_accum / batch_cnt, '--time:', time.time() - start_time)\n",
    "\n",
    "    model.eval()\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    #start_time = time.time()\n",
    "    for x, lengths, y in valid_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        target_val, tar_indices = torch.max(y, dim=1)\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    current_acc = acc_cnt/(err_cnt+acc_cnt)\n",
    "    if current_acc > max_acc:\n",
    "        max_acc = current_acc\n",
    "                \n",
    "    print(\"validation: \", current_acc, '--max', max_acc, '--time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
