{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import psutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/ubuntu/Intents/Intents-Analysis/Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_vocab import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is True\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/queues.py\", line 230, in _feed\n",
      "    close()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    }
   ],
   "source": [
    "#Defining constants and labels\n",
    "max_sent_len = {'english': 247, 'hindi': 265, 'gujarati': 283, 'bengali': 295, 'marathi': 307}\n",
    "intent_labels = {'movie-tickets':0, 'auto-repair':1, 'restaurant-table':2, 'pizza-ordering':3, 'uber-lyft':4, 'coffee-ordering':5}\n",
    "language = 'bengali'\n",
    "\n",
    "#Loading data\n",
    "train_file = '../Analysis/Labels/TaskMaster/taskmaster_training_' + language + '.pkl'\n",
    "test_file = '../Analysis/Labels/TaskMaster/taskmaster_testing_' + language + '.pkl'\n",
    "feature_file = '../Analysis/Labels/TaskMaster/panphon_features_' + language + '.pkl'\n",
    "\n",
    "train_data = load_data(train_file)\n",
    "test_data = load_data(test_file)\n",
    "feature_vectors = load_data(feature_file)\n",
    "\n",
    "\n",
    "#Add vector for padding, converting feature vectors to float tensors. \n",
    "size_of_feature_vector = 22\n",
    "feature_vectors['unk'] = np.zeros(size_of_feature_vector)\n",
    "for ipa in feature_vectors:\n",
    "    feature_vectors[ipa] = torch.from_numpy(feature_vectors[ipa]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_vector(utterance, feature_vectors, max_len):\n",
    "    '''\n",
    "    Pad sentence at the end with maximum length with 'unk' \n",
    "    '''\n",
    "    input_vector = feature_vectors[utterance[0]].reshape(-1,1)\n",
    "    for ipa in utterance[1:]:\n",
    "        input_vector = torch.cat((input_vector, feature_vectors[ipa].reshape(-1,1)), dim = 1)\n",
    "    \n",
    "    for i in range(max_len - len(utterance)):\n",
    "        input_vector = torch.cat((input_vector, feature_vectors['unk'].reshape(-1,1)), dim = 1)\n",
    "        \n",
    "    return input_vector\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, feature_vectors, intent_labels, max_len, train = True):\n",
    "        self.all_data = []\n",
    "        for intent in data:\n",
    "            for utterance in data[intent]:\n",
    "                input_vector = create_input_vector(utterance,feature_vectors, max_len)\n",
    "                self.all_data.append([input_vector, intent_labels[intent]])\n",
    "        \n",
    "        if train:\n",
    "            random.shuffle(self.all_data)\n",
    "\n",
    "        self.dim1 = self.all_data[0][0].shape[0]\n",
    "        self.dim2 = self.all_data[0][0].shape[1]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        \n",
    "        return self.all_data[index][0].reshape(1, self.dim1, self.dim2 ), self.all_data[index][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_data, feature_vectors, intent_labels, max_sent_len[language], train=True)\n",
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=32)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args)\n",
    "\n",
    "test_dataset = MyDataset(test_data, feature_vectors, intent_labels, max_sent_len[language], train=False)\n",
    "test_loader_args = dict(shuffle=False, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "test_loader = DataLoader(test_dataset, **test_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([128, 1, 22, 295])\n",
      "torch.Size([127, 1, 22, 295])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, (1,3)) # (22,245) \n",
    "        self.pool1 = nn.MaxPool2d( kernel_size = (1,3), stride = (1,2)) #(22, 122) \n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, (3,5)) # (20,118) \n",
    "        self.pool2 = nn.MaxPool2d( kernel_size = (1,2), stride = (1,2)) #(18, 59) \n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 32, (5,7)) # (16, 53)\n",
    "        self.pool3 = nn.MaxPool2d( kernel_size = (1,3), stride = (1,2)) #(16, 26)\n",
    "        self.conv3_bn = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 16 * 32, 512)\n",
    "        self.fc1_bn = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.fc2_bn = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 6)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = x.view(-1, 32 *16 * 32)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNN_Model(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 32, kernel_size=(5, 7), stride=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=16384, out_features=512, bias=True)\n",
      "  (fc1_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (fc2_bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=64, out_features=6, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyCNN_Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
    "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
    "        data = data.to(device)\n",
    "        target = target.to(device) # all data & model on same device\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += target.size(0)\n",
    "        correct_predictions += (predicted == target).sum().item()\n",
    "    \n",
    "            \n",
    "    end_time = time.time()\n",
    "    \n",
    "    acc = (correct_predictions/total_predictions)*100.0\n",
    "    running_loss /= len(train_loader)\n",
    "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')  \n",
    "    print('Training Accuracy: ', acc, '%')\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):   \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "        running_loss /= len(test_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('Testing Loss: ', running_loss)\n",
    "        print('Testing Accuracy: ', acc, '%')\n",
    "        return running_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Training Loss:  1.7534157711526621 Time:  5.5709123611450195 s\n",
      "Training Accuracy:  25.178389398572886 %\n",
      "Testing Loss:  1.9731375773747761\n",
      "Testing Accuracy:  21.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 1\n",
      "Training Loss:  1.6938334599785183 Time:  6.894856214523315 s\n",
      "Training Accuracy:  32.31396534148828 %\n",
      "Testing Loss:  1.9470420281092327\n",
      "Testing Accuracy:  25.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 2\n",
      "Training Loss:  1.6666537212288899 Time:  7.522845268249512 s\n",
      "Training Accuracy:  32.55181787291879 %\n",
      "Testing Loss:  1.9287957350413005\n",
      "Testing Accuracy:  26.333333333333332 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 3\n",
      "Training Loss:  1.652148407438527 Time:  5.543845176696777 s\n",
      "Training Accuracy:  34.08086986068638 %\n",
      "Testing Loss:  1.873987873395284\n",
      "Testing Accuracy:  31.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 4\n",
      "Training Loss:  1.5243639479512754 Time:  5.623064041137695 s\n",
      "Training Accuracy:  40.97859327217125 %\n",
      "Testing Loss:  1.589175780614217\n",
      "Testing Accuracy:  35.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 5\n",
      "Training Loss:  1.2003661912420522 Time:  5.6478049755096436 s\n",
      "Training Accuracy:  55.92932381923208 %\n",
      "Testing Loss:  1.3774099349975586\n",
      "Testing Accuracy:  52.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 6\n",
      "Training Loss:  0.9959454536437988 Time:  5.541264295578003 s\n",
      "Training Accuracy:  63.098878695208974 %\n",
      "Testing Loss:  1.2958351771036785\n",
      "Testing Accuracy:  54.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 7\n",
      "Training Loss:  0.9035645334616952 Time:  6.892726421356201 s\n",
      "Training Accuracy:  66.36085626911316 %\n",
      "Testing Loss:  1.3901776870091755\n",
      "Testing Accuracy:  53.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 8\n",
      "Training Loss:  0.8152587180552275 Time:  8.010737895965576 s\n",
      "Training Accuracy:  69.28304451240231 %\n",
      "Testing Loss:  1.0763280391693115\n",
      "Testing Accuracy:  63.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 9\n",
      "Training Loss:  0.7284191587696904 Time:  8.642921686172485 s\n",
      "Training Accuracy:  72.13727488956847 %\n",
      "Testing Loss:  0.9591499964396158\n",
      "Testing Accuracy:  66.66666666666666 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 10\n",
      "Training Loss:  0.6662282684574956 Time:  8.650883197784424 s\n",
      "Training Accuracy:  74.71967380224261 %\n",
      "Testing Loss:  1.0924916664759319\n",
      "Testing Accuracy:  64.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 11\n",
      "Training Loss:  0.6057790776957637 Time:  8.596306562423706 s\n",
      "Training Accuracy:  77.84573564390078 %\n",
      "Testing Loss:  1.0182071725527446\n",
      "Testing Accuracy:  65.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 12\n",
      "Training Loss:  0.5433184478593909 Time:  8.49845004081726 s\n",
      "Training Accuracy:  80.86986068637445 %\n",
      "Testing Loss:  0.9054076870282491\n",
      "Testing Accuracy:  68.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 13\n",
      "Training Loss:  0.4949631522531095 Time:  8.553727388381958 s\n",
      "Training Accuracy:  82.19503907577302 %\n",
      "Testing Loss:  0.9646355112393697\n",
      "Testing Accuracy:  67.66666666666666 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 14\n",
      "Training Loss:  0.4590768658596536 Time:  8.591272830963135 s\n",
      "Training Accuracy:  83.14644920149507 %\n",
      "Testing Loss:  0.926199754079183\n",
      "Testing Accuracy:  68.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 15\n",
      "Training Loss:  0.4043674261673637 Time:  8.59947395324707 s\n",
      "Training Accuracy:  85.76282704723072 %\n",
      "Testing Loss:  0.8816754619280497\n",
      "Testing Accuracy:  69.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 16\n",
      "Training Loss:  0.3480467303939488 Time:  8.7129065990448 s\n",
      "Training Accuracy:  87.2579001019368 %\n",
      "Testing Loss:  1.1220935980478923\n",
      "Testing Accuracy:  67.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 17\n",
      "Training Loss:  0.30395169685716217 Time:  8.658963918685913 s\n",
      "Training Accuracy:  89.39857288481141 %\n",
      "Testing Loss:  0.8330310980478922\n",
      "Testing Accuracy:  73.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 18\n",
      "Training Loss:  0.25648654738198157 Time:  8.551189661026001 s\n",
      "Training Accuracy:  91.30139313625553 %\n",
      "Testing Loss:  0.90678271651268\n",
      "Testing Accuracy:  71.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 19\n",
      "Training Loss:  0.24169971437557883 Time:  8.588265657424927 s\n",
      "Training Accuracy:  91.60720353380903 %\n",
      "Testing Loss:  1.069007972876231\n",
      "Testing Accuracy:  71.33333333333334 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 20\n",
      "Training Loss:  0.18505994748810065 Time:  8.650585174560547 s\n",
      "Training Accuracy:  93.95174991505266 %\n",
      "Testing Loss:  1.0901352167129517\n",
      "Testing Accuracy:  72.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 21\n",
      "Training Loss:  0.1492857405025026 Time:  8.636271953582764 s\n",
      "Training Accuracy:  94.97111790689773 %\n",
      "Testing Loss:  1.0968037247657776\n",
      "Testing Accuracy:  73.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 22\n",
      "Training Loss:  0.12596910706032877 Time:  8.82025146484375 s\n",
      "Training Accuracy:  96.05844376486579 %\n",
      "Testing Loss:  0.9528437852859497\n",
      "Testing Accuracy:  71.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 23\n",
      "Training Loss:  0.1184320219832918 Time:  8.947815179824829 s\n",
      "Training Accuracy:  96.16038056405029 %\n",
      "Testing Loss:  1.051725169022878\n",
      "Testing Accuracy:  72.33333333333334 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 24\n",
      "Training Loss:  0.08063283449281818 Time:  9.094950914382935 s\n",
      "Training Accuracy:  98.06320081549438 %\n",
      "Testing Loss:  1.2586535612742107\n",
      "Testing Accuracy:  72.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 25\n",
      "Training Loss:  0.06411850735869097 Time:  8.930210828781128 s\n",
      "Training Accuracy:  98.23309548080191 %\n",
      "Testing Loss:  1.0406725406646729\n",
      "Testing Accuracy:  71.33333333333334 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 26\n",
      "Training Loss:  0.07949998990997025 Time:  8.823362112045288 s\n",
      "Training Accuracy:  97.38362215426436 %\n",
      "Testing Loss:  1.3461923201878865\n",
      "Testing Accuracy:  71.33333333333334 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 27\n",
      "Training Loss:  0.07456697782744533 Time:  8.841639995574951 s\n",
      "Training Accuracy:  97.79136935100237 %\n",
      "Testing Loss:  1.5544658501942952\n",
      "Testing Accuracy:  71.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 28\n",
      "Training Loss:  0.04018381229885246 Time:  8.961478233337402 s\n",
      "Training Accuracy:  99.08256880733946 %\n",
      "Testing Loss:  1.6364941199620564\n",
      "Testing Accuracy:  71.33333333333334 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 29\n",
      "Training Loss:  0.02416306430392939 Time:  8.749151468276978 s\n",
      "Training Accuracy:  99.62623173632348 %\n",
      "Testing Loss:  1.7630971670150757\n",
      "Testing Accuracy:  73.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 30\n",
      "Training Loss:  0.013863124985895727 Time:  8.755582571029663 s\n",
      "Training Accuracy:  99.89806320081549 %\n",
      "Testing Loss:  1.5681285858154297\n",
      "Testing Accuracy:  73.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 31\n",
      "Training Loss:  0.010766098468119035 Time:  8.784730672836304 s\n",
      "Training Accuracy:  99.89806320081549 %\n",
      "Testing Loss:  1.6547092199325562\n",
      "Testing Accuracy:  73.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 32\n",
      "Training Loss:  0.006959751056021322 Time:  8.683408975601196 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  1.6921669244766235\n",
      "Testing Accuracy:  73.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 33\n",
      "Training Loss:  0.005153636731531309 Time:  8.663771390914917 s\n",
      "Training Accuracy:  99.9660210669385 %\n",
      "Testing Loss:  1.7634044488271077\n",
      "Testing Accuracy:  73.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 34\n",
      "Training Loss:  0.003721226634376723 Time:  8.562979936599731 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  1.91464630762736\n",
      "Testing Accuracy:  73.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 35\n",
      "Training Loss:  0.003189762031821453 Time:  8.536429166793823 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  1.9867723385492961\n",
      "Testing Accuracy:  73.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 36\n",
      "Training Loss:  0.0024742941731465576 Time:  8.512348175048828 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  1.8880237738291423\n",
      "Testing Accuracy:  73.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  0.002098693464295534 Time:  8.575011968612671 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  1.9112057288487752\n",
      "Testing Accuracy:  73.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 38\n",
      "Training Loss:  0.0018127247534246872 Time:  8.62217116355896 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  1.9732702573140461\n",
      "Testing Accuracy:  73.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 39\n",
      "Training Loss:  0.0015696985748313043 Time:  8.595051288604736 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  2.010905067125956\n",
      "Testing Accuracy:  73.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 40\n",
      "Training Loss:  0.0013393631189778123 Time:  8.084200859069824 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  2.06076979637146\n",
      "Testing Accuracy:  73.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 41\n",
      "Training Loss:  0.0012008123195973103 Time:  8.216927766799927 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  2.0450535217920938\n",
      "Testing Accuracy:  73.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 42\n",
      "Training Loss:  0.0011003778996857127 Time:  8.376013994216919 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  2.0202980836232505\n",
      "Testing Accuracy:  74.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 43\n",
      "Training Loss:  0.0009869056255252951 Time:  8.874453067779541 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  2.134013295173645\n",
      "Testing Accuracy:  73.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 44\n",
      "Training Loss:  0.000896351909234553 Time:  9.053327083587646 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  2.1584004958470664\n",
      "Testing Accuracy:  73.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 45\n",
      "Training Loss:  0.0008239293946763096 Time:  8.951608419418335 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  2.1860997676849365\n",
      "Testing Accuracy:  73.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 46\n",
      "Training Loss:  0.0007399562872824786 Time:  8.971324682235718 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  2.193523128827413\n",
      "Testing Accuracy:  73.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 47\n",
      "Training Loss:  0.0006880634021439145 Time:  8.863950967788696 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  2.188197692235311\n",
      "Testing Accuracy:  73.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 48\n",
      "Training Loss:  0.0006318098900880178 Time:  8.792049884796143 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  2.2352707386016846\n",
      "Testing Accuracy:  73.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 49\n",
      "Training Loss:  0.0005769991624654959 Time:  8.751318216323853 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  2.2283483346303306\n",
      "Testing Accuracy:  73.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "74.33333333333333\n"
     ]
    }
   ],
   "source": [
    "Train_loss = []\n",
    "Test_loss = []\n",
    "Test_acc = []\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, cooldown=5)\n",
    "\n",
    "for i in range(50):\n",
    "    print('epoch:', i)\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = test_model(model, test_loader, criterion)\n",
    "    Train_loss.append(train_loss)\n",
    "    Test_loss.append(test_loss)\n",
    "    Test_acc.append(test_acc)\n",
    "\n",
    "    #scheduler.step(test_acc)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print('Learning rate:', param_group['lr'])\n",
    "    \n",
    "\n",
    "    print('='*20)\n",
    "    \n",
    "print(max(Test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f14a4a162e8>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f14a49fe9b0>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAeSklEQVR4nO3de3SV9Z3v8fc3N0gI5EZACIRwqxdUiI0Igtpqq7V21N61tcVLjzOnPbU90+mc2nNpZ067zjhrej2dmVWnaunU1rvVao9Ta60VCioQERFrIIQQArnf78n+nj/2JgRIyE5Isnn2/rzWYu3sJ8/O/j5k5/P89m//nt/P3B0REQmepFgXICIi46MAFxEJKAW4iEhAKcBFRAJKAS4iElApU/lks2fP9qKioql8ShGRwNu+fXu9u+efuH1KA7yoqIht27ZN5VOKiASemR0Ybru6UEREAiqqADez/2pmu83sTTP7pZlNN7PFZvaKmZWZ2cNmljbZxYqIyDGjBriZFQB3ASXufj6QDNwE3AN8z92XA03AHZNZqIiIHC/aLpQUIN3MUoAM4DBwJfBY5PsbgRsnvjwRERnJqAHu7oeAfwIqCQd3C7AdaHb3/shuVUDBcI83szvNbJuZbaurq5uYqkVEJKoulBzgBmAxMB+YAVw7zK7Dzorl7ve6e4m7l+TnnzQKRkREximaLpT3Afvdvc7d+4AngEuB7EiXCsACoHqSahQRkWFEE+CVwBozyzAzA64C3gJeBD4W2WcD8NTklChTyd0pr2vn8e1VPFlaFetyROQURr2Qx91fMbPHgB1AP1AK3As8CzxkZt+KbLtvMguV47V09pGVkXraP6ejp5/tB5oorWym9GATrx9sprmzb/D7hnFj8bAfb4hIjEV1Jaa7fwP4xgmby4HVE16RjOonL5fzrWf3cMW78rl9/WIuXz6b8Juj6B1s7OSnf6rgkdcO0tbTjxm8a85MPrDiLIoLs1m5MJv/9avdfP3JXZxfMItlc2ZO0tGIyHjZVK7IU1JS4rqU/vSU17Vz7Q9eZtmcTGrbeqhr62HZnExuW1fER4oXkJ6WPOJj3Z3XKpq4f9N+fvvWEZLMuO7CeXz0ogWsKsxm1vTjW/Q1rd188Acvkzsjjaf+yzoy0qZ05gVJYAMh5/m3avj1zmrWLM3j06sLSUoaWyMlnpjZdncvOWm7AnzqbCqr59x5M8nLnDaux4dCzk33bmXPkVZ+99dXkJORxrO7qrlv037ePNRKdkYqnyxZSEFO+kmP7ekL8dTOQ4P7fWp1IZ9Zu4h5WSfve2LNn7n/FT68qoDvfGLlmFv6crymjl5eP9jMwabOYb8/LSWJFfOzOOesmaQkj2+mi5rWbkormwg5rFqYzfzsU/+Ox6N/IMTLe+vJm5HGhQuyJ+zntnb38chrB/npnyqoaupi5rQU2nr6uWRxLv/4sQtZlDfjlI9/o6qZioZOVi7IojA344x4vR5u6eKJHYf4z1csHfdJaKQAV5Nqivx6ZzVf/GUpy+dk8uhfrSU7Y+wzDzz4aiWvVjTyjx+9kLmzpgPw4eIF3LiqYLBl/W8vlxMa4Zy8NH8G3/7w+aO21Idav3w2X7pqOd//XRmrF+dy0+rCMdc9Encn5JAckJbVQMjHVGv/QIi3j7RRerCZ0somXq9spry+I6rHpqcmc8GCLIoLsylemMPKhVlkTjv5zzUUgr11beHPMCrDz1Pd0n3cPmfNmh7+OYXZFBfmcEFBFtNTo/v9n6il61jAHmruAuDdi3K4fd1irlkx95QnHXeno3eA4RqNtW09/HzrAR7dVkV7Tz+ri3L5H9edy/vOncsTOw7xv599i2u+/0e+es053Hpp0XG/h/6BEL99q4b7Nu1n+4Gmwe25M9IoXpjNRYtyKF6YzYULs4f9P5wspZVN3L+5gt/sOoy7s37ZbFYunLiTHagFPiX21bVz/f/dREFOOhUNnZw/fxYPfm5N1CEKcKi5i6u/+xIXLcrhZ7evHrFl0d7TT0/fwEnbzYycjNRxtUgGQs6tD7zKK/sbefLzl7JiftaYf8ZQbd19PLKtip/+aT91bT1cWJB9XMAcPTlNlndq2rj7iV0caOjgpovD70RGek53Z0dlE/dvquC53UcoyE6nuDCbiwpzKC7M5pyzZpGWEg6t2rbu44L0jaoWuiK/i9mZaRQX5gw+bml+JsOdC9p7+tlZ1UJpZfiD5d3VLfQNRPc3WpCdPhhWxYXZJJmFf87BcE2VjeFWf0qScd78WZH9wvWM1lqtqO8If2ay7SCdvQNcsjiX29YVcbilmwc2V1DZ2ElBdjobLl3EJy8uJCs9lc7efnZVtQyewEorm6lt6xnxOVKSjL9YOZ/b1y3mggXHv8aOtHTz9Sd38fu3a3n3ohzu+eiF5M+cdtzJpDA3g9vWFXFxUS5vRP4Pd1Q2sa8ufNI0g7Pnzhw8KQ7+HiawAdE/EOK53Ue4f9N+dlQ2M3NaCjetXshn1xaxMDdj3D9XXSgx0tU7wIf/ZTM1rd08e9dlvFHVzOcf3MEV78rn3s+WkBrF22R359YHXuO1ikb+48uXn9YLYbzq23u47ocvk56azNNfXD/YXz70j3TP4VYW5KRTvDCHVYXZzD6hq+hAQzgEjrayLi7KYcX8LHZWNbP7UCu9AyEgHETvmptJclL0XQhJBpe/K5+PXFQwYl9930CIH7+0jx++sJfM6SmsWpjNi3+uJdmMD104jzvWLxkMjr6BEL/ZdZj7N+1nZ1ULWempXL9yPvXtPeyobKKmNRxE01KSOG/+LGpbewZbpKnJxnnzswaD9KLCHBbkpI/r5NndN8Du6lZ2V7fQ2x8adp+FuRkUL8xmzignvvr2Hkorm3n9YBM7DjSzs6qZzt7wCSZ3Rhor5s9iWsrJjYq27j5erWg8LmDPLzgWsAMh54U9Ndy/eT9byxvJSEtmUd4M3qlpYyDydrAoL4PiwhzOPmsmKcMEZlpKEtesOOuUJ29351evH+KbT79FV98AKUlGZ+8Aa5bkcvu6xVx17txh3yG1dPbxelUzOw6ER1mVVjbR2h2+iHzm9BQuKMiasM933qpuobqlm0V5Gdx2aREfK1k4Ia1+BXiM/O1jO3l0exUP3Hox7zl7DgC/eKWSrz+5i48UF/BPH185agvg8e1VfOXRnXzjL87jtnWLp6LsYb26v5Gb/20rly7NY1FeBqWVzbx95Ngf6bys6dS19dAfuV+Ym0FxYTYXFGTx6v5Gnt9TQ7KFQ+C2dUXH9Z329IeD6mjrdX99B2N5aXb29lPR0ElWeiqfuqSQz57Qv/9WdStffWwnu6tbue7Cefz99SvIy5xGZUPnYMvy6Ell9eJcHt9+iCOt3SzJn8Ft6xbz0RNODNXNXcda2odayM+cNvgOYsX8WePuophKAyHnnZq2weMY+rscKjnJeO/Z+dyydhFzZp76JLG7uoWfbq7gSGs3Kxcce1eVO2PiJiutbevmO//xDo7z2bVFx51MohEKOeX1HYPvTnZXt9I3wslxrPJnTuOWNYu48pw5E9o1qACPgUe3HeSrj73BF69cxleuPvu47/3whTK++/w7/KfLFvPfrztvxJ9R19bD+777EsvmZPLoX66N+SfxP35pH//n/73NjLRkVg15K7pqYTZ5mdPo6h3gzerI29cDzeyobKK2rYecjFQ+fcmiU3ZXnA53Z/uBJu7fvJ/n3jyCmfHBC+Zx66WLeOmdev7lxb1kZ6TxrRtX8IHz5530+KHdOgcbu7hs+WxuX7+YK5bnx/z/XEQBPsXePtLKjf+8meKFOfz8c5ecdDZ2d77x9G5+tuUAd197Dn95xdJhf87nH9zO7/bU8pu7LmPZnMypKP2U3J3qlm7OmjU9qhaGu1Pb1kNWeuqUtUoPNnbysy0VPPRqeIw7wEeKC/ifHzqPnFFaggMhp6mz96TuH5FYUoBPofaefq7/0Sbauvt59q71I77tDIWcux4q5Zk3DnPDqvlknPChZnvPAL/eWc1XrzmbL7x32VSUHlfae/p59o1q5menc9lyTaQmwaVhhFMkFHLufmIXFfUdPPi5NafsM0xKMr7ziZUAbNnXMOw+V583lzsvXzIptca7zGkpfPLiiRv2KHKmUYBPkI6efh7fUcUDmyvYX9/BV685m7VL80Z93LSUZH70qYumoEIRiTcK8NN0qLmLjX+q4JevVtLW3U9xYTY/+lQx111w8gdlIiITSQE+TpUNndzz3Ns8t/sIANeefxa3r1/MRYU5Ma5MRBKFAnwcSiub+NzGbfT2h/jcZYvZsLZoUuabEBE5FQX4GP129xHueqiUOTOn8+hfXcyS/NgP7RORxKQAH4Ofbangm0/v5oKCLO679WKNFRaRmFKARyEUcu557m1+/Mdy3nfuHH54c7HmxhaRmFMKjaK7b4C/eXQnz7xxmM+sWcQ3r18RmOlPRSS+KcBH8c2nd/PMG4e5+9pzuPPyJWfEBPEiIqAAP6XGjl6e2HGIW9YUjjhXiYhIrIxvzaYE8fBrB+kdCLFhbVGsSxEROYkCfAQDIefBVw6wZkkuy+dqRXYROfMowEfw0ju1VDV18Zk1RbEuRURkWArwEfz7lgPkz5zG1SvmxroUEZFhKcCHUdnQyR/eqePm1YVRrVkpIhILSqdhPPjqAZLMuHn1wliXIiIyIgX4Cbr7BnjktYO8/9y5xy2KKyJyplGAn+A3uw7T1NnHZ9YuinUpIiKnpAA/wb9vPcCS/BlcGsVqOiIisaQAH+LNQy2UVjZzyyWLdMm8iJzxFOBD/HzrAaanJvHRdy+IdSkiIqNSgEe0dPXxq9cPceOqArLSU2NdjojIqEYNcDM728xeH/Kv1cy+bGa5Zva8mZVFbgO9GOTj26vo7gtxyxp9eCkiwTBqgLv7n919lbuvAt4NdAJPAl8DXnD35cALkfuB9fBrB1m1MJvzC7JiXYqISFTG2oVyFbDP3Q8ANwAbI9s3AjdOZGFTqbatmz/XtHHt+WfFuhQRkaiNNcBvAn4Z+Xquux8GiNzOGe4BZnanmW0zs211dXXjr3QSbS1vBGCthg6KSIBEHeBmlgZcDzw6lidw93vdvcTdS/Lz88da35TYsq+BmdNTWDFf3SciEhxjaYFfC+xw95rI/RozmwcQua2d6OKmytbyBi5ZnKu1LkUkUMYS4DdzrPsE4GlgQ+TrDcBTE1XUVDrS0s3++g7WLFH3iYgES1QBbmYZwPuBJ4Zs/gfg/WZWFvneP0x8eZNvS3k9gAJcRAInqkWN3b0TyDthWwPhUSmBtmVfA1npqZw3b1asSxERGZOEvxJza3kjlyzOJUn93yISMAkd4Ieau6hs7NTwQREJpIQO8C37GgD1f4tIMCV8gOdkpHL23JmxLkVEZMwSNsDdna3lDaxZkqf+bxEJpIQN8IONXRxq7lL/t4gEVsIG+NZy9X+LSLAlbIBvKW9gdmYay+dkxroUEZFxScgAd3e27GvgkiV5WvtSRAIrIQO8oqGTI63drFX3iYgEWEIG+NHx3/oAU0SCLDEDvLyB/JnTWDJ7RqxLEREZt4QL8KPjv9eq/1tEAi7hAnxfXQd1bT3qPhGRwEu4AN8SGf+tDzBFJOgSLsC37mvgrFnTWZSXEetSREROS0IF+GD/91L1f4tI8CVUgFc1ddHQ0UtJUU6sSxEROW0JFeBltW0Amj5WROJCYgV4TTsAyzT/iYjEgYQK8L217czOnEZ2RlqsSxEROW0JFeBlte2afVBE4kbCBLi7s7e2neVzFeAiEh8SJsBrWnto7+lX/7eIxI2ECfCjI1AU4CISLxInwCMjUJbP0RBCEYkPCRPge+vayUpPZXamRqCISHxInACvCY9A0SX0IhIvEibAy2rbNAJFROJKQgR4Q3sPTZ19LM1XgItI/EiIAC+rjXyAqTlQRCSOJFaAawihiMSRqALczLLN7DEze9vM9pjZWjPLNbPnzawscnvGztG6r7adGWnJzMuaHutSREQmTLQt8B8Az7n7OcBKYA/wNeAFd18OvBC5f0Yqq21jmUagiEicGTXAzWwWcDlwH4C797p7M3ADsDGy20bgxskq8nSV1bSzTBfwiEiciaYFvgSoAx4ws1Iz+4mZzQDmuvthgMjtnOEebGZ3mtk2M9tWV1c3YYVHq6Wrj9q2Hl1CLyJxJ5oATwEuAv7V3YuBDsbQXeLu97p7ibuX5Ofnj7PM8durDzBFJE5FE+BVQJW7vxK5/xjhQK8xs3kAkdvaySnx9OyNTGKli3hEJN6MGuDufgQ4aGZnRzZdBbwFPA1siGzbADw1KRWepr217aSlJLEgJyPWpYiITKiUKPf7IvCgmaUB5cBthMP/ETO7A6gEPj45JZ6estp2luZnkpykESgiEl+iCnB3fx0oGeZbV01sOROvrKaddy86Y4eoi4iMW1xfidnZ28+h5i6NQBGRuBTXAb6vtgPQCBQRiU9xHeBlGoEiInEsrgN8b207KUnGorwZsS5FRGTCxXWAl9W2UzR7BqnJcX2YIpKg4jrZ9tW2q/9bROJW3AZ4T/8AFQ0dGoEiInErbgN8f30HIUcBLiJxK24D/NgkVppGVkTiU9wGeFlNO2awJF8jUEQkPsVtgO+tbacwN4PpqcmxLkVEZFLEdYBrBIqIxLO4DPD+gRDl9e0sVYCLSByLywA/0NhJ34DrA0wRiWtxGeC7q1sBOHuuAlxE4ldcBvjmsnpmTk/h3HkKcBGJX3EX4O7Opr31XLo0jxTNgSIicSzuEq6ioZNDzV2sX54f61JERCZV3AX4prI6ANYvmx3jSkREJlf8Bfjeegqy0ynK0yr0IhLf4irA+wdC/GlfA5ctn42ZVqEXkfgWVwH+xqEW2rr7WafuExFJAHEV4JvL6gEU4CKSEOIqwF/eW8+K+bPInZEW61JERCZd3AR4R08/pZVNrF+u1reIJIa4CfBX9zfSN+Bctkzjv0UkMcRNgL9cVk9aShIlRTmxLkVEZErETYBv3lvP6qJcLeAgIgkjLgK8trWbP9e0qf9bRBJKXAT45n3h4YO6fF5EEklcBPjLZfXkZKRy3rxZsS5FRGTKBD7A3Z1NZfVcumw2SUm6fF5EEkdKNDuZWQXQBgwA/e5eYma5wMNAEVABfMLdmyanzJHtrW2ntq2Hy9R9IiIJZiwt8Pe6+yp3L4nc/xrwgrsvB16I3J9yL0cun9cHmCKSaE6nC+UGYGPk643Ajadfztht3ltPUV4GC3I0fayIJJZoA9yB35rZdjO7M7JtrrsfBojczhnugWZ2p5ltM7NtdXV1p1/xEH0DIbaWN6j1LSIJKao+cGCdu1eb2RzgeTN7O9oncPd7gXsBSkpKfBw1jqi0spmO3gHW6/J5EUlAUbXA3b06clsLPAmsBmrMbB5A5LZ2soocyWsVjQCsXZI31U8tIhJzowa4mc0ws5lHvwauBt4EngY2RHbbADw1WUWOpKa1m6z0VLIyUqf6qUVEYi6aLpS5wJORJcpSgF+4+3Nm9hrwiJndAVQCH5+8MofX2NFLnub+FpEENWqAu3s5sHKY7Q3AVZNRVLQaO3rJUYCLSIIK9JWYjR29Wn1HRBJWoAO8QV0oIpLAAhvg7k6TWuAiksACG+CtXf30h1wBLiIJK7AB3tjZC6AAF5GEFdwA7+gBFOAikrgCG+AN7eEWeN6MaTGuREQkNgIb4I0dkS6UTLXARSQxBTbAGzqOtsAV4CKSmAIb4E0dvWSkJTM9NTnWpYiIxERgA7yxo5ecDLW+RSRxBTbAGzp6yVP/t4gksMAGuOZBEZFEpwAXEQmowAZ4Q0ePRqCISEILZIB39Q7Q3RciVxfxiEgCC2SANwxeRq+l1EQkcQUywAevwlQLXEQSWCADvKFDMxGKiAQywBvbdRm9iEgwA1wTWYmIBDTAO3tJTTZmTkuJdSkiIjETzABvD8+DYmaxLkVEJGYCGeANugpTRCSYAd7Y0aOJrEQk4QU0wHs1BlxEEl4gA7yho1dDCEUk4QUuwPsGQrR192sxBxFJeIEL8CaNARcRAQIY4FrMWEQkLHAB3qh5UEREgAAGuFrgIiJhUQe4mSWbWamZPRO5v9jMXjGzMjN72MymJFEb24/OBa4AF5HENpYW+JeAPUPu3wN8z92XA03AHRNZ2EgaO/swg2yNQhGRBBdVgJvZAuA64CeR+wZcCTwW2WUjcONkFHiixo4estNTSU7SPCgiktiibYF/H/hbIBS5nwc0u3t/5H4VUDDcA83sTjPbZmbb6urqTqtY0Gr0IiJHjRrgZvYhoNbdtw/dPMyuPtzj3f1edy9x95L8/PxxlnlMQ3svebqMXkSEaCbUXgdcb2YfBKYDswi3yLPNLCXSCl8AVE9emcc0dvSyND9zKp5KROSMNmoL3N3vdvcF7l4E3AT83t0/DbwIfCyy2wbgqUmrcojGjl5dhSkiwumNA/9vwF+b2V7CfeL3TUxJIwuFnKbOXnI1AkVEJKoulEHu/gfgD5Gvy4HVE1/SyFq6+gi5xoCLiEDArsQcvApTXSgiIsEKcM2DIiJyTMACXJfRi4gcFagAb1ALXERkUKACvEkBLiIyKFAB3tDRS+a0FKalJMe6FBGRmAtUgGseFBGRYxTgIiIBFagAD09kpQAXEYGABXhjRy85CnARESBAAe7uNHaqBS4iclRgAryjd4De/pD6wEVEIgIT4I3tGgMuIjJUYAK8IXIZvSayEhEJC0yAH5vISsupiYhAgAJ8cB4ULeYgIgIEKMAH50FRF4qICBCgAG/s6CUtJYkZaZoHRUQEAhTgDR3hMeBmFutSRETOCIEJcM2DIiJyvMAEeIMCXETkOIEJ8MaOHgW4iMgQgQnwpo4+BbiIyBCBCPCe/gHae/o1kZWIyBCBCHBdhSkicrJABHiDJrISETlJIAK8UavRi4icRAEuIhJQgQpwfYgpInJMYAI8OcnISk+NdSkiImeMQAR4Q0cvORmpJCVpHhQRkaNGDXAzm25mr5rZTjPbbWZ/F9m+2MxeMbMyM3vYzCatf0NXYYqInCyaFngPcKW7rwRWAR8wszXAPcD33H050ATcMVlFXrggmyvPmTtZP15EJJBSRtvB3R1oj9xNjfxz4ErgU5HtG4FvAv868SXCF967bDJ+rIhIoEXVB25myWb2OlALPA/sA5rdvT+ySxVQMDkliojIcKIKcHcfcPdVwAJgNXDucLsN91gzu9PMtpnZtrq6uvFXKiIixxnTKBR3bwb+AKwBss3saBfMAqB6hMfc6+4l7l6Sn59/OrWKiMgQ0YxCyTez7MjX6cD7gD3Ai8DHIrttAJ6arCJFRORko36ICcwDNppZMuHAf8TdnzGzt4CHzOxbQClw3yTWKSIiJ4hmFMobQPEw28sJ94eLiEgMBOJKTBEROZkCXEQkoCx8nc4UPZlZHXBgnA+fDdRPYDlBoeNOLIl63JC4xx7NcS9y95OG8U1pgJ8OM9vm7iWxrmOq6bgTS6IeNyTusZ/OcasLRUQkoBTgIiIBFaQAvzfWBcSIjjuxJOpxQ+Ie+7iPOzB94CIicrwgtcBFRGQIBbiISEAFIsDN7ANm9mcz22tmX4t1PZPFzO43s1oze3PItlwzez6ydN3zZpYTyxong5ktNLMXzWxPZNm+L0W2x/WxnwnLFcZSZJ2BUjN7JnI/7o/bzCrMbJeZvW5m2yLbxv06P+MDPDKJ1j8D1wLnATeb2XmxrWrS/BT4wAnbvga8EFm67oXI/XjTD3zF3c8lPFXxFyK/43g/9pgvVxhjXyI8s+lRiXLc73X3VUPGfo/7dX7GBzjhCbP2unu5u/cCDwE3xLimSeHufwQaT9h8A+El64jc3jilRU0Bdz/s7jsiX7cR/qMuIM6P3cNGWq7wscj2uDtuADNbAFwH/CRy30iA4x7BuF/nQQjwAuDgkPuJtnzbXHc/DOGgA+bEuJ5JZWZFhGe/fIUEOPYEXq7w+8DfAqHI/TwS47gd+K2ZbTezOyPbxv06j2Y+8FizYbZp7GMcMrNM4HHgy+7eGm6UxTd3HwBWRRZNeZIxLFcYVGb2IaDW3beb2XuObh5m17g67oh17l5tZnOA583s7dP5YUFogVcBC4fcH3H5tjhVY2bzACK3tTGuZ1KYWSrh8H7Q3Z+IbE6IY4fxLVcYYOuA682sgnCX6JWEW+Txfty4e3XktpbwCXs1p/E6D0KAvwYsj3xCnQbcBDwd45qm0tOEl6yDOF26LtL/eR+wx92/O+RbcX3sibpcobvf7e4L3L2I8N/z793908T5cZvZDDObefRr4GrgTU7jdR6IKzHN7IOEz9DJwP3u/u0YlzQpzOyXwHsITy9ZA3wD+BXwCFAIVAIfd/cTP+gMNDNbD7wM7OJYn+jXCfeDx+2xm9mFhD+0Grpc4d+b2RLCLdNcwssV3uLuPbGrdPJEulD+xt0/FO/HHTm+JyN3U4BfuPu3zSyPcb7OAxHgIiJysiB0oYiIyDAU4CIiAaUAFxEJKAW4iEhAKcBFRAJKAS4iElAKcBGRgPr/wjLBE7Z7GdUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
