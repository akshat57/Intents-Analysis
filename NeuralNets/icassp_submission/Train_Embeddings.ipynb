{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_vocab import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['h', 'x', 'ɹ', 'ʒ', 'aː', 'r', 'k', 'uː', 'æ', 'b', 'θ', 'a', 'eː', 'p', 'ɔ', 'e', 'ə', 'i', 'iː', 'm', 'f', 'z', 'ʊ', 'ɒ', 'ɛ', 'd', 'w', 'ŋ', 'ʌ', 'ʃ', 'ɑ', 'j', 'ð', 'ɪ', 's', 'ʔ', 'o', 'l', 'u', 'pʰ', 'ɯ', 'n', 'v', 'ɻ', 'tʰ', 'kʰ', 't', 'ɡ'])\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "language = 'english'\n",
    "context_size = 2\n",
    "emb_size = 22 # size of embeddings you want to create\n",
    "embedding_data = load_data('embedding_data_' + language + '_' + str(context_size) + '.pkl')\n",
    "vocab_size = len(embedding_data) + 1\n",
    "\n",
    "print(embedding_data.keys())\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = {}        #create a dictionary of feature vectors\n",
    "for i, phone in enumerate(embedding_data):\n",
    "    feature_vectors[phone] = [0]*(len(embedding_data) + 1)\n",
    "    feature_vectors[phone][i] = 1\n",
    "    \n",
    "feature_vectors['unk'] = [0]*(len(embedding_data) + 1)\n",
    "feature_vectors['unk'][len(embedding_data)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, embedding_data, feature_vectors):\n",
    "\n",
    "        self.data = []\n",
    "        for phone in embedding_data:\n",
    "            for context in embedding_data[phone]:\n",
    "                phone_to_vector = []\n",
    "                for c in context:\n",
    "                    phone_to_vector.append(feature_vectors[c])\n",
    "                    \n",
    "                label = np.argmax(np.array(feature_vectors[phone]))\n",
    "                self.data.append([torch.from_numpy(np.array(phone_to_vector)).float(), label])\n",
    "                \n",
    "        random.shuffle(self.data)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        return self.data[index][0], self.data[index][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(embedding_data, feature_vectors)\n",
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=32)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5035"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([32, 4, 49]) torch.Size([32])\n",
      "tensor([17, 34, 41, 41,  6, 46, 41, 15, 24, 30, 33, 11, 33, 24, 27, 31, 19, 19,\n",
      "        33, 11, 34, 36,  8, 25, 34, 37, 33, 14, 36, 14, 16, 33])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(len(data))\n",
    "    print(data[0].shape, data[1].shape)\n",
    "    print(data[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Model(nn.Module):\n",
    "    def __init__(self, emb_size, vocab_size):\n",
    "        super(My_Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(vocab_size, emb_size, bias = False)\n",
    "        self.fc2 = nn.Linear(emb_size, vocab_size, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.fc1(x[:,0,:])\n",
    "        for i in range(1, x.shape[1]):\n",
    "            outputs += self.fc1(x[:,i,:])\n",
    "                           \n",
    "        outputs /= outputs/x.shape[1]\n",
    "                           \n",
    "        output = self.fc2(outputs)   \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My_Model(\n",
      "  (fc1): Linear(in_features=49, out_features=22, bias=False)\n",
      "  (fc2): Linear(in_features=22, out_features=49, bias=False)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = My_Model(emb_size, vocab_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
    "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
    "        data = data.to(device)\n",
    "        target = target.to(device) # all data & model on same device\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += target.size(0)\n",
    "        correct_predictions += (predicted == target).sum().item()\n",
    "    \n",
    "            \n",
    "    end_time = time.time()\n",
    "    \n",
    "    acc = (correct_predictions/total_predictions)*100.0\n",
    "    running_loss /= len(train_loader)\n",
    "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')  \n",
    "    print('Training Accuracy: ', acc, '%')\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Training Loss:  3.598143456306571 Time:  7.013299942016602 s\n",
      "Training Accuracy:  6.731598909932895 %\n",
      "epoch: 1\n",
      "Training Loss:  3.5978163810093564 Time:  6.887549161911011 s\n",
      "Training Accuracy:  6.894239901670485 %\n",
      "epoch: 2\n",
      "Training Loss:  3.5977098687521396 Time:  7.884326934814453 s\n",
      "Training Accuracy:  6.875616887349387 %\n",
      "epoch: 3\n",
      "Training Loss:  3.5976403592004558 Time:  7.110896110534668 s\n",
      "Training Accuracy:  6.799883295776921 %\n",
      "epoch: 4\n",
      "Training Loss:  3.601850768991828 Time:  8.692988157272339 s\n",
      "Training Accuracy:  6.7198043341961995 %\n",
      "epoch: 5\n",
      "Training Loss:  3.603662505665981 Time:  6.869415998458862 s\n",
      "Training Accuracy:  6.737806581373261 %\n",
      "epoch: 6\n",
      "Training Loss:  3.597650813346113 Time:  7.665459156036377 s\n",
      "Training Accuracy:  6.794917158624628 %\n",
      "epoch: 7\n",
      "Training Loss:  3.5992199381153065 Time:  8.610066890716553 s\n",
      "Training Accuracy:  6.8731338187732405 %\n",
      "epoch: 8\n",
      "Training Loss:  3.5985020568851445 Time:  8.213409185409546 s\n",
      "Training Accuracy:  6.828438584402605 %\n",
      "epoch: 9\n",
      "Training Loss:  3.59744234274492 Time:  6.703587055206299 s\n",
      "Training Accuracy:  6.813540172945726 %\n",
      "epoch: 10\n",
      "Training Loss:  nan Time:  5.883996963500977 s\n",
      "Training Accuracy:  2.5234184405087805 %\n",
      "epoch: 11\n",
      "Training Loss:  nan Time:  5.876314163208008 s\n",
      "Training Accuracy:  1.1540061207640402 %\n",
      "epoch: 12\n",
      "Training Loss:  nan Time:  7.448945999145508 s\n",
      "Training Accuracy:  1.1540061207640402 %\n",
      "epoch: 13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4c264b4a223c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mTrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-bc698f1b5bcf>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Train_loss = []\n",
    "Test_loss = []\n",
    "Test_acc = []\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, cooldown=5)\n",
    "\n",
    "for i in range(100):\n",
    "    print('epoch:', i)\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    Train_loss.append(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 49])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
