{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "#import psutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.insert(1, '/home/ubuntu/Intents/Intents-Analysis/Analysis')\n",
    "sys.path.insert(1, '/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_vocab import load_data, get_vocab\n",
    "from get_frequency import get_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    print(filename)\n",
    "    a_file = open(filename, \"rb\")\n",
    "    output = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/TaskMasterData/Get_Phones_Combos/1_lang_train_split/taskmaster_training_hindi.pkl\n",
      "/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/TaskMasterData/Get_Phones_Combos/1_language/taskmaster_testing_hindi.pkl\n"
     ]
    }
   ],
   "source": [
    "#Defining constants and labels\n",
    "intent_labels = {'movie-tickets':0, 'auto-repair':1, 'restaurant-table':2, 'pizza-ordering':3, 'uber-lyft':4, 'coffee-ordering':5}\n",
    "train_language = 'hindi'\n",
    "test_language = 'hindi'\n",
    "\n",
    "#Loading data\n",
    "train_file = '/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/TaskMasterData/Get_Phones_Combos/1_lang_train_split/taskmaster_training_' + train_language + '.pkl'\n",
    "test_file = '/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/TaskMasterData/Get_Phones_Combos/1_language/taskmaster_testing_' + train_language + '.pkl'\n",
    "\n",
    "test_data = load_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets frequency of all the phones in the dataset. Might be useful to assign unkown words\n",
    "frequency, word_index = get_frequency(1, train_file)\n",
    "all_freq = {}\n",
    "for phone in word_index:\n",
    "    all_freq[word_index[phone]] = 0\n",
    "    for intent in frequency:\n",
    "        all_freq[word_index[phone]] += frequency[intent][word_index[phone]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 23778,\n",
       " 1: 22578,\n",
       " 2: 12125,\n",
       " 3: 10800,\n",
       " 4: 10455,\n",
       " 5: 9564,\n",
       " 6: 9143,\n",
       " 7: 8986,\n",
       " 8: 8179,\n",
       " 9: 7661,\n",
       " 10: 6856,\n",
       " 11: 4311,\n",
       " 12: 4236,\n",
       " 13: 3925,\n",
       " 14: 3722,\n",
       " 15: 2941,\n",
       " 16: 2158,\n",
       " 17: 2112,\n",
       " 18: 2002,\n",
       " 19: 1808,\n",
       " 20: 1733,\n",
       " 21: 1512,\n",
       " 22: 1506,\n",
       " 23: 1239,\n",
       " 24: 1236,\n",
       " 25: 1145,\n",
       " 26: 1122,\n",
       " 27: 1041,\n",
       " 28: 1023,\n",
       " 29: 808,\n",
       " 30: 731,\n",
       " 31: 681,\n",
       " 32: 528,\n",
       " 33: 477,\n",
       " 34: 465,\n",
       " 35: 462,\n",
       " 36: 455,\n",
       " 37: 452,\n",
       " 38: 409,\n",
       " 39: 408,\n",
       " 40: 343,\n",
       " 41: 341,\n",
       " 42: 318,\n",
       " 43: 293,\n",
       " 44: 275,\n",
       " 45: 184,\n",
       " 46: 113,\n",
       " 47: 107,\n",
       " 48: 61,\n",
       " 49: 41,\n",
       " 50: 39,\n",
       " 51: 39,\n",
       " 52: 28,\n",
       " 53: 25,\n",
       " 54: 25,\n",
       " 55: 22,\n",
       " 56: 17,\n",
       " 57: 16,\n",
       " 58: 16,\n",
       " 59: 5,\n",
       " 60: 2}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(train_file):\n",
    "    '''This function creates an indexed vocabulary dictionary from the training file'''\n",
    "    \n",
    "    vocab, _ = get_vocab(1, train_file)\n",
    "    \n",
    "    phone_to_idx = {'unk': 0}\n",
    "    for i, phone in enumerate(vocab):\n",
    "        phone_to_idx[phone] = i + 1\n",
    "        \n",
    "    return phone_to_idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_to_idx = create_vocabulary(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_vector(utterance, feature_vectors, max_len):\n",
    "    '''\n",
    "    Pad sentence at the end with maximum length with 'unk' \n",
    "    '''\n",
    "    input_vector = feature_vectors[utterance[0]].reshape(-1,1)\n",
    "    for ipa in utterance[1:]:\n",
    "        input_vector = torch.cat((input_vector, feature_vectors[ipa].reshape(-1,1)), dim = 1)\n",
    "    \n",
    "    for i in range(max_len - len(utterance)):\n",
    "        input_vector = torch.cat((input_vector, feature_vectors['unk'].reshape(-1,1)), dim = 1)\n",
    "        \n",
    "    return input_vector\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_file, intent_labels, phone_to_idx, train=True):\n",
    "        \n",
    "        data = load_data(data_file)\n",
    "        self.all_data = []\n",
    "        \n",
    "        for intent in data:\n",
    "            for utterance in data[intent]:\n",
    "                utterance_to_idx = []\n",
    "                \n",
    "                for phone in utterance:\n",
    "                    if phone not in phone_to_idx:\n",
    "                        phone = 'unk'\n",
    "    \n",
    "                    utterance_to_idx.append(phone_to_idx[phone])\n",
    "                \n",
    "                self.all_data.append([utterance_to_idx, intent_labels[intent]])\n",
    "        \n",
    "        if train:\n",
    "            random.shuffle(self.all_data)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        input_vector = self.all_data[index][0]\n",
    "        label = self.all_data[index][1]\n",
    "        print(input_vector, label)\n",
    "\n",
    "        return input_vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_file, intent_labels, phone_to_idx, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=4)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47, 12, 40, 41, 52, 58, 41, 59, 47, 51, 45, 51, 15, 12, 47, 36, 47, 12, 5, 53, 16, 51, 11, 24, 50, 51, 12, 5, 53, 50, 36, 47, 24, 59, 16, 51, 39, 55, 41, 50, 41, 5, 41, 47, 12, 60, 12, 43, 60, 12, 40] 3\n",
      "[3, 43, 12, 24, 52, 48, 3, 12, 24, 40, 55, 45, 53, 5, 25, 5, 46, 48, 60, 48, 40, 9, 42, 48, 9, 48, 50, 48, 2, 46, 47, 47, 46, 52, 48, 3, 28, 50, 48] 5\n",
      "[3, 12, 40, 51, 16, 24, 47, 45, 51, 5, 47, 12, 52, 12, 43, 3, 28, 47, 34, 12, 60, 28, 47, 53, 16, 12, 60, 12, 3, 51, 5, 53, 47, 51, 5, 15, 12, 52, 24, 5, 47, 24, 5, 53, 36, 47, 53, 5, 51, 50, 48, 3, 12, 60, 12] 0\n",
      "[47, 12, 40, 41, 52, 60, 51, 47, 51, 16, 41, 50, 60, 40, 37, 42, 51, 5, 41, 49, 40, 51, 60, 24, 5, 47, 24, 5, 51, 44, 51, 43, 51, 60, 41, 44, 53, 47, 5, 41, 11, 36, 47, 12, 12, 43, 60, 12, 36] 0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_data, feature_vectors, intent_labels, max_sent_len[language], train=True)\n",
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=32)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args)\n",
    "\n",
    "test_dataset = MyDataset(test_data, feature_vectors, intent_labels, max_sent_len[language], train=False)\n",
    "test_loader_args = dict(shuffle=False, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "test_loader = DataLoader(test_dataset, **test_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([128, 1, 22, 307])\n",
      "torch.Size([127, 1, 22, 307])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, (1,3)) # (22,245) \n",
    "        self.pool1 = nn.MaxPool2d( kernel_size = (1,3), stride = (1,2)) #(22, 122) \n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, (3,5)) # (20,118) \n",
    "        self.pool2 = nn.MaxPool2d( kernel_size = (1,2), stride = (1,2)) #(18, 59) \n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 32, (5,7)) # (16, 53)\n",
    "        self.pool3 = nn.MaxPool2d( kernel_size = (1,3), stride = (1,2)) #(16, 26)\n",
    "        self.conv3_bn = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 16 * 33, 512)\n",
    "        self.fc1_bn = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.fc2_bn = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 6)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = x.view(-1, 32 *16 * 33)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNN_Model(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 32, kernel_size=(5, 7), stride=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=16896, out_features=512, bias=True)\n",
      "  (fc1_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (fc2_bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=64, out_features=6, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyCNN_Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
    "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
    "        data = data.to(device)\n",
    "        target = target.to(device) # all data & model on same device\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += target.size(0)\n",
    "        correct_predictions += (predicted == target).sum().item()\n",
    "    \n",
    "            \n",
    "    end_time = time.time()\n",
    "    \n",
    "    acc = (correct_predictions/total_predictions)*100.0\n",
    "    running_loss /= len(train_loader)\n",
    "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')  \n",
    "    print('Training Accuracy: ', acc, '%')\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):   \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "        running_loss /= len(test_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('Testing Loss: ', running_loss)\n",
    "        print('Testing Accuracy: ', acc, '%')\n",
    "        return running_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Training Loss:  1.794168057649032 Time:  8.998135089874268 s\n",
      "Training Accuracy:  23.173632347944277 %\n",
      "Testing Loss:  1.8785438934961955\n",
      "Testing Accuracy:  16.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 1\n",
      "Training Loss:  1.7274745650913403 Time:  8.822555541992188 s\n",
      "Training Accuracy:  26.979272850832487 %\n",
      "Testing Loss:  1.8781338930130005\n",
      "Testing Accuracy:  27.333333333333332 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 2\n",
      "Training Loss:  1.6892271612001502 Time:  8.723637819290161 s\n",
      "Training Accuracy:  33.197417601087324 %\n",
      "Testing Loss:  2.0117045640945435\n",
      "Testing Accuracy:  27.333333333333332 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 3\n",
      "Training Loss:  1.665141504743825 Time:  8.728636026382446 s\n",
      "Training Accuracy:  33.97893306150187 %\n",
      "Testing Loss:  1.9512519041697185\n",
      "Testing Accuracy:  28.333333333333332 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 4\n",
      "Training Loss:  1.5459278614624687 Time:  8.692805767059326 s\n",
      "Training Accuracy:  39.10975195378865 %\n",
      "Testing Loss:  1.7833617130915325\n",
      "Testing Accuracy:  33.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 5\n",
      "Training Loss:  1.3977020978927612 Time:  8.783669710159302 s\n",
      "Training Accuracy:  45.3958545701665 %\n",
      "Testing Loss:  1.7640759150187175\n",
      "Testing Accuracy:  37.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 6\n",
      "Training Loss:  1.2460102050200752 Time:  8.853622913360596 s\n",
      "Training Accuracy:  53.00713557594292 %\n",
      "Testing Loss:  1.6247481902440388\n",
      "Testing Accuracy:  44.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 7\n",
      "Training Loss:  1.135948429936948 Time:  8.797751903533936 s\n",
      "Training Accuracy:  56.03126061841658 %\n",
      "Testing Loss:  1.6311557690302532\n",
      "Testing Accuracy:  44.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 8\n",
      "Training Loss:  1.0430922300919243 Time:  8.817179679870605 s\n",
      "Training Accuracy:  61.39993204213388 %\n",
      "Testing Loss:  1.4427404403686523\n",
      "Testing Accuracy:  51.33333333333333 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 9\n",
      "Training Loss:  0.9487948391748511 Time:  8.777031183242798 s\n",
      "Training Accuracy:  65.4774040095141 %\n",
      "Testing Loss:  1.518769383430481\n",
      "Testing Accuracy:  48.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 10\n",
      "Training Loss:  0.877358527287193 Time:  8.783837795257568 s\n",
      "Training Accuracy:  68.67142371729528 %\n",
      "Testing Loss:  1.4005340337753296\n",
      "Testing Accuracy:  56.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 11\n",
      "Training Loss:  0.7926639525786691 Time:  8.771010875701904 s\n",
      "Training Accuracy:  70.74413863404689 %\n",
      "Testing Loss:  1.2270039916038513\n",
      "Testing Accuracy:  54.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 12\n",
      "Training Loss:  0.7406832601713098 Time:  8.8408842086792 s\n",
      "Training Accuracy:  73.80224260958205 %\n",
      "Testing Loss:  1.4324296315511067\n",
      "Testing Accuracy:  53.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 13\n",
      "Training Loss:  0.6790755287460659 Time:  8.861438512802124 s\n",
      "Training Accuracy:  76.04485219164118 %\n",
      "Testing Loss:  1.303671379884084\n",
      "Testing Accuracy:  54.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 14\n",
      "Training Loss:  0.6064040401707524 Time:  8.773140668869019 s\n",
      "Training Accuracy:  78.52531430513082 %\n",
      "Testing Loss:  1.3111806909243267\n",
      "Testing Accuracy:  55.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 15\n",
      "Training Loss:  0.5371547924435657 Time:  8.91283369064331 s\n",
      "Training Accuracy:  81.41352361535847 %\n",
      "Testing Loss:  1.354926586151123\n",
      "Testing Accuracy:  55.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 16\n",
      "Training Loss:  0.4880868015081986 Time:  8.817856788635254 s\n",
      "Training Accuracy:  83.21440706761808 %\n",
      "Testing Loss:  1.3248239358266194\n",
      "Testing Accuracy:  57.99999999999999 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 17\n",
      "Training Loss:  0.4021625155987947 Time:  8.665114164352417 s\n",
      "Training Accuracy:  85.69486918110772 %\n",
      "Testing Loss:  1.6083328326543171\n",
      "Testing Accuracy:  55.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 18\n",
      "Training Loss:  0.3503418253815692 Time:  8.560502529144287 s\n",
      "Training Accuracy:  87.97145769622834 %\n",
      "Testing Loss:  1.471421202023824\n",
      "Testing Accuracy:  56.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 19\n",
      "Training Loss:  0.3068867131419804 Time:  8.186140060424805 s\n",
      "Training Accuracy:  89.53448861705743 %\n",
      "Testing Loss:  1.6208962202072144\n",
      "Testing Accuracy:  57.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 20\n",
      "Training Loss:  0.24543386373830878 Time:  7.72600793838501 s\n",
      "Training Accuracy:  91.87903499830105 %\n",
      "Testing Loss:  1.4057586987813313\n",
      "Testing Accuracy:  57.99999999999999 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 21\n",
      "Training Loss:  0.182239909534869 Time:  8.383195638656616 s\n",
      "Training Accuracy:  94.6313285762827 %\n",
      "Testing Loss:  1.9944767157236736\n",
      "Testing Accuracy:  57.99999999999999 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 22\n",
      "Training Loss:  0.1583093357798846 Time:  8.581685304641724 s\n",
      "Training Accuracy:  95.48080190282026 %\n",
      "Testing Loss:  1.6958466370900471\n",
      "Testing Accuracy:  58.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 23\n",
      "Training Loss:  0.11211232095956802 Time:  8.160475969314575 s\n",
      "Training Accuracy:  96.77200135915733 %\n",
      "Testing Loss:  1.9319287538528442\n",
      "Testing Accuracy:  60.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 24\n",
      "Training Loss:  0.07838649351311766 Time:  8.345466613769531 s\n",
      "Training Accuracy:  98.1651376146789 %\n",
      "Testing Loss:  2.133752783139547\n",
      "Testing Accuracy:  60.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 25\n",
      "Training Loss:  0.0637991199998752 Time:  8.27334713935852 s\n",
      "Training Accuracy:  98.53890587835542 %\n",
      "Testing Loss:  1.9966511726379395\n",
      "Testing Accuracy:  58.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 26\n",
      "Training Loss:  0.05068392533323039 Time:  8.601824283599854 s\n",
      "Training Accuracy:  98.91267414203195 %\n",
      "Testing Loss:  1.892628788948059\n",
      "Testing Accuracy:  61.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 27\n",
      "Training Loss:  0.03613523814989173 Time:  8.776336431503296 s\n",
      "Training Accuracy:  99.52429493713896 %\n",
      "Testing Loss:  2.519706686337789\n",
      "Testing Accuracy:  60.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 28\n",
      "Training Loss:  0.02803331645934478 Time:  8.822147369384766 s\n",
      "Training Accuracy:  99.52429493713896 %\n",
      "Testing Loss:  2.579321543375651\n",
      "Testing Accuracy:  60.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 29\n",
      "Training Loss:  0.021262225978400395 Time:  8.72784161567688 s\n",
      "Training Accuracy:  99.66021066938498 %\n",
      "Testing Loss:  2.570065975189209\n",
      "Testing Accuracy:  60.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 30\n",
      "Training Loss:  0.016398454834099695 Time:  8.819328784942627 s\n",
      "Training Accuracy:  99.76214746856948 %\n",
      "Testing Loss:  2.47237761815389\n",
      "Testing Accuracy:  60.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 31\n",
      "Training Loss:  0.01307267831314517 Time:  8.78953766822815 s\n",
      "Training Accuracy:  99.76214746856948 %\n",
      "Testing Loss:  2.5176262855529785\n",
      "Testing Accuracy:  60.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 32\n",
      "Training Loss:  0.010502072182767417 Time:  8.809229850769043 s\n",
      "Training Accuracy:  99.83010533469249 %\n",
      "Testing Loss:  2.695507526397705\n",
      "Testing Accuracy:  59.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 33\n",
      "Training Loss:  0.008676978425406243 Time:  8.990276098251343 s\n",
      "Training Accuracy:  99.864084267754 %\n",
      "Testing Loss:  2.8086392084757485\n",
      "Testing Accuracy:  59.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 34\n",
      "Training Loss:  0.0075448492400186215 Time:  9.10340666770935 s\n",
      "Training Accuracy:  99.89806320081549 %\n",
      "Testing Loss:  2.7925682067871094\n",
      "Testing Accuracy:  59.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 35\n",
      "Training Loss:  0.006495453295824321 Time:  9.156219244003296 s\n",
      "Training Accuracy:  99.89806320081549 %\n",
      "Testing Loss:  2.9739821751912436\n",
      "Testing Accuracy:  59.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 36\n",
      "Training Loss:  0.005108294284740544 Time:  9.34318208694458 s\n",
      "Training Accuracy:  99.89806320081549 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss:  2.9723122119903564\n",
      "Testing Accuracy:  59.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 37\n",
      "Training Loss:  0.004270463756731023 Time:  9.116110563278198 s\n",
      "Training Accuracy:  99.93204213387699 %\n",
      "Testing Loss:  3.064540147781372\n",
      "Testing Accuracy:  59.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 38\n",
      "Training Loss:  0.003726943180916588 Time:  9.065786600112915 s\n",
      "Training Accuracy:  99.9660210669385 %\n",
      "Testing Loss:  3.066888173421224\n",
      "Testing Accuracy:  59.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 39\n",
      "Training Loss:  0.0030560165861338055 Time:  8.885696411132812 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  3.123511791229248\n",
      "Testing Accuracy:  59.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 40\n",
      "Training Loss:  0.0028524923102889697 Time:  8.96895694732666 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  3.13981040318807\n",
      "Testing Accuracy:  58.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 41\n",
      "Training Loss:  0.0025517357558862345 Time:  8.865358591079712 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  3.1678187052408853\n",
      "Testing Accuracy:  57.99999999999999 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 42\n",
      "Training Loss:  0.0021691589170823927 Time:  3.52290940284729 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  3.1533427238464355\n",
      "Testing Accuracy:  58.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 43\n",
      "Training Loss:  0.0018859022884103267 Time:  3.0388741493225098 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  3.222170352935791\n",
      "Testing Accuracy:  60.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 44\n",
      "Training Loss:  0.001714784431817901 Time:  3.016663074493408 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  3.2615109284718833\n",
      "Testing Accuracy:  59.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 45\n",
      "Training Loss:  0.0014596896489029345 Time:  3.027850866317749 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  3.278437614440918\n",
      "Testing Accuracy:  59.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 46\n",
      "Training Loss:  0.0013641409699946803 Time:  3.0285956859588623 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  3.2629252274831138\n",
      "Testing Accuracy:  58.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 47\n",
      "Training Loss:  0.0012491528531941383 Time:  3.0390191078186035 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  3.37456742922465\n",
      "Testing Accuracy:  59.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 48\n",
      "Training Loss:  0.0010720135773147415 Time:  3.0275838375091553 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  3.4454282919565835\n",
      "Testing Accuracy:  57.99999999999999 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "epoch: 49\n",
      "Training Loss:  0.0009866272499177444 Time:  3.030522584915161 s\n",
      "Training Accuracy:  100.0 %\n",
      "Testing Loss:  3.4579006830851235\n",
      "Testing Accuracy:  59.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "61.0\n"
     ]
    }
   ],
   "source": [
    "Train_loss = []\n",
    "Test_loss = []\n",
    "Test_acc = []\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, cooldown=5)\n",
    "\n",
    "for i in range(50):\n",
    "    print('epoch:', i)\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = test_model(model, test_loader, criterion)\n",
    "    Train_loss.append(train_loss)\n",
    "    Test_loss.append(test_loss)\n",
    "    Test_acc.append(test_acc)\n",
    "\n",
    "    #scheduler.step(test_acc)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print('Learning rate:', param_group['lr'])\n",
    "    \n",
    "\n",
    "    print('='*20)\n",
    "    \n",
    "print(max(Test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1dbc829e48>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(np.array([1,2,3,4]))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = torch.argsort(x, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 2, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
