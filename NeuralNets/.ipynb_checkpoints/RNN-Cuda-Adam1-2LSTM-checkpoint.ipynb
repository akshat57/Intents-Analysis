{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import psutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/ubuntu/Intents-Analysis/Analysis')\n",
    "#sys.path.insert(1, '/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_vocab import load_data, get_vocab\n",
    "from get_frequency import get_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is True\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Needed Functions\n",
    "def load_data(filename):\n",
    "    a_file = open(filename, \"rb\")\n",
    "    output = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_vocabulary(train_file):\n",
    "    '''This function creates an indexed vocabulary dictionary from the training file'''\n",
    "    \n",
    "    vocab, _ = get_vocab(1, train_file)\n",
    "    \n",
    "    phone_to_idx = {'unk': 1}#Padding indx = 0, unkown_idx = 1, indexing starts from 2\n",
    "    for i, phone in enumerate(vocab):\n",
    "        phone_to_idx[phone] = i + 2\n",
    "        \n",
    "    return phone_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_file, intent_labels, phone_to_idx):\n",
    "        data = load_data(data_file)\n",
    "        self.all_data = []\n",
    "        \n",
    "        for intent in data:\n",
    "            for utterance in data[intent]:\n",
    "                utterance_to_idx = []\n",
    "                \n",
    "                for phone in utterance:\n",
    "                    if phone not in phone_to_idx:\n",
    "                        phone = 'unk'\n",
    "    \n",
    "                    utterance_to_idx.append(phone_to_idx[phone])\n",
    "                \n",
    "                self.all_data.append([utterance_to_idx, intent_labels[intent]])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        input_vector = self.all_data[index][0]\n",
    "        label = self.all_data[index][1]\n",
    "\n",
    "        return input_vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_indic(tuple_lst):\n",
    "\n",
    "    x_lst = [x[0] for x in tuple_lst]\n",
    "    y_lst = [x[1] for x in tuple_lst]\n",
    "\n",
    "    # collate x\n",
    "    B = len(tuple_lst)#Number of training samples\n",
    "    T = max(len(x) for x in x_lst)#Max length of a sentence\n",
    "\n",
    "    # x values\n",
    "    x = torch.zeros([B, T], dtype=torch.int64)\n",
    "    lengths = torch.zeros(B, dtype=torch.int64)\n",
    "\n",
    "    for i, x_np in enumerate(x_lst):\n",
    "        lengths[i] = len(x_np)\n",
    "        x[i,:len(x_np)] = torch.tensor(x_np)\n",
    "\n",
    "    # collate y\n",
    "    y = torch.zeros([B, 6])\n",
    "    for i, y_label in enumerate(y_lst):\n",
    "        y[i][y_label] = 1\n",
    "        \n",
    "    ids = torch.argsort(lengths, descending=True)\n",
    "\n",
    "    return x[ids], lengths[ids], y[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "#Defining constants and labels\n",
    "intent_labels = {'movie-tickets':0, 'auto-repair':1, 'restaurant-table':2, 'pizza-ordering':3, 'uber-lyft':4, 'coffee-ordering':5}\n",
    "train_language = 'hindi'\n",
    "test_language = 'hindi'\n",
    "\n",
    "#Loading data\n",
    "train_file = '/home/ubuntu/Intents-Analysis/TaskMasterData/Get_Phones_Combos/1_lang_train_split/taskmaster_training_' + train_language + '.pkl'\n",
    "test_file = '/home/ubuntu/Intents-Analysis/TaskMasterData/Get_Phones_Combos/1_language/taskmaster_testing_' + test_language + '.pkl'\n",
    "\n",
    "#create vocabulary and phone_to_idx\n",
    "phone_to_idx = create_vocabulary(train_file)\n",
    "print(len(phone_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_file, intent_labels, phone_to_idx)\n",
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=32)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args, collate_fn=collate_indic)\n",
    "\n",
    "test_dataset = MyDataset(test_file, intent_labels, phone_to_idx)\n",
    "test_loader_args = dict(shuffle=False, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "valid_loader = DataLoader(test_dataset, **test_loader_args, collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=63, embed_size=128, hidden_size=128, label_size=6):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "        self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(embed_size*3)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_size*3, hidden_size, num_layers=2)\n",
    "        self.linear = nn.Linear(hidden_size, label_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "\n",
    "        # B,T,H\n",
    "        input = self.embed(x)\n",
    "\n",
    "        # (B,T,H) -> (B,H,T)\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input), self.cnn3(input)], dim=1)\n",
    "\n",
    "        # (B,H,T)\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n",
    "\n",
    "        output, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        #output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        #output = torch.cat([hn[0], hn[1]], dim=1)\n",
    "        logits = self.linear(hn[0])\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNClassifier(\n",
       "  (embed): Embedding(63, 128)\n",
       "  (cnn): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (cnn2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (cnn3): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  (batchnorm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lstm): LSTM(384, 128, num_layers=2)\n",
       "  (linear): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNClassifier()\n",
    "opt = optim.Adam(model.parameters(), lr = 0.001)\n",
    "#opt = SGD(model.parameters(), lr=0.05)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hindi hindi\n",
      "train acc:  0.24600747536527354  train loss:  0.46741431044495624 --time: 2.0287442207336426\n",
      "validation:  0.18 --max 0.18 --time: 2.4200804233551025\n",
      "train acc:  0.30479102956167176  train loss:  0.42773039444633154 --time: 2.1660425662994385\n",
      "validation:  0.22 --max 0.22 --time: 2.4760851860046387\n",
      "train acc:  0.33367312266394833  train loss:  0.417949088241743 --time: 2.110436201095581\n",
      "validation:  0.23333333333333334 --max 0.23333333333333334 --time: 2.420358419418335\n",
      "train acc:  0.3550798504926945  train loss:  0.41224888614986255 --time: 2.1102778911590576\n",
      "validation:  0.25333333333333335 --max 0.25333333333333335 --time: 2.40234375\n",
      "train acc:  0.36765205572545023  train loss:  0.4032789002294126 --time: 1.2727978229522705\n",
      "validation:  0.2966666666666667 --max 0.2966666666666667 --time: 1.4712152481079102\n",
      "train acc:  0.43391097519537886  train loss:  0.3879574951918229 --time: 1.092165231704712\n",
      "validation:  0.35333333333333333 --max 0.35333333333333333 --time: 1.288442611694336\n",
      "train acc:  0.48997621474685693  train loss:  0.3654787825501483 --time: 1.1058220863342285\n",
      "validation:  0.44 --max 0.44 --time: 1.3018121719360352\n",
      "train acc:  0.5745837580699966  train loss:  0.3248482242874477 --time: 1.1147754192352295\n",
      "validation:  0.51 --max 0.51 --time: 1.3196935653686523\n",
      "train acc:  0.6768603465851172  train loss:  0.2780125652966292 --time: 1.1255955696105957\n",
      "validation:  0.6 --max 0.6 --time: 1.3244879245758057\n",
      "train acc:  0.7699626231736324  train loss:  0.22668598786644314 --time: 1.1054930686950684\n",
      "validation:  0.6866666666666666 --max 0.6866666666666666 --time: 1.3059818744659424\n",
      "train acc:  0.8154943934760448  train loss:  0.1836388260126114 --time: 1.0939123630523682\n",
      "validation:  0.7533333333333333 --max 0.7533333333333333 --time: 1.2881901264190674\n",
      "train acc:  0.8484539585457017  train loss:  0.15417398965877036 --time: 1.080902338027954\n",
      "validation:  0.7433333333333333 --max 0.7533333333333333 --time: 1.2799415588378906\n",
      "train acc:  0.8685015290519877  train loss:  0.12452603908984558 --time: 1.094926118850708\n",
      "validation:  0.7566666666666667 --max 0.7566666666666667 --time: 1.2906301021575928\n",
      "train acc:  0.8698606863744478  train loss:  0.12071360453315404 --time: 1.120176076889038\n",
      "validation:  0.76 --max 0.76 --time: 1.3224985599517822\n",
      "train acc:  0.9157322460074754  train loss:  0.08976765236128932 --time: 1.1077470779418945\n",
      "validation:  0.79 --max 0.79 --time: 1.3075535297393799\n",
      "train acc:  0.9170914033299354  train loss:  0.08787870536679807 --time: 1.0907669067382812\n",
      "validation:  0.8433333333333334 --max 0.8433333333333334 --time: 1.2857780456542969\n",
      "train acc:  0.945633707101597  train loss:  0.06828389009055884 --time: 1.0853509902954102\n",
      "validation:  0.84 --max 0.8433333333333334 --time: 1.2814691066741943\n",
      "train acc:  0.9531090723751274  train loss:  0.0568780471449313 --time: 1.0913381576538086\n",
      "validation:  0.8233333333333334 --max 0.8433333333333334 --time: 1.2905759811401367\n",
      "train acc:  0.963302752293578  train loss:  0.04894022756944532 --time: 1.088996410369873\n",
      "validation:  0.8533333333333334 --max 0.8533333333333334 --time: 1.2881379127502441\n",
      "train acc:  0.9690791709140333  train loss:  0.044017410796621574 --time: 1.0975589752197266\n",
      "validation:  0.8433333333333334 --max 0.8533333333333334 --time: 1.2906715869903564\n",
      "train acc:  0.9724770642201835  train loss:  0.03712199927996034 --time: 1.109541416168213\n",
      "validation:  0.8666666666666667 --max 0.8666666666666667 --time: 1.3048784732818604\n",
      "train acc:  0.9711179068977234  train loss:  0.03658638862164124 --time: 1.1054165363311768\n",
      "validation:  0.8533333333333334 --max 0.8666666666666667 --time: 1.304138422012329\n",
      "train acc:  0.9782534828406388  train loss:  0.029898245535466984 --time: 1.1186742782592773\n",
      "validation:  0.84 --max 0.8666666666666667 --time: 1.3112187385559082\n",
      "train acc:  0.9881073734284743  train loss:  0.023260039479836174 --time: 1.0901737213134766\n",
      "validation:  0.8833333333333333 --max 0.8833333333333333 --time: 1.2897651195526123\n",
      "train acc:  0.983010533469249  train loss:  0.02442025680742834 --time: 1.1003007888793945\n",
      "validation:  0.8666666666666667 --max 0.8833333333333333 --time: 1.2972047328948975\n",
      "train acc:  0.9904858987427795  train loss:  0.018934877143929833 --time: 2.2578186988830566\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 2.4897100925445557\n",
      "train acc:  0.9959225280326198  train loss:  0.011147619123854067 --time: 2.385310411453247\n",
      "validation:  0.8966666666666666 --max 0.8966666666666666 --time: 2.675168037414551\n",
      "train acc:  0.9986408426775399  train loss:  0.008764688877145882 --time: 2.3597493171691895\n",
      "validation:  0.8966666666666666 --max 0.8966666666666666 --time: 2.5911827087402344\n",
      "train acc:  0.9891267414203194  train loss:  0.01636874376107817 --time: 2.328178644180298\n",
      "validation:  0.86 --max 0.8966666666666666 --time: 2.5890800952911377\n",
      "train acc:  0.9932042133876996  train loss:  0.012142765295246372 --time: 2.3886942863464355\n",
      "validation:  0.87 --max 0.8966666666666666 --time: 2.6174445152282715\n",
      "train acc:  0.9945633707101597  train loss:  0.009934805151399063 --time: 2.3865585327148438\n",
      "validation:  0.7933333333333333 --max 0.8966666666666666 --time: 2.6307926177978516\n",
      "train acc:  0.9833503227998641  train loss:  0.02223862620556484 --time: 2.387260675430298\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.610443115234375\n",
      "train acc:  0.9976214746856948  train loss:  0.008652374209107264 --time: 2.3513834476470947\n",
      "validation:  0.8666666666666667 --max 0.8966666666666666 --time: 2.588430881500244\n",
      "train acc:  0.9966021066938499  train loss:  0.007295427337774764 --time: 2.3052804470062256\n",
      "validation:  0.8766666666666667 --max 0.8966666666666666 --time: 2.5485305786132812\n",
      "train acc:  0.9969418960244648  train loss:  0.008265263461710318 --time: 2.2766246795654297\n",
      "validation:  0.87 --max 0.8966666666666666 --time: 2.5099527835845947\n",
      "train acc:  0.9938837920489296  train loss:  0.010513980609729238 --time: 2.257227897644043\n",
      "validation:  0.86 --max 0.8966666666666666 --time: 2.4960882663726807\n",
      "train acc:  0.9945633707101597  train loss:  0.010886728723088036 --time: 2.2051303386688232\n",
      "validation:  0.87 --max 0.8966666666666666 --time: 2.430698871612549\n",
      "train acc:  0.9945633707101597  train loss:  0.009055051041524048 --time: 2.221186876296997\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.471834421157837\n",
      "train acc:  0.9942235813795447  train loss:  0.0087890081188601 --time: 2.211125373840332\n",
      "validation:  0.8966666666666666 --max 0.8966666666666666 --time: 2.4989535808563232\n",
      "train acc:  0.9938837920489296  train loss:  0.010473715394492383 --time: 2.1129250526428223\n",
      "validation:  0.8666666666666667 --max 0.8966666666666666 --time: 2.4247264862060547\n",
      "train acc:  0.9959225280326198  train loss:  0.007438123104688914 --time: 2.0454635620117188\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.3794806003570557\n",
      "train acc:  0.9925246347264696  train loss:  0.00878936552402118 --time: 2.0394084453582764\n",
      "validation:  0.8433333333333334 --max 0.8966666666666666 --time: 2.348275899887085\n",
      "train acc:  0.9904858987427795  train loss:  0.010702965598877357 --time: 2.0126380920410156\n",
      "validation:  0.8633333333333333 --max 0.8966666666666666 --time: 2.345407485961914\n",
      "train acc:  0.9901461094121644  train loss:  0.014583836755026941 --time: 2.0182015895843506\n",
      "validation:  0.8633333333333333 --max 0.8966666666666666 --time: 2.354386329650879\n",
      "train acc:  0.9904858987427795  train loss:  0.011116559607098285 --time: 2.0288009643554688\n",
      "validation:  0.89 --max 0.8966666666666666 --time: 2.38519287109375\n",
      "train acc:  0.9969418960244648  train loss:  0.004906515631338824 --time: 1.9709866046905518\n",
      "validation:  0.88 --max 0.8966666666666666 --time: 2.322495460510254\n",
      "train acc:  0.99932042133877  train loss:  0.002968373020058093 --time: 1.9602320194244385\n",
      "validation:  0.88 --max 0.8966666666666666 --time: 2.3081471920013428\n",
      "train acc:  0.9925246347264696  train loss:  0.009856579815159026 --time: 1.9471838474273682\n",
      "validation:  0.8633333333333333 --max 0.8966666666666666 --time: 2.2740566730499268\n",
      "train acc:  0.9989806320081549  train loss:  0.003180415167108826 --time: 1.9079420566558838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:  0.8933333333333333 --max 0.8966666666666666 --time: 2.2589197158813477\n",
      "train acc:  1.0  train loss:  0.0017502459434225507 --time: 1.8815481662750244\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.2236807346343994\n",
      "train acc:  1.0  train loss:  0.0015057730083556278 --time: 1.914846420288086\n",
      "validation:  0.89 --max 0.8966666666666666 --time: 2.256897211074829\n",
      "train acc:  1.0  train loss:  0.0013779641594737768 --time: 1.940354585647583\n",
      "validation:  0.89 --max 0.8966666666666666 --time: 2.2640249729156494\n",
      "train acc:  1.0  train loss:  0.0012873568389888692 --time: 1.924726963043213\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.2799577713012695\n",
      "train acc:  1.0  train loss:  0.0012093273993662517 --time: 1.9049577713012695\n",
      "validation:  0.8933333333333333 --max 0.8966666666666666 --time: 2.245577096939087\n",
      "train acc:  1.0  train loss:  0.0011409355135148635 --time: 1.900207281112671\n",
      "validation:  0.89 --max 0.8966666666666666 --time: 2.24041748046875\n",
      "train acc:  1.0  train loss:  0.001090436396897649 --time: 1.9342515468597412\n",
      "validation:  0.89 --max 0.8966666666666666 --time: 2.2731428146362305\n",
      "train acc:  1.0  train loss:  0.0010485014341690619 --time: 1.9077107906341553\n",
      "validation:  0.89 --max 0.8966666666666666 --time: 2.254591464996338\n",
      "train acc:  1.0  train loss:  0.0009998044191414247 --time: 2.0664072036743164\n",
      "validation:  0.89 --max 0.8966666666666666 --time: 2.3989813327789307\n",
      "train acc:  1.0  train loss:  0.0009638227157942627 --time: 2.088488817214966\n",
      "validation:  0.8933333333333333 --max 0.8966666666666666 --time: 2.4453227519989014\n",
      "train acc:  1.0  train loss:  0.0009223466420181743 --time: 2.160151481628418\n",
      "validation:  0.8933333333333333 --max 0.8966666666666666 --time: 2.4317522048950195\n",
      "train acc:  1.0  train loss:  0.0008871470016184385 --time: 2.1468427181243896\n",
      "validation:  0.8933333333333333 --max 0.8966666666666666 --time: 2.4529237747192383\n",
      "train acc:  1.0  train loss:  0.0008561185475074402 --time: 2.1661527156829834\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.4088754653930664\n",
      "train acc:  0.9925246347264696  train loss:  0.007969972060021499 --time: 2.25703763961792\n",
      "validation:  0.8566666666666667 --max 0.8966666666666666 --time: 2.4850239753723145\n",
      "train acc:  0.963982330954808  train loss:  0.036129751607127815 --time: 2.2962448596954346\n",
      "validation:  0.8266666666666667 --max 0.8966666666666666 --time: 2.5320277214050293\n",
      "train acc:  0.9898063200815495  train loss:  0.014092192640933006 --time: 2.2962350845336914\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.526653289794922\n",
      "train acc:  0.9966021066938499  train loss:  0.006181966553887595 --time: 2.3538100719451904\n",
      "validation:  0.8766666666666667 --max 0.8966666666666666 --time: 2.6284890174865723\n",
      "train acc:  0.99932042133877  train loss:  0.002295344693424261 --time: 2.454423189163208\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.7445640563964844\n",
      "train acc:  0.9996602106693849  train loss:  0.0015566077225072229 --time: 2.355952024459839\n",
      "validation:  0.8766666666666667 --max 0.8966666666666666 --time: 2.6379506587982178\n",
      "train acc:  0.9989806320081549  train loss:  0.0018076196277473607 --time: 2.353658437728882\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.65151309967041\n",
      "train acc:  1.0  train loss:  0.0010985882912317047 --time: 2.37424635887146\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.609114170074463\n",
      "train acc:  1.0  train loss:  0.0009368127490312833 --time: 2.314743757247925\n",
      "validation:  0.89 --max 0.8966666666666666 --time: 2.5948894023895264\n",
      "train acc:  1.0  train loss:  0.0008556493912297099 --time: 2.340784788131714\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.582597255706787\n",
      "train acc:  1.0  train loss:  0.0007945082514830258 --time: 2.282038927078247\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.5247905254364014\n",
      "train acc:  1.0  train loss:  0.0007407202603011999 --time: 2.2882988452911377\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.5190393924713135\n",
      "train acc:  1.0  train loss:  0.0007034402198927558 --time: 2.248676300048828\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.4769492149353027\n",
      "train acc:  1.0  train loss:  0.0006713489672857459 --time: 2.2455074787139893\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.4908719062805176\n",
      "train acc:  1.0  train loss:  0.0006450187141561638 --time: 2.2174487113952637\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.4509239196777344\n",
      "train acc:  1.0  train loss:  0.0006222041657842371 --time: 2.1794121265411377\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.4355216026306152\n",
      "train acc:  1.0  train loss:  0.0005966718485781356 --time: 2.1440110206604004\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.4242184162139893\n",
      "train acc:  1.0  train loss:  0.00057886023853865 --time: 2.1636276245117188\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.435931444168091\n",
      "train acc:  1.0  train loss:  0.0005607467724273548 --time: 2.159625768661499\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.487307548522949\n",
      "train acc:  1.0  train loss:  0.000541118143187107 --time: 2.051934003829956\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.40189266204834\n",
      "train acc:  1.0  train loss:  0.0005145699226135469 --time: 2.0079712867736816\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.346935987472534\n",
      "train acc:  1.0  train loss:  0.0004977999614430187 --time: 1.971412181854248\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.3100216388702393\n",
      "train acc:  1.0  train loss:  0.0004787975226265743 --time: 1.9623339176177979\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.286001443862915\n",
      "train acc:  1.0  train loss:  0.00046309918853575766 --time: 1.9072256088256836\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.24893856048584\n",
      "train acc:  1.0  train loss:  0.0004493630017943518 --time: 1.8480901718139648\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.1814730167388916\n",
      "train acc:  1.0  train loss:  0.0004347316179242309 --time: 1.9434244632720947\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.274005889892578\n",
      "train acc:  1.0  train loss:  0.00042485030691908753 --time: 1.8848001956939697\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.2324421405792236\n",
      "train acc:  1.0  train loss:  0.0004123367847490084 --time: 1.908729076385498\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.257645845413208\n",
      "train acc:  1.0  train loss:  0.0004044438373175976 --time: 1.9652435779571533\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.302135705947876\n",
      "train acc:  1.0  train loss:  0.00039091558226019794 --time: 1.9501073360443115\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.2900619506835938\n",
      "train acc:  1.0  train loss:  0.00038267745074573094 --time: 1.9235239028930664\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.2379937171936035\n",
      "train acc:  1.0  train loss:  0.00037342501783986455 --time: 2.0166916847229004\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.341078519821167\n",
      "train acc:  1.0  train loss:  0.0003632126697440348 --time: 2.123004913330078\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.4570775032043457\n",
      "train acc:  1.0  train loss:  0.00035512066350075537 --time: 2.1220779418945312\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.4145891666412354\n",
      "train acc:  1.0  train loss:  0.000348106914948996 --time: 2.164104461669922\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.3924410343170166\n",
      "train acc:  1.0  train loss:  0.0003403731249778977 --time: 2.1777913570404053\n",
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.3907721042633057\n",
      "train acc:  1.0  train loss:  0.000331684286483442 --time: 2.196838140487671\n",
      "validation:  0.8866666666666667 --max 0.8966666666666666 --time: 2.4369494915008545\n",
      "train acc:  1.0  train loss:  0.0003226814619467958 --time: 2.2368991374969482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:  0.8833333333333333 --max 0.8966666666666666 --time: 2.4648406505584717\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5aab3af95490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss_accum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mbatch_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(train_language, test_language)\n",
    "max_acc = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    #print(\"epoch \", i)\n",
    "    loss_accum = 0.0\n",
    "    batch_cnt = 0\n",
    "\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch, (x, lengths, y) in enumerate(train_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "        loss_score = loss.cpu().item()\n",
    "\n",
    "        loss_accum += loss_score\n",
    "        batch_cnt += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        target_val, tar_indices = torch.max(y, dim=1)\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    print(\"train acc: \", acc_cnt/(err_cnt+acc_cnt), \" train loss: \", loss_accum / batch_cnt, '--time:', time.time() - start_time)\n",
    "\n",
    "    model.eval()\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    #start_time = time.time()\n",
    "    for x, lengths, y in valid_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        target_val, tar_indices = torch.max(y, dim=1)\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    current_acc = acc_cnt/(err_cnt+acc_cnt)\n",
    "    if current_acc > max_acc:\n",
    "        max_acc = current_acc\n",
    "                \n",
    "    print(\"validation: \", current_acc, '--max', max_acc, '--time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
