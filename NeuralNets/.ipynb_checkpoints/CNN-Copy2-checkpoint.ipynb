{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import psutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/ubuntu/Intents/Intents-Analysis/Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_vocab import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is True\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining constants and labels\n",
    "max_sent_len = {'english': 247, 'hindi': 265, 'gujarati': 283, 'bengali': 295, 'marathi': 307}\n",
    "intent_labels = {'movie-tickets':0, 'auto-repair':1, 'restaurant-table':2, 'pizza-ordering':3, 'uber-lyft':4, 'coffee-ordering':5}\n",
    "language = 'english'\n",
    "\n",
    "#Loading data\n",
    "train_file = '../Analysis/Labels/TaskMaster/taskmaster_training_' + language + '.pkl'\n",
    "test_file = '../Analysis/Labels/TaskMaster/taskmaster_testing_' + language + '.pkl'\n",
    "feature_file = '../Analysis/Labels/TaskMaster/panphon_features_' + language + '.pkl'\n",
    "\n",
    "train_data = load_data(train_file)\n",
    "test_data = load_data(test_file)\n",
    "feature_vectors = load_data(feature_file)\n",
    "\n",
    "\n",
    "#Add vector for padding, converting feature vectors to float tensors. \n",
    "size_of_feature_vector = 22\n",
    "feature_vectors['unk'] = np.zeros(size_of_feature_vector)\n",
    "for ipa in feature_vectors:\n",
    "    feature_vectors[ipa] = torch.from_numpy(feature_vectors[ipa]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_vector(utterance, feature_vectors, max_len):\n",
    "    '''\n",
    "    Pad sentence at the end with maximum length with 'unk' \n",
    "    '''\n",
    "    input_vector = feature_vectors[utterance[0]].reshape(-1,1)\n",
    "    for ipa in utterance[1:]:\n",
    "        input_vector = torch.cat((input_vector, feature_vectors[ipa].reshape(-1,1)), dim = 1)\n",
    "    \n",
    "    for i in range(max_len - len(utterance)):\n",
    "        input_vector = torch.cat((input_vector, feature_vectors['unk'].reshape(-1,1)), dim = 1)\n",
    "        \n",
    "    return input_vector\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, feature_vectors, intent_labels, max_len, train = True):\n",
    "        self.all_data = []\n",
    "        for intent in data:\n",
    "            for utterance in data[intent]:\n",
    "                input_vector = create_input_vector(utterance,feature_vectors, max_len)\n",
    "                self.all_data.append([input_vector, intent_labels[intent]])\n",
    "        \n",
    "        if train:\n",
    "            random.shuffle(self.all_data)\n",
    "\n",
    "        self.dim1 = self.all_data[0][0].shape[0]\n",
    "        self.dim2 = self.all_data[0][0].shape[1]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        \n",
    "        return self.all_data[index][0].reshape(1, self.dim1, self.dim2 ), self.all_data[index][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_data, feature_vectors, intent_labels, max_sent_len[language], train=True)\n",
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=32)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args)\n",
    "\n",
    "test_dataset = MyDataset(test_data, feature_vectors, intent_labels, max_sent_len[language], train=False)\n",
    "test_loader_args = dict(shuffle=False, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "test_loader = DataLoader(test_dataset, **test_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([128, 1, 22, 247])\n",
      "torch.Size([127, 1, 22, 247])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, (1,3)) # (22,245) 265\n",
    "        self.pool1 = nn.MaxPool2d( kernel_size = (1,3), stride = (1,2)) #(22, 122) 132\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, (3,7)) # (20,116) 126\n",
    "        self.pool2 = nn.MaxPool2d( kernel_size = (3,4), stride = (1,2)) #(18, 57) 63\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 32, (5,11)) # (14, 47) 53\n",
    "        self.pool3 = nn.MaxPool2d( kernel_size = (3,5), stride = (1,2)) #(12, 22) 25\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 12 * 22, 512)\n",
    "        self.fc1_bn = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.fc2_bn = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 6)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        \n",
    "        x = x.view(-1, 32 *12 * 22)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNN_Model(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 7), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 4), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 32, kernel_size=(5, 11), stride=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 5), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=8448, out_features=512, bias=True)\n",
      "  (fc1_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (fc2_bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=64, out_features=6, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyCNN_Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
    "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
    "        data = data.to(device)\n",
    "        target = target.to(device) # all data & model on same device\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += target.size(0)\n",
    "        correct_predictions += (predicted == target).sum().item()\n",
    "    \n",
    "            \n",
    "    end_time = time.time()\n",
    "    \n",
    "    acc = (correct_predictions/total_predictions)*100.0\n",
    "    running_loss /= len(train_loader)\n",
    "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')  \n",
    "    print('Training Accuracy: ', acc, '%')\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):   \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "        running_loss /= len(test_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('Testing Loss: ', running_loss)\n",
    "        print('Testing Accuracy: ', acc, '%')\n",
    "        return running_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  1.7877519286197165 Time:  2.890486717224121 s\n",
      "Training Accuracy:  21.032959565069657 %\n",
      "Testing Loss:  1.9195574124654133\n",
      "Testing Accuracy:  22.666666666666664 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  1.6676931484885837 Time:  2.558720111846924 s\n",
      "Training Accuracy:  34.21678559293238 %\n",
      "Testing Loss:  1.8207782904307048\n",
      "Testing Accuracy:  27.666666666666668 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  1.5722906174867048 Time:  2.574145793914795 s\n",
      "Training Accuracy:  37.78457356439008 %\n",
      "Testing Loss:  1.8348263104756672\n",
      "Testing Accuracy:  29.333333333333332 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  1.4503602359605872 Time:  2.577073335647583 s\n",
      "Training Accuracy:  42.50764525993883 %\n",
      "Testing Loss:  1.7319352229436238\n",
      "Testing Accuracy:  35.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  1.3208843003148618 Time:  2.582756519317627 s\n",
      "Training Accuracy:  47.43459055385661 %\n",
      "Testing Loss:  1.5971167882283528\n",
      "Testing Accuracy:  42.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  1.19408641172492 Time:  2.6070730686187744 s\n",
      "Training Accuracy:  53.14305130818893 %\n",
      "Testing Loss:  1.454981009165446\n",
      "Testing Accuracy:  50.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  1.0949257016181946 Time:  2.5938427448272705 s\n",
      "Training Accuracy:  59.12334352701325 %\n",
      "Testing Loss:  1.3504622379938762\n",
      "Testing Accuracy:  56.333333333333336 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  0.9295295010442319 Time:  2.58646821975708 s\n",
      "Training Accuracy:  64.35609921848454 %\n",
      "Testing Loss:  1.1811556021372478\n",
      "Testing Accuracy:  59.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  0.8713852270789768 Time:  2.5879762172698975 s\n",
      "Training Accuracy:  66.39483520217465 %\n",
      "Testing Loss:  1.0051851272583008\n",
      "Testing Accuracy:  60.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  0.7696607086969458 Time:  2.621567487716675 s\n",
      "Training Accuracy:  70.47230716955487 %\n",
      "Testing Loss:  0.9972312450408936\n",
      "Testing Accuracy:  63.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  0.6953647395838862 Time:  2.611386775970459 s\n",
      "Training Accuracy:  72.81685355079851 %\n",
      "Testing Loss:  1.009046494960785\n",
      "Testing Accuracy:  65.66666666666666 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  0.6448975412741952 Time:  2.605750560760498 s\n",
      "Training Accuracy:  74.78763166836562 %\n",
      "Testing Loss:  0.8608733415603638\n",
      "Testing Accuracy:  67.66666666666666 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  0.6047589442004329 Time:  2.6283440589904785 s\n",
      "Training Accuracy:  75.94291539245668 %\n",
      "Testing Loss:  1.0640380382537842\n",
      "Testing Accuracy:  66.0 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  0.5898351565651272 Time:  2.6401116847991943 s\n",
      "Training Accuracy:  76.65647298674821 %\n",
      "Testing Loss:  0.904247373342514\n",
      "Testing Accuracy:  70.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  0.55365891041963 Time:  2.6206862926483154 s\n",
      "Training Accuracy:  77.84573564390078 %\n",
      "Testing Loss:  0.7487640380859375\n",
      "Testing Accuracy:  72.33333333333334 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  0.5288887386736663 Time:  2.645193576812744 s\n",
      "Training Accuracy:  79.44274549779136 %\n",
      "Testing Loss:  0.8494463562965393\n",
      "Testing Accuracy:  73.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n",
      "Training Loss:  0.5033661062302797 Time:  4.498445272445679 s\n",
      "Training Accuracy:  80.49609242269793 %\n",
      "Testing Loss:  1.19723845521609\n",
      "Testing Accuracy:  68.66666666666667 %\n",
      "Learning rate: 0.001\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "Train_loss = []\n",
    "Test_loss = []\n",
    "Test_acc = []\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, cooldown=5)\n",
    "\n",
    "for i in range(50):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = test_model(model, test_loader, criterion)\n",
    "    Train_loss.append(train_loss)\n",
    "    Test_loss.append(test_loss)\n",
    "    Test_acc.append(test_acc)\n",
    "\n",
    "    scheduler.step(test_acc)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print('Learning rate:', param_group['lr'])\n",
    "    \n",
    "\n",
    "    print('='*20)\n",
    "    \n",
    "print(max(Test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
