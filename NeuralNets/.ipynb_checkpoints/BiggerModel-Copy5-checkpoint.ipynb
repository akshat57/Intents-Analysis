{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import psutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/ubuntu/Intents-Analysis/Analysis')\n",
    "#sys.path.insert(1, '/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_vocab import load_data, get_vocab\n",
    "from get_frequency import get_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is True\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Needed Functions\n",
    "def load_data(filename):\n",
    "    a_file = open(filename, \"rb\")\n",
    "    output = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_vocabulary(train_file):\n",
    "    '''This function creates an indexed vocabulary dictionary from the training file'''\n",
    "    \n",
    "    vocab, _ = get_vocab(1, train_file)\n",
    "    \n",
    "    phone_to_idx = {'unk': 1}#Padding indx = 0, unkown_idx = 1, indexing starts from 2\n",
    "    for i, phone in enumerate(vocab):\n",
    "        phone_to_idx[phone] = i + 2\n",
    "        \n",
    "    return phone_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_file, intent_labels, phone_to_idx):\n",
    "        data = load_data(data_file)\n",
    "        self.all_data = []\n",
    "        \n",
    "        for intent in data:\n",
    "            for utterance in data[intent]:\n",
    "                if len(utterance) != 0:\n",
    "                    utterance_to_idx = []\n",
    "\n",
    "                    for phone in utterance:\n",
    "                        if phone not in phone_to_idx:\n",
    "                            phone = 'unk'\n",
    "\n",
    "                        utterance_to_idx.append(phone_to_idx[phone])\n",
    "\n",
    "                    self.all_data.append([utterance_to_idx, intent_labels[intent]])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        input_vector = self.all_data[index][0]\n",
    "        label = self.all_data[index][1]\n",
    "\n",
    "        return input_vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_indic(tuple_lst):\n",
    "\n",
    "    x_lst = [x[0] for x in tuple_lst]\n",
    "    y_lst = [x[1] for x in tuple_lst]\n",
    "\n",
    "    # collate x\n",
    "    B = len(tuple_lst)#Number of training samples\n",
    "    T = max(len(x) for x in x_lst)#Max length of a sentence\n",
    "\n",
    "    # x values\n",
    "    x = torch.zeros([B, T], dtype=torch.int64)\n",
    "    lengths = torch.zeros(B, dtype=torch.int64)\n",
    "\n",
    "    for i, x_np in enumerate(x_lst):\n",
    "        lengths[i] = len(x_np)\n",
    "        x[i,:len(x_np)] = torch.tensor(x_np)\n",
    "\n",
    "    # collate y\n",
    "    y = torch.tensor(y_lst)\n",
    "\n",
    "    ids = torch.argsort(lengths, descending=True)\n",
    "\n",
    "    return x[ids], lengths[ids], y[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domains():\n",
    "    all_intents = ['increase', 'decrease', 'activate', 'deactivate', 'bring', 'change language']\n",
    "    return all_intents\n",
    "\n",
    "def get_intents():\n",
    "    all_intents = [\n",
    "        'activate|lamp',\n",
    "        'activate|lights|bedroom',\n",
    "        'activate|lights|kitchen',\n",
    "        'activate|lights|none',\n",
    "        'activate|lights|washroom',\n",
    "        'activate|music',\n",
    "        'bring|juice',\n",
    "        'bring|newspaper',\n",
    "        'bring|shoes',\n",
    "        'bring|socks',\n",
    "        'change language|Chinese',\n",
    "        'change language|English',\n",
    "        'change language|German',\n",
    "        'change language|Korean',\n",
    "        'change language|none',\n",
    "        'deactivate|lamp',\n",
    "        'deactivate|lights|bedroom',\n",
    "        'deactivate|lights|kitchen',\n",
    "        'deactivate|lights|none',\n",
    "        'deactivate|lights|washroom',\n",
    "        'deactivate|music',\n",
    "        'decrease|heat|bedroom',\n",
    "        'decrease|heat|kitchen',\n",
    "        'decrease|heat|none',\n",
    "        'decrease|heat|washroom',\n",
    "        'decrease|volume',\n",
    "        'increase|heat|bedroom',\n",
    "        'increase|heat|kitchen',\n",
    "        'increase|heat|none',\n",
    "        'increase|heat|washroom',\n",
    "        'increase|volume'\n",
    "        ]\n",
    "\n",
    "    return all_intents\n",
    "\n",
    "def get_intent_labels(class_type):\n",
    "    if class_type == 'domain':\n",
    "        all_intents = get_domains()\n",
    "    else:\n",
    "        all_intents = get_intents()\n",
    "        \n",
    "    intent_labels = {}\n",
    "    labels_to_intents = {}\n",
    "    for i, intent in enumerate(all_intents):\n",
    "        intent_labels[intent] = i\n",
    "        labels_to_intents[i] = intent\n",
    "        \n",
    "    return intent_labels, labels_to_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "class_type = 'domain'\n",
    "split = 'train'\n",
    "\n",
    "intent_labels, labels_to_intents = get_intent_labels(class_type)\n",
    "\n",
    "#Loading data\n",
    "train_file = '../FSC/fsc_' + class_type + '_' + split + '.pkl'\n",
    "test_file = '../FSC/fsc_' + class_type + '_test.pkl'\n",
    "#create vocabulary and phone_to_idx\n",
    "phone_to_idx = create_vocabulary(train_file)\n",
    "print(len(phone_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_file, intent_labels, phone_to_idx)\n",
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=32)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args, collate_fn=collate_indic)\n",
    "\n",
    "test_dataset = MyDataset(test_file, intent_labels, phone_to_idx)\n",
    "test_loader_args = dict(shuffle=False, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "valid_loader = DataLoader(test_dataset, **test_loader_args, collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=50, embed_size=128, hidden_size=256, label_size=6):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "        self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(embed_size*3)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_size*3, hidden_size, num_layers=1)\n",
    "        self.linear = nn.Linear(hidden_size, label_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "\n",
    "        # B,T,H\n",
    "        input = self.embed(x)\n",
    "\n",
    "        # (B,T,H) -> (B,H,T)\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input), self.cnn3(input)], dim=1)\n",
    "\n",
    "        # (B,H,T)\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "        #input = F.relu(cnn_output)\n",
    "        \n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n",
    "\n",
    "        output, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        #output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        #output = torch.cat([hn[0], hn[1]], dim=1)\n",
    "        logits = self.linear(hn[0])\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNClassifier(\n",
       "  (embed): Embedding(50, 128)\n",
       "  (cnn): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (cnn2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (cnn3): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  (batchnorm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lstm): LSTM(384, 256)\n",
       "  (linear): Linear(in_features=256, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNClassifier()\n",
    "opt = optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#opt = SGD(model.parameters(), lr=0.05)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain train\n",
      "train acc:  0.691708836123005  train loss:  0.7746658501374787 --time: 9.994140148162842\n",
      "0 validation:  0.8610232067510548 --max 0.8610232067510548 --time: 11.299210786819458\n",
      "train acc:  0.8612949266900221  train loss:  0.37348957450350345 --time: 9.742955684661865\n",
      "1 validation:  0.9055907172995781 --max 0.9055907172995781 --time: 11.040213108062744\n",
      "train acc:  0.9016911033259807  train loss:  0.2671281330246293 --time: 9.651448249816895\n",
      "2 validation:  0.9171940928270043 --max 0.9171940928270043 --time: 11.165040493011475\n",
      "train acc:  0.9257385061199775  train loss:  0.20322960158244022 --time: 9.593721628189087\n",
      "3 validation:  0.9309071729957806 --max 0.9309071729957806 --time: 11.14086389541626\n",
      "train acc:  0.9435145538687773  train loss:  0.15632598688671603 --time: 9.433641910552979\n",
      "4 validation:  0.9301160337552743 --max 0.9309071729957806 --time: 10.959903717041016\n",
      "train acc:  0.9598200769862896  train loss:  0.11728271201911553 --time: 9.450295209884644\n",
      "5 validation:  0.9356540084388185 --max 0.9356540084388185 --time: 10.95410442352295\n",
      "train acc:  0.9678214610094719  train loss:  0.09049359017478827 --time: 9.556076288223267\n",
      "6 validation:  0.9385548523206751 --max 0.9385548523206751 --time: 11.08965015411377\n",
      "train acc:  0.9724492885255828  train loss:  0.07895483791786992 --time: 9.48767614364624\n",
      "7 validation:  0.930379746835443 --max 0.9385548523206751 --time: 11.019654989242554\n",
      "train acc:  0.9756498421348557  train loss:  0.06685436564852684 --time: 9.545665502548218\n",
      "8 validation:  0.935126582278481 --max 0.9385548523206751 --time: 11.08081316947937\n",
      "train acc:  0.9827429609445958  train loss:  0.048365379091949094 --time: 9.579641580581665\n",
      "9 validation:  0.9343354430379747 --max 0.9385548523206751 --time: 11.098738193511963\n",
      "train acc:  0.9853380044115739  train loss:  0.041941560740526046 --time: 9.45796513557434\n",
      "10 validation:  0.9324894514767933 --max 0.9385548523206751 --time: 10.995039224624634\n",
      "train acc:  0.9839972319536352  train loss:  0.04499988829284824 --time: 9.650491952896118\n",
      "11 validation:  0.9264240506329114 --max 0.9385548523206751 --time: 11.192673683166504\n",
      "train acc:  0.9871977855629082  train loss:  0.03672123561968296 --time: 9.596768617630005\n",
      "12 validation:  0.929324894514768 --max 0.9385548523206751 --time: 11.118251323699951\n",
      "train acc:  0.9887115609186454  train loss:  0.03320481974466894 --time: 9.476471662521362\n",
      "13 validation:  0.9309071729957806 --max 0.9385548523206751 --time: 10.997812032699585\n",
      "train acc:  0.9923878724968643  train loss:  0.022274722675767147 --time: 9.685147762298584\n",
      "14 validation:  0.9380274261603375 --max 0.9385548523206751 --time: 11.190571069717407\n",
      "train acc:  0.9951126681371913  train loss:  0.015641343804302713 --time: 9.642644166946411\n",
      "15 validation:  0.9335443037974683 --max 0.9385548523206751 --time: 11.17897629737854\n",
      "train acc:  0.9938583971281519  train loss:  0.01929792034239071 --time: 9.739728450775146\n",
      "16 validation:  0.9309071729957806 --max 0.9385548523206751 --time: 11.25695276260376\n",
      "train acc:  0.9912633536611738  train loss:  0.025777443818933234 --time: 9.567670822143555\n",
      "17 validation:  0.9311708860759493 --max 0.9385548523206751 --time: 10.236041784286499\n",
      "train acc:  0.9922148695990658  train loss:  0.02276210378320342 --time: 10.179014921188354\n",
      "18 validation:  0.9301160337552743 --max 0.9385548523206751 --time: 11.319941520690918\n",
      "train acc:  0.9937718956792526  train loss:  0.019292345244787346 --time: 8.173543930053711\n",
      "19 validation:  0.929324894514768 --max 0.9385548523206751 --time: 8.998217582702637\n",
      "train acc:  0.994204402923749  train loss:  0.017199736779288117 --time: 6.674997806549072\n",
      "20 validation:  0.9332805907172996 --max 0.9385548523206751 --time: 7.482021808624268\n",
      "train acc:  0.9906145927944293  train loss:  0.02712060130993676 --time: 6.682655096054077\n",
      "21 validation:  0.9309071729957806 --max 0.9385548523206751 --time: 7.523863792419434\n",
      "train acc:  0.9922148695990658  train loss:  0.023118974761883033 --time: 6.6875996589660645\n",
      "22 validation:  0.9274789029535865 --max 0.9385548523206751 --time: 7.529176712036133\n",
      "train acc:  0.9951559188616409  train loss:  0.015773595760329447 --time: 6.705133438110352\n",
      "23 validation:  0.9372362869198312 --max 0.9385548523206751 --time: 7.5857253074646\n",
      "train acc:  0.9947234116171446  train loss:  0.014716636399624004 --time: 6.693532228469849\n",
      "24 validation:  0.9258966244725738 --max 0.9385548523206751 --time: 7.630784273147583\n",
      "train acc:  0.9922148695990658  train loss:  0.023552582957794714 --time: 6.648886442184448\n",
      "25 validation:  0.9390822784810127 --max 0.9390822784810127 --time: 7.562368154525757\n",
      "train acc:  0.9898360797543359  train loss:  0.026295062123658907 --time: 6.668548107147217\n",
      "26 validation:  0.931698312236287 --max 0.9390822784810127 --time: 7.636004447937012\n",
      "train acc:  0.9945504087193461  train loss:  0.01611565515297357 --time: 6.665672302246094\n",
      "27 validation:  0.9377637130801688 --max 0.9390822784810127 --time: 7.641107797622681\n",
      "train acc:  0.9979239652264176  train loss:  0.0068939307657776665 --time: 6.719427108764648\n",
      "28 validation:  0.9340717299578059 --max 0.9390822784810127 --time: 7.721260070800781\n",
      "train acc:  0.9981402188486657  train loss:  0.004797735599365512 --time: 6.6988654136657715\n",
      "29 validation:  0.9319620253164557 --max 0.9390822784810127 --time: 7.7149810791015625\n",
      "train acc:  0.9983132217464643  train loss:  0.004855838079638689 --time: 6.654707670211792\n",
      "30 validation:  0.9404008438818565 --max 0.9404008438818565 --time: 7.607025623321533\n",
      "train acc:  0.9986592275420614  train loss:  0.003528250096824396 --time: 6.683248519897461\n",
      "31 validation:  0.9411919831223629 --max 0.9411919831223629 --time: 7.660144329071045\n",
      "train acc:  0.998226720297565  train loss:  0.0035427560389547762 --time: 6.612840890884399\n",
      "32 validation:  0.9419831223628692 --max 0.9419831223628692 --time: 7.593340158462524\n",
      "train acc:  0.9983997231953635  train loss:  0.003291964368502036 --time: 6.669515609741211\n",
      "33 validation:  0.9382911392405063 --max 0.9419831223628692 --time: 7.666574716567993\n",
      "train acc:  0.9983564724709139  train loss:  0.0036260043087178065 --time: 6.669882535934448\n",
      "34 validation:  0.9396097046413502 --max 0.9419831223628692 --time: 7.667062044143677\n",
      "train acc:  0.9986592275420614  train loss:  0.002986018605339238 --time: 6.623346328735352\n",
      "35 validation:  0.9409282700421941 --max 0.9419831223628692 --time: 7.6247663497924805\n",
      "train acc:  0.9986159768176117  train loss:  0.003101350924190525 --time: 6.57803750038147\n",
      "36 validation:  0.9377637130801688 --max 0.9419831223628692 --time: 7.5542638301849365\n",
      "train acc:  0.9984862246442628  train loss:  0.0031044368305483457 --time: 6.651065826416016\n",
      "37 validation:  0.9404008438818565 --max 0.9419831223628692 --time: 7.618466377258301\n",
      "train acc:  0.9984429739198132  train loss:  0.0033236644874363548 --time: 6.66920018196106\n",
      "38 validation:  0.9390822784810127 --max 0.9419831223628692 --time: 7.602195978164673\n",
      "train acc:  0.9986159768176117  train loss:  0.0031241142995046445 --time: 6.698497295379639\n",
      "39 validation:  0.9411919831223629 --max 0.9419831223628692 --time: 7.69352388381958\n",
      "train acc:  0.9984862246442628  train loss:  0.0031355086734570826 --time: 6.642071962356567\n",
      "40 validation:  0.9409282700421941 --max 0.9419831223628692 --time: 7.648841619491577\n",
      "train acc:  0.9987889797154103  train loss:  0.0027776581904396976 --time: 6.661756277084351\n",
      "41 validation:  0.9396097046413502 --max 0.9419831223628692 --time: 7.6569037437438965\n",
      "train acc:  0.9984862246442628  train loss:  0.003002126034280383 --time: 6.690483808517456\n",
      "42 validation:  0.939873417721519 --max 0.9419831223628692 --time: 7.706664323806763\n",
      "train acc:  0.9986592275420614  train loss:  0.0029152002221983003 --time: 6.652862548828125\n",
      "43 validation:  0.9396097046413502 --max 0.9419831223628692 --time: 7.642847061157227\n",
      "train acc:  0.9985294753687124  train loss:  0.002916898284472772 --time: 6.625125408172607\n",
      "44 validation:  0.9409282700421941 --max 0.9419831223628692 --time: 7.570026159286499\n",
      "train acc:  0.9985294753687124  train loss:  0.002927389299516384 --time: 6.678627967834473\n",
      "45 validation:  0.9438291139240507 --max 0.9438291139240507 --time: 7.596817970275879\n",
      "train acc:  0.9984862246442628  train loss:  0.002850104776823389 --time: 6.667450904846191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 validation:  0.9427742616033755 --max 0.9438291139240507 --time: 7.567822456359863\n",
      "train acc:  0.9987889797154103  train loss:  0.002681533191046769 --time: 6.7106804847717285\n",
      "47 validation:  0.9417194092827004 --max 0.9438291139240507 --time: 7.652398347854614\n",
      "train acc:  0.9984862246442628  train loss:  0.0028666384339242376 --time: 6.590258359909058\n",
      "48 validation:  0.9401371308016878 --max 0.9438291139240507 --time: 7.545629978179932\n",
      "train acc:  0.9913498551100731  train loss:  0.025680331579311936 --time: 6.647367715835571\n",
      "49 validation:  0.895042194092827 --max 0.9438291139240507 --time: 7.918487548828125\n",
      "train acc:  0.9490073958738808  train loss:  0.14340995461036815 --time: 9.751025199890137\n",
      "50 validation:  0.9338080168776371 --max 0.9438291139240507 --time: 10.357525110244751\n",
      "train acc:  0.990657843518879  train loss:  0.02854111268781949 --time: 10.054054737091064\n",
      "51 validation:  0.9396097046413502 --max 0.9438291139240507 --time: 11.05779242515564\n",
      "train acc:  0.9970589507374249  train loss:  0.009562190426565007 --time: 10.368094682693481\n",
      "52 validation:  0.9411919831223629 --max 0.9438291139240507 --time: 11.428930521011353\n",
      "train acc:  0.9971887029107738  train loss:  0.008751446428806495 --time: 10.149936437606812\n",
      "53 validation:  0.939873417721519 --max 0.9438291139240507 --time: 11.424219846725464\n",
      "train acc:  0.9977942130530686  train loss:  0.006183908344278606 --time: 10.015209436416626\n",
      "54 validation:  0.9372362869198312 --max 0.9438291139240507 --time: 11.293190240859985\n",
      "train acc:  0.9966696942173782  train loss:  0.009248999886160706 --time: 10.112041234970093\n",
      "55 validation:  0.9380274261603375 --max 0.9438291139240507 --time: 11.463013648986816\n",
      "train acc:  0.9977942130530686  train loss:  0.006871969975017845 --time: 9.968355178833008\n",
      "56 validation:  0.9348628691983122 --max 0.9438291139240507 --time: 11.29650330543518\n",
      "train acc:  0.9962804376973314  train loss:  0.011179841705276347 --time: 9.91616415977478\n",
      "57 validation:  0.932753164556962 --max 0.9438291139240507 --time: 11.254914045333862\n",
      "train acc:  0.9952424203105402  train loss:  0.013752503153348332 --time: 9.920976400375366\n",
      "58 validation:  0.9311708860759493 --max 0.9438291139240507 --time: 11.264889001846313\n",
      "train acc:  0.9954154232083388  train loss:  0.014027654955669136 --time: 9.855045795440674\n",
      "59 validation:  0.9264240506329114 --max 0.9438291139240507 --time: 11.246828079223633\n",
      "train acc:  0.9962371869728818  train loss:  0.010359385274659369 --time: 10.047191858291626\n",
      "60 validation:  0.9335443037974683 --max 0.9438291139240507 --time: 11.357076406478882\n",
      "train acc:  0.9945936594437956  train loss:  0.01501132472667802 --time: 9.90965747833252\n",
      "61 validation:  0.9272151898734177 --max 0.9438291139240507 --time: 11.241449356079102\n",
      "train acc:  0.9955884261061373  train loss:  0.01304312649350845 --time: 10.018304109573364\n",
      "62 validation:  0.9343354430379747 --max 0.9438291139240507 --time: 11.388437509536743\n",
      "train acc:  0.9962804376973314  train loss:  0.010887343587304943 --time: 9.97455620765686\n",
      "63 validation:  0.9338080168776371 --max 0.9438291139240507 --time: 11.309993743896484\n",
      "train acc:  0.9975347087063708  train loss:  0.0067365946333314474 --time: 9.962404489517212\n",
      "64 validation:  0.9377637130801688 --max 0.9438291139240507 --time: 11.289452314376831\n",
      "train acc:  0.998226720297565  train loss:  0.004803432204536463 --time: 9.97560429573059\n",
      "65 validation:  0.9369725738396625 --max 0.9438291139240507 --time: 11.320761919021606\n",
      "train acc:  0.9985294753687124  train loss:  0.0030260229447992577 --time: 9.942554950714111\n",
      "66 validation:  0.9380274261603375 --max 0.9438291139240507 --time: 11.319152116775513\n",
      "train acc:  0.9986159768176117  train loss:  0.002830934516299427 --time: 9.985689640045166\n",
      "67 validation:  0.9367088607594937 --max 0.9438291139240507 --time: 11.359052896499634\n",
      "train acc:  0.998572726093162  train loss:  0.0028455503557799694 --time: 9.917954683303833\n",
      "68 validation:  0.9393459915611815 --max 0.9438291139240507 --time: 11.26735544204712\n",
      "train acc:  0.9987889797154103  train loss:  0.0027159140835018012 --time: 9.947816610336304\n",
      "69 validation:  0.9382911392405063 --max 0.9438291139240507 --time: 11.344226598739624\n",
      "train acc:  0.9984862246442628  train loss:  0.002833032402122626 --time: 10.09277057647705\n",
      "70 validation:  0.9377637130801688 --max 0.9438291139240507 --time: 11.36620044708252\n",
      "train acc:  0.9984429739198132  train loss:  0.002714220888692228 --time: 10.153348922729492\n",
      "71 validation:  0.9380274261603375 --max 0.9438291139240507 --time: 11.284698486328125\n",
      "train acc:  0.9987457289909606  train loss:  0.002740563415711262 --time: 10.380403995513916\n",
      "72 validation:  0.9380274261603375 --max 0.9438291139240507 --time: 11.489217281341553\n",
      "train acc:  0.9986592275420614  train loss:  0.002666453465039746 --time: 10.453035593032837\n",
      "73 validation:  0.9375 --max 0.9438291139240507 --time: 11.591081619262695\n",
      "train acc:  0.9985294753687124  train loss:  0.0028121471788926508 --time: 10.349936485290527\n",
      "74 validation:  0.9377637130801688 --max 0.9438291139240507 --time: 11.481513261795044\n",
      "train acc:  0.9985294753687124  train loss:  0.0026754613876800153 --time: 10.41431713104248\n",
      "75 validation:  0.9388185654008439 --max 0.9438291139240507 --time: 11.50169038772583\n",
      "train acc:  0.9985294753687124  train loss:  0.0025997574516547616 --time: 10.375409126281738\n",
      "76 validation:  0.9377637130801688 --max 0.9438291139240507 --time: 11.479087829589844\n",
      "train acc:  0.9986592275420614  train loss:  0.002656805131619218 --time: 10.441766738891602\n",
      "77 validation:  0.9380274261603375 --max 0.9438291139240507 --time: 11.544559717178345\n",
      "train acc:  0.9985294753687124  train loss:  0.0026739767223030735 --time: 10.17408537864685\n",
      "78 validation:  0.9388185654008439 --max 0.9438291139240507 --time: 11.261337995529175\n",
      "train acc:  0.9987457289909606  train loss:  0.002543782227014705 --time: 10.005783796310425\n",
      "79 validation:  0.9382911392405063 --max 0.9438291139240507 --time: 10.792967081069946\n",
      "train acc:  0.9986592275420614  train loss:  0.0025912190210231364 --time: 10.006511449813843\n",
      "80 validation:  0.9380274261603375 --max 0.9438291139240507 --time: 10.825754165649414\n",
      "train acc:  0.998572726093162  train loss:  0.0025000328401570964 --time: 9.982568740844727\n",
      "81 validation:  0.9393459915611815 --max 0.9438291139240507 --time: 11.22751522064209\n",
      "train acc:  0.998572726093162  train loss:  0.002711450640047522 --time: 9.917726993560791\n",
      "82 validation:  0.9364451476793249 --max 0.9438291139240507 --time: 11.231175422668457\n",
      "train acc:  0.9852947536871243  train loss:  0.04374530863310736 --time: 9.896484375\n",
      "83 validation:  0.919831223628692 --max 0.9438291139240507 --time: 11.227282524108887\n",
      "train acc:  0.9748713290947624  train loss:  0.06826040798088134 --time: 9.78528618812561\n",
      "84 validation:  0.9367088607594937 --max 0.9438291139240507 --time: 11.216169118881226\n",
      "train acc:  0.9949829159638424  train loss:  0.014493478703935173 --time: 9.780272006988525\n",
      "85 validation:  0.9364451476793249 --max 0.9438291139240507 --time: 11.263838768005371\n",
      "train acc:  0.9981834695731153  train loss:  0.005804910873788414 --time: 9.757307529449463\n",
      "86 validation:  0.9451476793248945 --max 0.9451476793248945 --time: 11.302309036254883\n",
      "train acc:  0.998572726093162  train loss:  0.0033911876540434244 --time: 9.716041326522827\n",
      "87 validation:  0.9438291139240507 --max 0.9451476793248945 --time: 11.27647590637207\n",
      "train acc:  0.9987024782665109  train loss:  0.002914033521440148 --time: 9.640321016311646\n",
      "88 validation:  0.9419831223628692 --max 0.9451476793248945 --time: 11.242883443832397\n",
      "train acc:  0.9986159768176117  train loss:  0.00272796291348078 --time: 9.650714874267578\n",
      "89 validation:  0.9438291139240507 --max 0.9451476793248945 --time: 11.22026777267456\n",
      "train acc:  0.9986592275420614  train loss:  0.0026624530354593186 --time: 9.694339275360107\n",
      "90 validation:  0.943301687763713 --max 0.9451476793248945 --time: 11.283560991287231\n",
      "train acc:  0.9983997231953635  train loss:  0.0026231887102928153 --time: 9.648377656936646\n",
      "91 validation:  0.943301687763713 --max 0.9451476793248945 --time: 11.202558517456055\n",
      "train acc:  0.9987024782665109  train loss:  0.002585778946405243 --time: 9.663357019424438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 validation:  0.9438291139240507 --max 0.9451476793248945 --time: 11.208987474441528\n",
      "train acc:  0.9985294753687124  train loss:  0.0026315283236088673 --time: 9.586256504058838\n",
      "93 validation:  0.9438291139240507 --max 0.9451476793248945 --time: 11.098599433898926\n",
      "train acc:  0.9987457289909606  train loss:  0.002529572125577184 --time: 9.497112035751343\n",
      "94 validation:  0.9435654008438819 --max 0.9451476793248945 --time: 11.033645629882812\n",
      "train acc:  0.9987457289909606  train loss:  0.002527964125508047 --time: 9.535823345184326\n",
      "95 validation:  0.943301687763713 --max 0.9451476793248945 --time: 11.05025029182434\n",
      "train acc:  0.9987024782665109  train loss:  0.0025209046113021795 --time: 9.562537908554077\n",
      "96 validation:  0.9427742616033755 --max 0.9451476793248945 --time: 11.066036939620972\n",
      "train acc:  0.9988322304398599  train loss:  0.0024972057198489454 --time: 9.452425479888916\n",
      "97 validation:  0.9443565400843882 --max 0.9451476793248945 --time: 10.9669189453125\n",
      "train acc:  0.9987457289909606  train loss:  0.0025447829455374905 --time: 9.567854166030884\n",
      "98 validation:  0.9430379746835443 --max 0.9451476793248945 --time: 11.118510007858276\n",
      "train acc:  0.998572726093162  train loss:  0.0025538685323372393 --time: 9.531848669052124\n",
      "99 validation:  0.9438291139240507 --max 0.9451476793248945 --time: 11.10487151145935\n",
      "train acc:  0.9986159768176117  train loss:  0.0025444040870174506 --time: 9.56012773513794\n",
      "100 validation:  0.9425105485232067 --max 0.9451476793248945 --time: 10.551110744476318\n",
      "train acc:  0.9987024782665109  train loss:  0.002607804051103059 --time: 8.531862497329712\n",
      "101 validation:  0.9425105485232067 --max 0.9451476793248945 --time: 10.104771614074707\n",
      "train acc:  0.9987889797154103  train loss:  0.0024820031159220857 --time: 9.588683605194092\n",
      "102 validation:  0.9430379746835443 --max 0.9451476793248945 --time: 11.142421960830688\n",
      "train acc:  0.9987024782665109  train loss:  0.002506373486434293 --time: 9.600200176239014\n",
      "103 validation:  0.9435654008438819 --max 0.9451476793248945 --time: 11.141661167144775\n",
      "train acc:  0.9986592275420614  train loss:  0.0024550752303847986 --time: 9.57666802406311\n",
      "104 validation:  0.942246835443038 --max 0.9451476793248945 --time: 11.098387241363525\n",
      "train acc:  0.9986592275420614  train loss:  0.0025796526919474577 --time: 9.617949962615967\n",
      "105 validation:  0.9440928270042194 --max 0.9451476793248945 --time: 11.178356409072876\n",
      "train acc:  0.9986592275420614  train loss:  0.0024220073040429188 --time: 12.560003757476807\n",
      "106 validation:  0.9435654008438819 --max 0.9451476793248945 --time: 14.793426513671875\n"
     ]
    }
   ],
   "source": [
    "print(class_type, split)\n",
    "max_acc = 0\n",
    "\n",
    "for j in range(1000):\n",
    "    #print(\"epoch \", i)\n",
    "    loss_accum = 0.0\n",
    "    batch_cnt = 0\n",
    "\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch, (x, lengths, y) in enumerate(train_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        loss = criterion(logits, y)\n",
    "        loss_score = loss.cpu().item()\n",
    "\n",
    "        loss_accum += loss_score\n",
    "        batch_cnt += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "                    \n",
    "\n",
    "    print(\"train acc: \", acc_cnt/(err_cnt+acc_cnt), \" train loss: \", loss_accum / batch_cnt, '--time:', time.time() - start_time)\n",
    "\n",
    "    model.eval()\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    #start_time = time.time()\n",
    "    for x, lengths, y in valid_loader:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    current_acc = acc_cnt/(err_cnt+acc_cnt)\n",
    "    if current_acc > max_acc:\n",
    "        max_acc = current_acc\n",
    "                \n",
    "    print(j, \"validation: \", current_acc, '--max', max_acc, '--time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 layer, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
