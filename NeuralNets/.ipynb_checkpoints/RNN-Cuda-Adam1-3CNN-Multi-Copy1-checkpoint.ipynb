{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import psutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/ubuntu/Intents-Analysis/Analysis')\n",
    "#sys.path.insert(1, '/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_vocab import load_data, get_vocab\n",
    "from get_frequency import get_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is True\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Needed Functions\n",
    "def load_data(filename):\n",
    "    a_file = open(filename, \"rb\")\n",
    "    output = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_vocabulary(train_file):\n",
    "    '''This function creates an indexed vocabulary dictionary from the training file'''\n",
    "    \n",
    "    vocab, _ = get_vocab(1, train_file)\n",
    "    \n",
    "    phone_to_idx = {'unk': 1}#Padding indx = 0, unkown_idx = 1, indexing starts from 2\n",
    "    for i, phone in enumerate(vocab):\n",
    "        phone_to_idx[phone] = i + 2\n",
    "        \n",
    "    return phone_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_file, intent_labels, phone_to_idx):\n",
    "        data = load_data(data_file)\n",
    "        self.all_data = []\n",
    "        \n",
    "        for intent in data:\n",
    "            for utterance in data[intent]:\n",
    "                utterance_to_idx = []\n",
    "                \n",
    "                for phone in utterance:\n",
    "                    if phone not in phone_to_idx:\n",
    "                        phone = 'unk'\n",
    "    \n",
    "                    utterance_to_idx.append(phone_to_idx[phone])\n",
    "                \n",
    "                self.all_data.append([utterance_to_idx, intent_labels[intent]])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        input_vector = self.all_data[index][0]\n",
    "        label = self.all_data[index][1]\n",
    "\n",
    "        return input_vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_indic(tuple_lst):\n",
    "\n",
    "    x_lst = [x[0] for x in tuple_lst]\n",
    "    y_lst = [x[1] for x in tuple_lst]\n",
    "\n",
    "    # collate x\n",
    "    B = len(tuple_lst)#Number of training samples\n",
    "    T = max(len(x) for x in x_lst)#Max length of a sentence\n",
    "\n",
    "    # x values\n",
    "    x = torch.zeros([B, T], dtype=torch.int64)\n",
    "    lengths = torch.zeros(B, dtype=torch.int64)\n",
    "\n",
    "    for i, x_np in enumerate(x_lst):\n",
    "        lengths[i] = len(x_np)\n",
    "        x[i,:len(x_np)] = torch.tensor(x_np)\n",
    "\n",
    "    # collate y\n",
    "    y = torch.zeros([B, 6])\n",
    "    for i, y_label in enumerate(y_lst):\n",
    "        y[i][y_label] = 1\n",
    "        \n",
    "    ids = torch.argsort(lengths, descending=True)\n",
    "\n",
    "    return x[ids], lengths[ids], y[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "#Defining constants and labels\n",
    "intent_labels = {'movie-tickets':0, 'auto-repair':1, 'restaurant-table':2, 'pizza-ordering':3, 'uber-lyft':4, 'coffee-ordering':5}\n",
    "train_language = 'hindi_gujarati_marathi'\n",
    "test_language = 'gujarati'\n",
    "\n",
    "#Loading data\n",
    "train_file = '/home/ubuntu/Intents-Analysis/TaskMasterData/Get_Phones_Combos/3_languages/taskmaster_training_' + train_language + '.pkl'\n",
    "test_file = '/home/ubuntu/Intents-Analysis/TaskMasterData/Get_Phones_Combos/1_language/taskmaster_testing_' + test_language + '.pkl'\n",
    "\n",
    "#create vocabulary and phone_to_idx\n",
    "phone_to_idx = create_vocabulary(train_file)\n",
    "print(len(phone_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_file, intent_labels, phone_to_idx)\n",
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=32)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args, collate_fn=collate_indic)\n",
    "\n",
    "test_dataset = MyDataset(test_file, intent_labels, phone_to_idx)\n",
    "test_loader_args = dict(shuffle=False, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "valid_loader = DataLoader(test_dataset, **test_loader_args, collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=67, embed_size=128, hidden_size=128, label_size=6):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "        self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(embed_size*3)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_size*3, hidden_size, num_layers=1)\n",
    "        self.linear = nn.Linear(hidden_size, label_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "\n",
    "        # B,T,H\n",
    "        input = self.embed(x)\n",
    "\n",
    "        # (B,T,H) -> (B,H,T)\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input), self.cnn3(input)], dim=1)\n",
    "\n",
    "        # (B,H,T)\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n",
    "\n",
    "        output, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        #output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        #output = torch.cat([hn[0], hn[1]], dim=1)\n",
    "        logits = self.linear(hn[0])\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNClassifier(\n",
       "  (embed): Embedding(67, 128)\n",
       "  (cnn): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (cnn2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (cnn3): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  (batchnorm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lstm): LSTM(384, 128)\n",
       "  (linear): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNClassifier()\n",
    "opt = optim.Adam(model.parameters(), lr = 0.001)\n",
    "#opt = SGD(model.parameters(), lr=0.05)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hindi_gujarati_marathi gujarati\n",
      "validation:  0.21 --max 0.21 --time: 4.59466290473938\n",
      "validation:  0.2733333333333333 --max 0.2733333333333333 --time: 5.430022239685059\n",
      "validation:  0.3233333333333333 --max 0.3233333333333333 --time: 5.263693571090698\n",
      "validation:  0.3466666666666667 --max 0.3466666666666667 --time: 5.551421403884888\n",
      "validation:  0.37 --max 0.37 --time: 5.534646272659302\n",
      "validation:  0.43333333333333335 --max 0.43333333333333335 --time: 3.8496391773223877\n",
      "validation:  0.5066666666666667 --max 0.5066666666666667 --time: 6.0727763175964355\n",
      "validation:  0.5433333333333333 --max 0.5433333333333333 --time: 3.25691294670105\n",
      "validation:  0.54 --max 0.5433333333333333 --time: 5.491772651672363\n",
      "validation:  0.6033333333333334 --max 0.6033333333333334 --time: 5.17203950881958\n",
      "validation:  0.6666666666666666 --max 0.6666666666666666 --time: 5.261861801147461\n",
      "validation:  0.6833333333333333 --max 0.6833333333333333 --time: 5.47744083404541\n",
      "validation:  0.7333333333333333 --max 0.7333333333333333 --time: 3.9233927726745605\n",
      "validation:  0.7466666666666667 --max 0.7466666666666667 --time: 5.598839521408081\n",
      "validation:  0.7533333333333333 --max 0.7533333333333333 --time: 3.3645431995391846\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.883874416351318\n",
      "validation:  0.7733333333333333 --max 0.7833333333333333 --time: 4.926882982254028\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.246517181396484\n",
      "validation:  0.7566666666666667 --max 0.7833333333333333 --time: 5.659586668014526\n",
      "validation:  0.82 --max 0.82 --time: 3.634470224380493\n",
      "validation:  0.78 --max 0.82 --time: 5.543376207351685\n",
      "validation:  0.83 --max 0.83 --time: 3.829637289047241\n",
      "validation:  0.83 --max 0.83 --time: 5.6628947257995605\n",
      "validation:  0.83 --max 0.83 --time: 5.280803680419922\n",
      "validation:  0.85 --max 0.85 --time: 4.850165843963623\n",
      "validation:  0.8333333333333334 --max 0.85 --time: 5.693267345428467\n",
      "validation:  0.83 --max 0.85 --time: 4.24739146232605\n",
      "validation:  0.87 --max 0.87 --time: 5.518465757369995\n",
      "validation:  0.8666666666666667 --max 0.87 --time: 4.27756667137146\n",
      "validation:  0.8433333333333334 --max 0.87 --time: 6.102578163146973\n",
      "validation:  0.8466666666666667 --max 0.87 --time: 5.2035231590271\n",
      "validation:  0.8333333333333334 --max 0.87 --time: 5.256037473678589\n",
      "validation:  0.8466666666666667 --max 0.87 --time: 5.412749528884888\n",
      "validation:  0.85 --max 0.87 --time: 3.798490047454834\n",
      "validation:  0.85 --max 0.87 --time: 5.915024995803833\n",
      "validation:  0.8533333333333334 --max 0.87 --time: 4.364488363265991\n",
      "validation:  0.83 --max 0.87 --time: 5.158797025680542\n",
      "validation:  0.8066666666666666 --max 0.87 --time: 5.5134618282318115\n",
      "validation:  0.8433333333333334 --max 0.87 --time: 3.8616178035736084\n",
      "validation:  0.84 --max 0.87 --time: 5.378952503204346\n",
      "validation:  0.86 --max 0.87 --time: 3.321678400039673\n",
      "validation:  0.8566666666666667 --max 0.87 --time: 5.626602411270142\n",
      "validation:  0.8666666666666667 --max 0.87 --time: 4.261007308959961\n",
      "validation:  0.87 --max 0.87 --time: 5.446983337402344\n",
      "validation:  0.8666666666666667 --max 0.87 --time: 5.582322359085083\n",
      "validation:  0.8766666666666667 --max 0.8766666666666667 --time: 4.379637241363525\n",
      "validation:  0.8766666666666667 --max 0.8766666666666667 --time: 5.821617126464844\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 4.413647890090942\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 5.8243560791015625\n",
      "validation:  0.8766666666666667 --max 0.8766666666666667 --time: 4.3495190143585205\n",
      "validation:  0.8733333333333333 --max 0.8766666666666667 --time: 5.733473777770996\n",
      "validation:  0.8733333333333333 --max 0.8766666666666667 --time: 5.493433237075806\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 4.204683542251587\n",
      "validation:  0.8666666666666667 --max 0.8766666666666667 --time: 5.4971160888671875\n",
      "validation:  0.8666666666666667 --max 0.8766666666666667 --time: 3.6373391151428223\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 5.3244569301605225\n",
      "validation:  0.8733333333333333 --max 0.8766666666666667 --time: 5.329176425933838\n",
      "validation:  0.8666666666666667 --max 0.8766666666666667 --time: 5.301815986633301\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 5.408471345901489\n",
      "validation:  0.8666666666666667 --max 0.8766666666666667 --time: 3.0521764755249023\n",
      "validation:  0.8666666666666667 --max 0.8766666666666667 --time: 5.660709857940674\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 4.367746353149414\n",
      "validation:  0.8666666666666667 --max 0.8766666666666667 --time: 5.303577423095703\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 6.03792667388916\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 4.873974323272705\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 5.613064765930176\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 3.3396313190460205\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 5.498741388320923\n",
      "validation:  0.8733333333333333 --max 0.8766666666666667 --time: 4.861238718032837\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 5.366093397140503\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 5.620944023132324\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 4.435040473937988\n",
      "validation:  0.8233333333333334 --max 0.8766666666666667 --time: 5.300831317901611\n",
      "validation:  0.83 --max 0.8766666666666667 --time: 3.9139158725738525\n",
      "validation:  0.85 --max 0.8766666666666667 --time: 5.8216233253479\n",
      "validation:  0.86 --max 0.8766666666666667 --time: 4.727847576141357\n",
      "validation:  0.86 --max 0.8766666666666667 --time: 5.663074731826782\n",
      "validation:  0.8666666666666667 --max 0.8766666666666667 --time: 5.193875074386597\n",
      "validation:  0.8766666666666667 --max 0.8766666666666667 --time: 4.934433698654175\n",
      "validation:  0.8566666666666667 --max 0.8766666666666667 --time: 5.656090974807739\n",
      "validation:  0.87 --max 0.8766666666666667 --time: 4.576334476470947\n",
      "validation:  0.8666666666666667 --max 0.8766666666666667 --time: 5.540785312652588\n",
      "validation:  0.8733333333333333 --max 0.8766666666666667 --time: 4.121171236038208\n",
      "validation:  0.86 --max 0.8766666666666667 --time: 5.929686784744263\n",
      "validation:  0.8633333333333333 --max 0.8766666666666667 --time: 4.931164741516113\n",
      "validation:  0.85 --max 0.8766666666666667 --time: 5.412448883056641\n",
      "validation:  0.85 --max 0.8766666666666667 --time: 5.465795278549194\n",
      "validation:  0.8566666666666667 --max 0.8766666666666667 --time: 3.083613157272339\n",
      "validation:  0.8433333333333334 --max 0.8766666666666667 --time: 5.554008960723877\n",
      "validation:  0.86 --max 0.8766666666666667 --time: 3.8370048999786377\n",
      "validation:  0.8833333333333333 --max 0.8833333333333333 --time: 5.686598777770996\n",
      "validation:  0.88 --max 0.8833333333333333 --time: 5.632136344909668\n",
      "validation:  0.8833333333333333 --max 0.8833333333333333 --time: 4.705095052719116\n",
      "validation:  0.8766666666666667 --max 0.8833333333333333 --time: 5.524338722229004\n",
      "validation:  0.88 --max 0.8833333333333333 --time: 3.076460599899292\n",
      "validation:  0.8866666666666667 --max 0.8866666666666667 --time: 5.502672433853149\n",
      "validation:  0.8866666666666667 --max 0.8866666666666667 --time: 5.365853309631348\n",
      "validation:  0.89 --max 0.89 --time: 5.242149353027344\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 5.509073495864868\n",
      "validation:  0.89 --max 0.8933333333333333 --time: 4.203804969787598\n",
      "validation:  0.8866666666666667 --max 0.8933333333333333 --time: 2.2269420623779297\n",
      "validation:  0.89 --max 0.8933333333333333 --time: 3.7005274295806885\n",
      "validation:  0.89 --max 0.8933333333333333 --time: 5.515390157699585\n",
      "validation:  0.8833333333333333 --max 0.8933333333333333 --time: 4.422560453414917\n",
      "validation:  0.8833333333333333 --max 0.8933333333333333 --time: 5.8501293659210205\n",
      "validation:  0.89 --max 0.8933333333333333 --time: 4.64251184463501\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 5.098052024841309\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 5.736185073852539\n",
      "validation:  0.89 --max 0.8933333333333333 --time: 4.4954328536987305\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 4.611542701721191\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 2.536710023880005\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 4.494910001754761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 4.415773153305054\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 4.366687536239624\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 5.899176836013794\n",
      "validation:  0.89 --max 0.8933333333333333 --time: 3.5275979042053223\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 5.262280225753784\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 5.444000959396362\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 5.2500245571136475\n",
      "validation:  0.89 --max 0.8933333333333333 --time: 5.83792781829834\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 3.7042336463928223\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 5.5700201988220215\n",
      "validation:  0.8933333333333333 --max 0.8933333333333333 --time: 4.415863752365112\n",
      "validation:  0.8966666666666666 --max 0.8966666666666666 --time: 5.31057333946228\n",
      "validation:  0.8933333333333333 --max 0.8966666666666666 --time: 5.452179908752441\n",
      "validation:  0.8933333333333333 --max 0.8966666666666666 --time: 3.875169515609741\n",
      "validation:  0.9 --max 0.9 --time: 5.527540683746338\n",
      "validation:  0.8966666666666666 --max 0.9 --time: 3.457944869995117\n",
      "validation:  0.8966666666666666 --max 0.9 --time: 5.805577516555786\n",
      "validation:  0.8966666666666666 --max 0.9 --time: 5.032313108444214\n",
      "validation:  0.8966666666666666 --max 0.9 --time: 5.15745997428894\n",
      "validation:  0.8966666666666666 --max 0.9 --time: 5.7096848487854\n",
      "validation:  0.8966666666666666 --max 0.9 --time: 3.6826486587524414\n",
      "validation:  0.8966666666666666 --max 0.9 --time: 5.479620933532715\n",
      "validation:  0.9 --max 0.9 --time: 3.952582836151123\n",
      "validation:  0.9 --max 0.9 --time: 5.910845518112183\n",
      "validation:  0.9 --max 0.9 --time: 5.336333751678467\n",
      "validation:  0.9 --max 0.9 --time: 4.634585618972778\n",
      "validation:  0.8966666666666666 --max 0.9 --time: 5.681370735168457\n",
      "validation:  0.8933333333333333 --max 0.9 --time: 4.302486419677734\n",
      "validation:  0.8933333333333333 --max 0.9 --time: 5.857760906219482\n",
      "validation:  0.8966666666666666 --max 0.9 --time: 4.538464069366455\n",
      "validation:  0.9 --max 0.9 --time: 5.657849550247192\n",
      "validation:  0.9 --max 0.9 --time: 5.334805727005005\n",
      "validation:  0.9033333333333333 --max 0.9033333333333333 --time: 4.882134437561035\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 5.399490594863892\n",
      "validation:  0.8966666666666666 --max 0.9033333333333333 --time: 3.351569414138794\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 5.459184169769287\n",
      "validation:  0.9033333333333333 --max 0.9033333333333333 --time: 5.014995813369751\n",
      "validation:  0.9033333333333333 --max 0.9033333333333333 --time: 5.092545032501221\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 5.380457162857056\n",
      "validation:  0.9033333333333333 --max 0.9033333333333333 --time: 3.677232265472412\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 5.570067644119263\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 4.174887418746948\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 5.542830228805542\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 5.518726825714111\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 5.4539549350738525\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 5.6493752002716064\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 4.396635055541992\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 5.816630125045776\n",
      "validation:  0.8966666666666666 --max 0.9033333333333333 --time: 4.528958082199097\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 5.702351331710815\n",
      "validation:  0.9033333333333333 --max 0.9033333333333333 --time: 5.093766450881958\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 5.052379369735718\n",
      "validation:  0.9 --max 0.9033333333333333 --time: 5.79731822013855\n",
      "validation:  0.8966666666666666 --max 0.9033333333333333 --time: 3.6141488552093506\n",
      "validation:  0.8933333333333333 --max 0.9033333333333333 --time: 6.235008001327515\n",
      "validation:  0.8933333333333333 --max 0.9033333333333333 --time: 3.9178106784820557\n"
     ]
    }
   ],
   "source": [
    "print(train_language, test_language)\n",
    "max_acc = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    #print(\"epoch \", i)\n",
    "    loss_accum = 0.0\n",
    "    batch_cnt = 0\n",
    "\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch, (x, lengths, y) in enumerate(train_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "        loss_score = loss.cpu().item()\n",
    "\n",
    "        loss_accum += loss_score\n",
    "        batch_cnt += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        target_val, tar_indices = torch.max(y, dim=1)\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    #print(\"train acc: \", acc_cnt/(err_cnt+acc_cnt), \" train loss: \", loss_accum / batch_cnt, '--time:', time.time() - start_time)\n",
    "\n",
    "    model.eval()\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    #start_time = time.time()\n",
    "    for x, lengths, y in valid_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        target_val, tar_indices = torch.max(y, dim=1)\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    current_acc = acc_cnt/(err_cnt+acc_cnt)\n",
    "    if current_acc > max_acc:\n",
    "        max_acc = current_acc\n",
    "                \n",
    "    print(\"validation: \", current_acc, '--max', max_acc, '--time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
