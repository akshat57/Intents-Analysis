{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import psutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/ubuntu/Intents-Analysis/Analysis')\n",
    "#sys.path.insert(1, '/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_vocab import load_data, get_vocab\n",
    "from get_frequency import get_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is True\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Needed Functions\n",
    "def load_data(filename):\n",
    "    a_file = open(filename, \"rb\")\n",
    "    output = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_vocabulary(train_file):\n",
    "    '''This function creates an indexed vocabulary dictionary from the training file'''\n",
    "    \n",
    "    vocab, _ = get_vocab(1, train_file)\n",
    "    \n",
    "    phone_to_idx = {'unk': 1}#Padding indx = 0, unkown_idx = 1, indexing starts from 2\n",
    "    for i, phone in enumerate(vocab):\n",
    "        phone_to_idx[phone] = i + 2\n",
    "        \n",
    "    return phone_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_file, intent_labels, phone_to_idx):\n",
    "        data = load_data(data_file)\n",
    "        self.all_data = []\n",
    "        \n",
    "        for intent in data:\n",
    "            for utterance in data[intent]:\n",
    "                utterance_to_idx = []\n",
    "                \n",
    "                for phone in utterance:\n",
    "                    if phone not in phone_to_idx:\n",
    "                        phone = 'unk'\n",
    "    \n",
    "                    utterance_to_idx.append(phone_to_idx[phone])\n",
    "                \n",
    "                self.all_data.append([utterance_to_idx, intent_labels[intent]])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        input_vector = self.all_data[index][0]\n",
    "        label = self.all_data[index][1]\n",
    "\n",
    "        return input_vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_indic(tuple_lst):\n",
    "\n",
    "    x_lst = [x[0] for x in tuple_lst]\n",
    "    y_lst = [x[1] for x in tuple_lst]\n",
    "\n",
    "    # collate x\n",
    "    B = len(tuple_lst)#Number of training samples\n",
    "    T = max(len(x) for x in x_lst)#Max length of a sentence\n",
    "\n",
    "    # x values\n",
    "    x = torch.zeros([B, T], dtype=torch.int64)\n",
    "    lengths = torch.zeros(B, dtype=torch.int64)\n",
    "\n",
    "    for i, x_np in enumerate(x_lst):\n",
    "        lengths[i] = len(x_np)\n",
    "        x[i,:len(x_np)] = torch.tensor(x_np)\n",
    "\n",
    "    # collate y\n",
    "    y = torch.zeros([B, 6])\n",
    "    for i, y_label in enumerate(y_lst):\n",
    "        y[i][y_label] = 1\n",
    "        \n",
    "    ids = torch.argsort(lengths, descending=True)\n",
    "\n",
    "    return x[ids], lengths[ids], y[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/Intents-Analysis/TaskMasterData/Get_Phones_Combos/3_lang_variations/taskmaster_training_hindi.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cd2f8a0cab59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#create vocabulary and phone_to_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mphone_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphone_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e8461cfdb260>\u001b[0m in \u001b[0;36mcreate_vocabulary\u001b[0;34m(train_file)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m'''This function creates an indexed vocabulary dictionary from the training file'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mphone_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'unk'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;31m#Padding indx = 0, unkown_idx = 1, indexing starts from 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Intents-Analysis/Analysis/get_vocab.py\u001b[0m in \u001b[0;36mget_vocab\u001b[0;34m(N, filename)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"Labels/intent_labels.pkl\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Intents-Analysis/Analysis/get_vocab.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Labels/intent_labels.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0ma_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ma_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/Intents-Analysis/TaskMasterData/Get_Phones_Combos/3_lang_variations/taskmaster_training_hindi.pkl'"
     ]
    }
   ],
   "source": [
    "#Defining constants and labels\n",
    "intent_labels = {'movie-tickets':0, 'auto-repair':1, 'restaurant-table':2, 'pizza-ordering':3, 'uber-lyft':4, 'coffee-ordering':5}\n",
    "train_language = 'gujarati_marathi_bengali_hindi_05'\n",
    "test_language = 'hindi'\n",
    "\n",
    "#Loading data\n",
    "train_file = '/home/ubuntu/Intents-Analysis/TaskMasterData/Get_Phones_Combos/3_lang_variations/taskmaster_training_' + train_language + '.pkl'\n",
    "test_file = '/home/ubuntu/Intents-Analysis/TaskMasterData/Get_Phones_Combos/1_language/taskmaster_testing_' + test_language + '.pkl'\n",
    "\n",
    "#create vocabulary and phone_to_idx\n",
    "phone_to_idx = create_vocabulary(train_file)\n",
    "print(len(phone_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_file, intent_labels, phone_to_idx)\n",
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=32)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args, collate_fn=collate_indic)\n",
    "\n",
    "test_dataset = MyDataset(test_file, intent_labels, phone_to_idx)\n",
    "test_loader_args = dict(shuffle=False, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "valid_loader = DataLoader(test_dataset, **test_loader_args, collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=68, embed_size=128, hidden_size=128, label_size=6):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "        self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(embed_size*3)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_size*3, hidden_size, num_layers=1)\n",
    "        self.linear = nn.Linear(hidden_size, label_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "\n",
    "        # B,T,H\n",
    "        input = self.embed(x)\n",
    "\n",
    "        # (B,T,H) -> (B,H,T)\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input), self.cnn3(input)], dim=1)\n",
    "\n",
    "        # (B,H,T)\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n",
    "\n",
    "        output, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        #output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        #output = torch.cat([hn[0], hn[1]], dim=1)\n",
    "        logits = self.linear(hn[0])\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNClassifier(\n",
       "  (embed): Embedding(68, 128)\n",
       "  (cnn): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (cnn2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (cnn3): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  (batchnorm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lstm): LSTM(384, 128)\n",
       "  (linear): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNClassifier()\n",
    "opt = optim.Adam(model.parameters(), lr = 0.001)\n",
    "#opt = SGD(model.parameters(), lr=0.05)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gujarati_marathi_bengali_hindi_05 hindi\n",
      "train acc:  0.25178389398572887  train loss:  0.4556196785491446 --time: 5.27141809463501\n",
      "validation:  0.17333333333333334 --max 0.17333333333333334 --time: 5.917364835739136\n",
      "train acc:  0.2969758749575263  train loss:  0.43075917596402374 --time: 5.191982269287109\n",
      "validation:  0.17 --max 0.17333333333333334 --time: 5.925041675567627\n",
      "train acc:  0.3367312266394835  train loss:  0.4192426969175753 --time: 4.926982164382935\n",
      "validation:  0.19666666666666666 --max 0.19666666666666666 --time: 5.576266527175903\n",
      "train acc:  0.4274549779136935  train loss:  0.3968094276345294 --time: 4.85190486907959\n",
      "validation:  0.2633333333333333 --max 0.2633333333333333 --time: 5.662023305892944\n",
      "train acc:  0.5225959904858988  train loss:  0.36370921782825305 --time: 4.938372611999512\n",
      "validation:  0.3333333333333333 --max 0.3333333333333333 --time: 5.651646137237549\n",
      "train acc:  0.6041454298335033  train loss:  0.32105090436728106 --time: 3.729836940765381\n",
      "validation:  0.4033333333333333 --max 0.4033333333333333 --time: 4.520596981048584\n",
      "train acc:  0.6598708800543663  train loss:  0.27848679604737653 --time: 4.608937740325928\n",
      "validation:  0.4766666666666667 --max 0.4766666666666667 --time: 5.132716417312622\n",
      "train acc:  0.6826367652055726  train loss:  0.2521154530670332 --time: 5.042686700820923\n",
      "validation:  0.4866666666666667 --max 0.4866666666666667 --time: 5.7787861824035645\n",
      "train acc:  0.7390417940876657  train loss:  0.21713081909262616 --time: 4.3068273067474365\n",
      "validation:  0.49 --max 0.49 --time: 4.983281135559082\n",
      "train acc:  0.7686034658511722  train loss:  0.2023762671843819 --time: 4.837240695953369\n",
      "validation:  0.51 --max 0.51 --time: 5.504888534545898\n",
      "train acc:  0.799184505606524  train loss:  0.1817012889229733 --time: 4.700555324554443\n",
      "validation:  0.6133333333333333 --max 0.6133333333333333 --time: 5.396534442901611\n",
      "train acc:  0.8372409106354061  train loss:  0.15702128086401068 --time: 4.701677083969116\n",
      "validation:  0.6066666666666667 --max 0.6133333333333333 --time: 5.466594934463501\n",
      "train acc:  0.8848114169215087  train loss:  0.13017221313455832 --time: 5.1026341915130615\n",
      "validation:  0.6233333333333333 --max 0.6233333333333333 --time: 5.8375115394592285\n",
      "train acc:  0.891946992864424  train loss:  0.11590209732884946 --time: 4.669856548309326\n",
      "validation:  0.7066666666666667 --max 0.7066666666666667 --time: 5.438331842422485\n",
      "train acc:  0.90859667006456  train loss:  0.09910247993210088 --time: 4.971535682678223\n",
      "validation:  0.7033333333333334 --max 0.7066666666666667 --time: 5.66744327545166\n",
      "train acc:  0.9401970778117568  train loss:  0.07608865606396095 --time: 5.0577051639556885\n",
      "validation:  0.71 --max 0.71 --time: 5.764104604721069\n",
      "train acc:  0.9378185524974516  train loss:  0.07197330519556999 --time: 4.9993109703063965\n",
      "validation:  0.7133333333333334 --max 0.7133333333333334 --time: 5.754187345504761\n",
      "train acc:  0.9629629629629629  train loss:  0.05335488235173018 --time: 5.074781894683838\n",
      "validation:  0.7333333333333333 --max 0.7333333333333333 --time: 5.560351610183716\n",
      "train acc:  0.9694189602446484  train loss:  0.04608683028946752 --time: 4.738718748092651\n",
      "validation:  0.7066666666666667 --max 0.7333333333333333 --time: 5.423790693283081\n",
      "train acc:  0.9847094801223242  train loss:  0.03195419138216454 --time: 4.911289930343628\n",
      "validation:  0.7233333333333334 --max 0.7333333333333333 --time: 5.55435585975647\n",
      "train acc:  0.9911654774040095  train loss:  0.024055599477951942 --time: 4.932163953781128\n",
      "validation:  0.7266666666666667 --max 0.7333333333333333 --time: 5.599903345108032\n",
      "train acc:  0.9802922188243289  train loss:  0.03010473509683557 --time: 4.785787343978882\n",
      "validation:  0.6966666666666667 --max 0.7333333333333333 --time: 5.455773591995239\n",
      "train acc:  0.9599048589874278  train loss:  0.04831643613136333 --time: 4.721842288970947\n",
      "validation:  0.7166666666666667 --max 0.7333333333333333 --time: 5.475226163864136\n",
      "train acc:  0.9874277947672443  train loss:  0.023902569654519142 --time: 5.006435394287109\n",
      "validation:  0.7433333333333333 --max 0.7433333333333333 --time: 5.755886793136597\n",
      "train acc:  0.9867482161060143  train loss:  0.021297056592353012 --time: 4.997152090072632\n",
      "validation:  0.7366666666666667 --max 0.7433333333333333 --time: 5.728684186935425\n",
      "train acc:  0.9884471627590894  train loss:  0.017089861445128918 --time: 5.0572755336761475\n",
      "validation:  0.7166666666666667 --max 0.7433333333333333 --time: 5.7455456256866455\n",
      "train acc:  0.9789330615018689  train loss:  0.02564071052019363 --time: 4.962054014205933\n",
      "validation:  0.6933333333333334 --max 0.7433333333333333 --time: 5.692513465881348\n",
      "train acc:  0.9853890587835542  train loss:  0.021881295752752085 --time: 5.061145782470703\n",
      "validation:  0.7366666666666667 --max 0.7433333333333333 --time: 5.668195486068726\n",
      "train acc:  0.9904858987427795  train loss:  0.015928024324871923 --time: 5.409097194671631\n",
      "validation:  0.7133333333333334 --max 0.7433333333333333 --time: 5.935498952865601\n",
      "train acc:  0.9966021066938499  train loss:  0.010622822841548401 --time: 5.61217474937439\n",
      "validation:  0.7366666666666667 --max 0.7433333333333333 --time: 6.165654897689819\n",
      "train acc:  0.9969418960244648  train loss:  0.009015023090836146 --time: 5.686845064163208\n",
      "validation:  0.73 --max 0.7433333333333333 --time: 6.2017412185668945\n",
      "train acc:  0.99932042133877  train loss:  0.006138467209656601 --time: 5.651888608932495\n",
      "validation:  0.6866666666666666 --max 0.7433333333333333 --time: 6.237921237945557\n",
      "train acc:  0.9918450560652395  train loss:  0.011013193116725786 --time: 5.501619815826416\n",
      "validation:  0.69 --max 0.7433333333333333 --time: 5.986673593521118\n",
      "train acc:  0.9894665307509344  train loss:  0.013706174476639084 --time: 5.297630786895752\n",
      "validation:  0.71 --max 0.7433333333333333 --time: 5.989093780517578\n",
      "train acc:  0.9959225280326198  train loss:  0.009198675701475662 --time: 4.847285747528076\n",
      "validation:  0.7066666666666667 --max 0.7433333333333333 --time: 5.590272426605225\n",
      "train acc:  0.9785932721712538  train loss:  0.023520908115998558 --time: 4.44799542427063\n",
      "validation:  0.7266666666666667 --max 0.7433333333333333 --time: 5.160614728927612\n",
      "train acc:  0.9898063200815495  train loss:  0.01445814126940525 --time: 4.501356601715088\n",
      "validation:  0.7233333333333334 --max 0.7433333333333333 --time: 5.320443391799927\n",
      "train acc:  0.9966021066938499  train loss:  0.006856129838801597 --time: 4.325399398803711\n",
      "validation:  0.7366666666666667 --max 0.7433333333333333 --time: 5.0127174854278564\n",
      "train acc:  0.9989806320081549  train loss:  0.004236848579476709 --time: 4.5038230419158936\n",
      "validation:  0.74 --max 0.7433333333333333 --time: 5.250912427902222\n",
      "train acc:  0.9952429493713897  train loss:  0.006935814051362483 --time: 5.301003694534302\n",
      "validation:  0.7266666666666667 --max 0.7433333333333333 --time: 5.924190282821655\n",
      "train acc:  0.9901461094121644  train loss:  0.012218792183810601 --time: 5.05035138130188\n",
      "validation:  0.72 --max 0.7433333333333333 --time: 5.598490953445435\n",
      "train acc:  0.9955827387020048  train loss:  0.007868289016187191 --time: 5.1073691844940186\n",
      "validation:  0.7333333333333333 --max 0.7433333333333333 --time: 5.82570743560791\n",
      "train acc:  0.9966021066938499  train loss:  0.006530188266997752 --time: 5.2130725383758545\n",
      "validation:  0.67 --max 0.7433333333333333 --time: 6.037222385406494\n",
      "train acc:  0.9955827387020048  train loss:  0.00776062389511777 --time: 4.935226202011108\n",
      "validation:  0.6733333333333333 --max 0.7433333333333333 --time: 5.667558193206787\n",
      "train acc:  0.9942235813795447  train loss:  0.008109611044030475 --time: 5.056640148162842\n",
      "validation:  0.7333333333333333 --max 0.7433333333333333 --time: 5.78544807434082\n",
      "train acc:  0.9979612640163099  train loss:  0.004131729896787716 --time: 4.682335138320923\n",
      "validation:  0.7233333333333334 --max 0.7433333333333333 --time: 5.39817476272583\n",
      "train acc:  0.9918450560652395  train loss:  0.010875597494937803 --time: 4.383392333984375\n",
      "validation:  0.6833333333333333 --max 0.7433333333333333 --time: 5.113880157470703\n",
      "train acc:  0.9925246347264696  train loss:  0.009901525736179041 --time: 4.5028722286224365\n",
      "validation:  0.6933333333333334 --max 0.7433333333333333 --time: 5.107956409454346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc:  0.9976214746856948  train loss:  0.005482553382930549 --time: 5.033552646636963\n",
      "validation:  0.75 --max 0.75 --time: 5.817176103591919\n",
      "train acc:  0.9983010533469249  train loss:  0.0037610126892104745 --time: 5.18383526802063\n",
      "validation:  0.7333333333333333 --max 0.75 --time: 5.92573618888855\n",
      "train acc:  0.9921848453958546  train loss:  0.00956611810049609 --time: 5.449359178543091\n",
      "validation:  0.7133333333333334 --max 0.75 --time: 6.21384072303772\n",
      "train acc:  0.9959225280326198  train loss:  0.006902260503367237 --time: 5.315237283706665\n",
      "validation:  0.7466666666666667 --max 0.75 --time: 6.104578495025635\n",
      "train acc:  0.9983010533469249  train loss:  0.0031130389340788774 --time: 5.385574579238892\n",
      "validation:  0.75 --max 0.75 --time: 6.106876850128174\n",
      "train acc:  0.9996602106693849  train loss:  0.0017404554199184413 --time: 4.92876672744751\n",
      "validation:  0.7566666666666667 --max 0.7566666666666667 --time: 5.661174297332764\n",
      "train acc:  1.0  train loss:  0.0011726785932019677 --time: 5.2962806224823\n",
      "validation:  0.76 --max 0.76 --time: 5.962407827377319\n",
      "train acc:  1.0  train loss:  0.001033696302961882 --time: 5.13850736618042\n",
      "validation:  0.7533333333333333 --max 0.76 --time: 5.755049705505371\n",
      "train acc:  1.0  train loss:  0.0009620118779940126 --time: 5.261225938796997\n",
      "validation:  0.7566666666666667 --max 0.76 --time: 5.71330714225769\n",
      "train acc:  1.0  train loss:  0.0009070487146306297 --time: 5.256814002990723\n",
      "validation:  0.7566666666666667 --max 0.76 --time: 5.983996629714966\n",
      "train acc:  1.0  train loss:  0.0008663309373609397 --time: 5.370236396789551\n",
      "validation:  0.7633333333333333 --max 0.7633333333333333 --time: 5.9011712074279785\n",
      "train acc:  1.0  train loss:  0.000830156230064028 --time: 5.069561958312988\n",
      "validation:  0.7633333333333333 --max 0.7633333333333333 --time: 5.792151689529419\n",
      "train acc:  1.0  train loss:  0.0007891226332108288 --time: 4.530101537704468\n",
      "validation:  0.7633333333333333 --max 0.7633333333333333 --time: 5.182385444641113\n",
      "train acc:  1.0  train loss:  0.0007605284108253925 --time: 4.124330043792725\n",
      "validation:  0.7566666666666667 --max 0.7633333333333333 --time: 4.855844974517822\n",
      "train acc:  1.0  train loss:  0.000736414862331003 --time: 4.494892597198486\n",
      "validation:  0.7733333333333333 --max 0.7733333333333333 --time: 5.249340534210205\n",
      "train acc:  1.0  train loss:  0.0007072550588813813 --time: 4.5237648487091064\n",
      "validation:  0.7633333333333333 --max 0.7733333333333333 --time: 5.2402894496917725\n",
      "train acc:  1.0  train loss:  0.0006848665602181269 --time: 4.977203607559204\n",
      "validation:  0.77 --max 0.7733333333333333 --time: 5.746196985244751\n",
      "train acc:  1.0  train loss:  0.0006607812399085125 --time: 5.222105979919434\n",
      "validation:  0.7666666666666667 --max 0.7733333333333333 --time: 5.7992377281188965\n",
      "train acc:  1.0  train loss:  0.0006427125544692187 --time: 5.23700737953186\n",
      "validation:  0.7666666666666667 --max 0.7733333333333333 --time: 5.789036273956299\n",
      "train acc:  1.0  train loss:  0.0006250922401111735 --time: 5.476558446884155\n",
      "validation:  0.77 --max 0.7733333333333333 --time: 6.253080606460571\n",
      "train acc:  1.0  train loss:  0.0006048114231342207 --time: 5.61765718460083\n",
      "validation:  0.77 --max 0.7733333333333333 --time: 6.3625569343566895\n",
      "train acc:  1.0  train loss:  0.0005890095312877194 --time: 5.495989084243774\n",
      "validation:  0.7733333333333333 --max 0.7733333333333333 --time: 6.084433555603027\n",
      "train acc:  1.0  train loss:  0.000568625362812663 --time: 5.081002235412598\n",
      "validation:  0.7766666666666666 --max 0.7766666666666666 --time: 5.8102476596832275\n",
      "train acc:  1.0  train loss:  0.000552517350550498 --time: 4.234089374542236\n",
      "validation:  0.78 --max 0.78 --time: 4.972050905227661\n",
      "train acc:  1.0  train loss:  0.0005358691382950739 --time: 2.519171714782715\n",
      "validation:  0.78 --max 0.78 --time: 3.3335468769073486\n",
      "train acc:  1.0  train loss:  0.0005214252375046034 --time: 5.0328216552734375\n",
      "validation:  0.7766666666666666 --max 0.78 --time: 5.457657337188721\n",
      "train acc:  1.0  train loss:  0.0005082074532528286 --time: 5.674036264419556\n",
      "validation:  0.7766666666666666 --max 0.78 --time: 6.340141296386719\n",
      "train acc:  1.0  train loss:  0.0004897369198379633 --time: 5.635084390640259\n",
      "validation:  0.7766666666666666 --max 0.78 --time: 6.146513223648071\n",
      "train acc:  1.0  train loss:  0.0004772578958300469 --time: 5.472018718719482\n",
      "validation:  0.7766666666666666 --max 0.78 --time: 5.921894073486328\n",
      "train acc:  1.0  train loss:  0.0004628583530733443 --time: 4.7692131996154785\n",
      "validation:  0.7766666666666666 --max 0.78 --time: 5.553889751434326\n",
      "train acc:  1.0  train loss:  0.00045541243288544535 --time: 4.340829610824585\n",
      "validation:  0.78 --max 0.78 --time: 5.069916248321533\n",
      "train acc:  1.0  train loss:  0.00044045060032816684 --time: 4.6483986377716064\n",
      "validation:  0.78 --max 0.78 --time: 5.479331970214844\n",
      "train acc:  1.0  train loss:  0.0004318440181162694 --time: 4.5411694049835205\n",
      "validation:  0.7766666666666666 --max 0.78 --time: 5.274032354354858\n",
      "train acc:  1.0  train loss:  0.0004183802115933403 --time: 4.694649934768677\n",
      "validation:  0.7766666666666666 --max 0.78 --time: 5.498383283615112\n",
      "train acc:  1.0  train loss:  0.0004079162545562924 --time: 4.6417436599731445\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.212698221206665\n",
      "train acc:  1.0  train loss:  0.0004012121720259766 --time: 5.339089632034302\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.953792333602905\n",
      "train acc:  1.0  train loss:  0.000389903666117512 --time: 5.163757801055908\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.821160554885864\n",
      "train acc:  1.0  train loss:  0.00038088012851126814 --time: 5.171024560928345\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.892148971557617\n",
      "train acc:  1.0  train loss:  0.00037414025712717813 --time: 5.138714075088501\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 5.873798370361328\n",
      "train acc:  1.0  train loss:  0.00036394648613286733 --time: 5.225978136062622\n",
      "validation:  0.7733333333333333 --max 0.7833333333333333 --time: 5.9192893505096436\n",
      "train acc:  1.0  train loss:  0.00035603004431797433 --time: 5.121108770370483\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 5.8257129192352295\n",
      "train acc:  1.0  train loss:  0.00034730928777919513 --time: 4.8997251987457275\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 5.595274925231934\n",
      "train acc:  1.0  train loss:  0.00033925236177468753 --time: 5.101664304733276\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 5.746574401855469\n",
      "train acc:  1.0  train loss:  0.00033263246397204375 --time: 5.055049419403076\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 5.746706962585449\n",
      "train acc:  1.0  train loss:  0.00032677623169982564 --time: 5.151674270629883\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 5.932040452957153\n",
      "train acc:  1.0  train loss:  0.00031863896014249843 --time: 5.162964344024658\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 5.957362651824951\n",
      "train acc:  1.0  train loss:  0.00031061666896161825 --time: 5.251982688903809\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 6.009066343307495\n",
      "train acc:  1.0  train loss:  0.0003052403474651763 --time: 5.012724161148071\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.651774168014526\n",
      "train acc:  1.0  train loss:  0.00030001464208749974 --time: 4.826229095458984\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.5688793659210205\n",
      "train acc:  1.0  train loss:  0.0002935079417353415 --time: 5.13846755027771\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 5.878724575042725\n",
      "train acc:  1.0  train loss:  0.00028656299084263003 --time: 4.953294277191162\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.7646496295928955\n",
      "train acc:  1.0  train loss:  0.00028225359299382114 --time: 4.793108224868774\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.386736869812012\n",
      "train acc:  1.0  train loss:  0.000276069089760194 --time: 5.32158899307251\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.985682725906372\n",
      "train acc:  1.0  train loss:  0.00027021668653975684 --time: 5.079930305480957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.724406003952026\n",
      "train acc:  1.0  train loss:  0.000264275209148131 --time: 5.043195486068726\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.737087249755859\n",
      "train acc:  1.0  train loss:  0.00025972987603618884 --time: 5.087347030639648\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.833815097808838\n",
      "train acc:  1.0  train loss:  0.00025524182685488915 --time: 4.937372922897339\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 5.584127902984619\n",
      "train acc:  1.0  train loss:  0.0002483834010174336 --time: 4.810994386672974\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.548080682754517\n",
      "train acc:  1.0  train loss:  0.00024272633891087025 --time: 5.104565382003784\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.822178363800049\n",
      "train acc:  1.0  train loss:  0.00024088159325006217 --time: 5.008148431777954\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.673076629638672\n",
      "train acc:  1.0  train loss:  0.00023514668156048688 --time: 5.1629133224487305\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.88187050819397\n",
      "train acc:  1.0  train loss:  0.00023063280589311668 --time: 4.98581075668335\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.677738666534424\n",
      "train acc:  1.0  train loss:  0.000227065093223127 --time: 4.86652684211731\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.6538543701171875\n",
      "train acc:  1.0  train loss:  0.00022119374530713844 --time: 5.016868829727173\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.7863969802856445\n",
      "train acc:  1.0  train loss:  0.000218070487987817 --time: 5.086284875869751\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.85260534286499\n",
      "train acc:  1.0  train loss:  0.00021239169860643375 --time: 4.9927732944488525\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.768409967422485\n",
      "train acc:  1.0  train loss:  0.0002103201455294924 --time: 4.808661937713623\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.544101238250732\n",
      "train acc:  1.0  train loss:  0.00020752937859430423 --time: 4.822444915771484\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.626352071762085\n",
      "train acc:  1.0  train loss:  0.00020121344119695056 --time: 4.828408718109131\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.47488260269165\n",
      "train acc:  1.0  train loss:  0.00019675465148833135 --time: 5.029046535491943\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.743980169296265\n",
      "train acc:  1.0  train loss:  0.00019327798192693 --time: 4.939515113830566\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.6818320751190186\n",
      "train acc:  1.0  train loss:  0.0001893983812213106 --time: 4.749847412109375\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.45043683052063\n",
      "train acc:  1.0  train loss:  0.00018573198948338953 --time: 5.0771191120147705\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.791325807571411\n",
      "train acc:  1.0  train loss:  0.00018371307068382916 --time: 5.073268890380859\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.55172324180603\n",
      "train acc:  1.0  train loss:  0.00017929810881310993 --time: 5.442022323608398\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 6.078863859176636\n",
      "train acc:  1.0  train loss:  0.00017603706130656698 --time: 5.746680021286011\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 6.38900899887085\n",
      "train acc:  1.0  train loss:  0.00017406391650539538 --time: 5.55403995513916\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 6.033691644668579\n",
      "train acc:  1.0  train loss:  0.0001709962304195632 --time: 4.39296293258667\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.107725381851196\n",
      "train acc:  1.0  train loss:  0.00016686645761618146 --time: 3.5031633377075195\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 4.262092590332031\n",
      "train acc:  1.0  train loss:  0.00016406087493321493 --time: 3.8635141849517822\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 4.55041766166687\n",
      "train acc:  1.0  train loss:  0.00016140088795826 --time: 5.1406121253967285\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.527862310409546\n",
      "train acc:  1.0  train loss:  0.0001581488221468728 --time: 5.579195499420166\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 6.177304744720459\n",
      "train acc:  1.0  train loss:  0.0001547693676041925 --time: 5.64367413520813\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 6.101981163024902\n",
      "train acc:  1.0  train loss:  0.00015462369280968508 --time: 5.29217791557312\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 6.125036716461182\n",
      "train acc:  1.0  train loss:  0.00015028694495255047 --time: 5.082712888717651\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.8072075843811035\n",
      "train acc:  1.0  train loss:  0.00014747899536893743 --time: 4.187976360321045\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 4.928317070007324\n",
      "train acc:  1.0  train loss:  0.00014477315720717382 --time: 3.362128973007202\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 4.142193794250488\n",
      "train acc:  1.0  train loss:  0.0001431701466967554 --time: 4.849223613739014\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.653537750244141\n",
      "train acc:  1.0  train loss:  0.0001404812286162506 --time: 5.177399158477783\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.859107732772827\n",
      "train acc:  1.0  train loss:  0.0001379085942576437 --time: 5.314960241317749\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.765364408493042\n",
      "train acc:  1.0  train loss:  0.00013505245632309791 --time: 5.340484857559204\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 5.958817481994629\n",
      "train acc:  1.0  train loss:  0.0001330319678147688 --time: 5.668911933898926\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 6.405638217926025\n",
      "train acc:  1.0  train loss:  0.00013044996107371685 --time: 5.295378684997559\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.9469592571258545\n",
      "train acc:  1.0  train loss:  0.0001283428143284729 --time: 4.92990255355835\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 5.670703887939453\n",
      "train acc:  1.0  train loss:  0.00012611793404768991 --time: 4.236914396286011\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.019113779067993\n",
      "train acc:  1.0  train loss:  0.00012404335385603505 --time: 3.480940818786621\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 4.26147985458374\n",
      "train acc:  1.0  train loss:  0.00012203125357779714 --time: 4.3700950145721436\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.08403754234314\n",
      "train acc:  1.0  train loss:  0.0001200940902851036 --time: 5.2759764194488525\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.684839487075806\n",
      "train acc:  1.0  train loss:  0.00011790822969962154 --time: 5.7088847160339355\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 6.289584636688232\n",
      "train acc:  1.0  train loss:  0.00011524766254613338 --time: 5.7227678298950195\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 6.170237302780151\n",
      "train acc:  1.0  train loss:  0.00011356023226297744 --time: 5.74458384513855\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 6.1853954792022705\n",
      "train acc:  1.0  train loss:  0.00011168276345731853 --time: 5.357287645339966\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 6.045772552490234\n",
      "train acc:  1.0  train loss:  0.00011002306501209007 --time: 5.036010026931763\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.7480127811431885\n",
      "train acc:  1.0  train loss:  0.00010857784724541251 --time: 4.951954126358032\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.524551153182983\n",
      "train acc:  1.0  train loss:  0.00010716799031639391 --time: 5.11862325668335\n",
      "validation:  0.7766666666666666 --max 0.7833333333333333 --time: 5.780550479888916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc:  1.0  train loss:  0.00010406677630152959 --time: 4.840366363525391\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.502370357513428\n",
      "train acc:  1.0  train loss:  0.00010298480281009056 --time: 4.673288345336914\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.4128100872039795\n",
      "train acc:  1.0  train loss:  0.00010100611088210312 --time: 4.46805477142334\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.217271327972412\n",
      "train acc:  1.0  train loss:  9.960707266936484e-05 --time: 4.594513416290283\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.353996276855469\n",
      "train acc:  1.0  train loss:  9.83381994402684e-05 --time: 5.0203163623809814\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 5.733248710632324\n",
      "train acc:  1.0  train loss:  9.612293449564554e-05 --time: 5.131403923034668\n",
      "validation:  0.78 --max 0.7833333333333333 --time: 5.650821924209595\n",
      "train acc:  1.0  train loss:  9.493492625947313e-05 --time: 5.4568352699279785\n",
      "validation:  0.7833333333333333 --max 0.7833333333333333 --time: 6.111770391464233\n",
      "train acc:  1.0  train loss:  9.31632090688926e-05 --time: 5.36319375038147\n",
      "validation:  0.79 --max 0.79 --time: 5.887833833694458\n",
      "train acc:  1.0  train loss:  9.186806773473306e-05 --time: 5.296793460845947\n",
      "validation:  0.7866666666666666 --max 0.79 --time: 6.002588510513306\n",
      "train acc:  1.0  train loss:  9.046041510452557e-05 --time: 4.076764345169067\n",
      "validation:  0.78 --max 0.79 --time: 4.7927405834198\n",
      "train acc:  1.0  train loss:  9.043340168832599e-05 --time: 4.1309123039245605\n",
      "validation:  0.7833333333333333 --max 0.79 --time: 4.861278533935547\n",
      "train acc:  1.0  train loss:  8.868032138865522e-05 --time: 3.971438407897949\n",
      "validation:  0.78 --max 0.79 --time: 4.762753486633301\n",
      "train acc:  1.0  train loss:  8.712965791346505e-05 --time: 4.911069393157959\n",
      "validation:  0.7766666666666666 --max 0.79 --time: 5.5713605880737305\n",
      "train acc:  1.0  train loss:  8.556720991770777e-05 --time: 5.476036548614502\n",
      "validation:  0.7866666666666666 --max 0.79 --time: 6.199354410171509\n",
      "train acc:  1.0  train loss:  8.357590369363923e-05 --time: 5.360531806945801\n",
      "validation:  0.79 --max 0.79 --time: 5.871044635772705\n",
      "train acc:  1.0  train loss:  8.285798717026964e-05 --time: 5.415745973587036\n",
      "validation:  0.7866666666666666 --max 0.79 --time: 6.039488792419434\n",
      "train acc:  1.0  train loss:  8.139261215388694e-05 --time: 5.360165596008301\n",
      "validation:  0.7866666666666666 --max 0.79 --time: 6.093132972717285\n",
      "train acc:  1.0  train loss:  8.082024863182122e-05 --time: 5.369084119796753\n",
      "validation:  0.79 --max 0.79 --time: 5.957123279571533\n",
      "train acc:  1.0  train loss:  7.88606602050688e-05 --time: 5.007216930389404\n",
      "validation:  0.7833333333333333 --max 0.79 --time: 5.689298629760742\n",
      "train acc:  1.0  train loss:  7.802540494594723e-05 --time: 5.111707448959351\n",
      "validation:  0.79 --max 0.79 --time: 5.866225957870483\n",
      "train acc:  1.0  train loss:  7.709027135127184e-05 --time: 4.827478647232056\n",
      "validation:  0.7833333333333333 --max 0.79 --time: 5.496482849121094\n",
      "train acc:  1.0  train loss:  7.52881580568931e-05 --time: 4.763604164123535\n",
      "validation:  0.7866666666666666 --max 0.79 --time: 5.506727695465088\n",
      "train acc:  1.0  train loss:  7.415885098136799e-05 --time: 4.650706052780151\n",
      "validation:  0.79 --max 0.79 --time: 5.415587425231934\n",
      "train acc:  1.0  train loss:  7.308535208247359e-05 --time: 4.598876476287842\n",
      "validation:  0.7833333333333333 --max 0.79 --time: 5.352371454238892\n",
      "train acc:  1.0  train loss:  7.225869415813814e-05 --time: 4.559388875961304\n",
      "validation:  0.7866666666666666 --max 0.79 --time: 5.31955885887146\n",
      "train acc:  1.0  train loss:  7.156224234242235e-05 --time: 5.096559524536133\n",
      "validation:  0.79 --max 0.79 --time: 5.656043529510498\n",
      "train acc:  1.0  train loss:  7.078592993227927e-05 --time: 5.279448509216309\n",
      "validation:  0.7833333333333333 --max 0.79 --time: 5.941146373748779\n",
      "train acc:  1.0  train loss:  6.930794663038914e-05 --time: 5.277839422225952\n",
      "validation:  0.79 --max 0.79 --time: 5.856192350387573\n",
      "train acc:  1.0  train loss:  6.826068799811132e-05 --time: 5.408294677734375\n",
      "validation:  0.79 --max 0.79 --time: 6.15911340713501\n",
      "train acc:  1.0  train loss:  6.69545761015995e-05 --time: 5.233670473098755\n",
      "validation:  0.79 --max 0.79 --time: 5.897059440612793\n",
      "train acc:  1.0  train loss:  6.56859135589279e-05 --time: 5.025449752807617\n",
      "validation:  0.7833333333333333 --max 0.79 --time: 5.667327880859375\n",
      "train acc:  1.0  train loss:  6.540573019225596e-05 --time: 4.956483840942383\n",
      "validation:  0.79 --max 0.79 --time: 5.62915825843811\n",
      "train acc:  1.0  train loss:  6.41695938690606e-05 --time: 4.769439220428467\n",
      "validation:  0.79 --max 0.79 --time: 5.5166096687316895\n",
      "train acc:  1.0  train loss:  6.338231247829516e-05 --time: 4.6879119873046875\n",
      "validation:  0.7866666666666666 --max 0.79 --time: 5.365981101989746\n",
      "train acc:  1.0  train loss:  6.25483263992583e-05 --time: 5.103606224060059\n",
      "validation:  0.79 --max 0.79 --time: 5.882208347320557\n",
      "train acc:  1.0  train loss:  6.14966468318649e-05 --time: 4.735661268234253\n",
      "validation:  0.7833333333333333 --max 0.79 --time: 5.5218987464904785\n",
      "train acc:  1.0  train loss:  6.079957940686575e-05 --time: 4.65289568901062\n",
      "validation:  0.7866666666666666 --max 0.79 --time: 5.4367146492004395\n",
      "train acc:  1.0  train loss:  5.9706893016877785e-05 --time: 4.890913486480713\n",
      "validation:  0.7933333333333333 --max 0.7933333333333333 --time: 5.712361812591553\n",
      "train acc:  1.0  train loss:  5.878373691381927e-05 --time: 4.928304195404053\n",
      "validation:  0.7866666666666666 --max 0.7933333333333333 --time: 5.351600646972656\n",
      "train acc:  1.0  train loss:  5.8101327538125865e-05 --time: 5.592431545257568\n",
      "validation:  0.7866666666666666 --max 0.7933333333333333 --time: 6.140760183334351\n",
      "train acc:  1.0  train loss:  5.722658549885914e-05 --time: 5.744095087051392\n",
      "validation:  0.7866666666666666 --max 0.7933333333333333 --time: 6.19904088973999\n",
      "train acc:  1.0  train loss:  5.6770959022485286e-05 --time: 5.615972518920898\n",
      "validation:  0.7933333333333333 --max 0.7933333333333333 --time: 6.204530239105225\n",
      "train acc:  1.0  train loss:  5.562423662606465e-05 --time: 5.019039869308472\n",
      "validation:  0.7866666666666666 --max 0.7933333333333333 --time: 5.772832632064819\n",
      "train acc:  1.0  train loss:  5.4820186051074415e-05 --time: 3.8502371311187744\n",
      "validation:  0.7833333333333333 --max 0.7933333333333333 --time: 4.6015625\n",
      "train acc:  1.0  train loss:  5.405397251192683e-05 --time: 4.666762828826904\n",
      "validation:  0.79 --max 0.7933333333333333 --time: 5.4110846519470215\n",
      "train acc:  1.0  train loss:  5.32507988480021e-05 --time: 4.719683408737183\n",
      "validation:  0.7933333333333333 --max 0.7933333333333333 --time: 5.464434862136841\n",
      "train acc:  1.0  train loss:  5.25840759624059e-05 --time: 4.473927736282349\n",
      "validation:  0.7933333333333333 --max 0.7933333333333333 --time: 5.283136606216431\n",
      "train acc:  1.0  train loss:  5.164891516197594e-05 --time: 4.927846193313599\n",
      "validation:  0.79 --max 0.7933333333333333 --time: 5.640795946121216\n",
      "train acc:  1.0  train loss:  5.121567032208828e-05 --time: 5.089080095291138\n",
      "validation:  0.7866666666666666 --max 0.7933333333333333 --time: 5.771191120147705\n",
      "train acc:  1.0  train loss:  5.030212164654032e-05 --time: 4.9944517612457275\n",
      "validation:  0.79 --max 0.7933333333333333 --time: 5.699383974075317\n",
      "train acc:  1.0  train loss:  4.984740466486824e-05 --time: 4.973660707473755\n",
      "validation:  0.7933333333333333 --max 0.7933333333333333 --time: 5.6565775871276855\n",
      "train acc:  1.0  train loss:  4.9063259370007515e-05 --time: 5.087512493133545\n",
      "validation:  0.7933333333333333 --max 0.7933333333333333 --time: 5.7507004737854\n",
      "train acc:  1.0  train loss:  4.8356625326129645e-05 --time: 4.854942321777344\n",
      "validation:  0.7866666666666666 --max 0.7933333333333333 --time: 5.533200025558472\n",
      "train acc:  1.0  train loss:  4.7591447978250116e-05 --time: 5.061651706695557\n",
      "validation:  0.7866666666666666 --max 0.7933333333333333 --time: 5.7476677894592285\n",
      "train acc:  1.0  train loss:  4.683565376857903e-05 --time: 5.175589561462402\n",
      "validation:  0.7866666666666666 --max 0.7933333333333333 --time: 5.958959579467773\n",
      "train acc:  1.0  train loss:  4.627808780439765e-05 --time: 5.15450119972229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:  0.79 --max 0.7933333333333333 --time: 5.954129219055176\n",
      "train acc:  1.0  train loss:  4.5918592545406327e-05 --time: 4.927094459533691\n",
      "validation:  0.79 --max 0.7933333333333333 --time: 5.727493524551392\n",
      "train acc:  1.0  train loss:  4.498539435545631e-05 --time: 5.023127317428589\n",
      "validation:  0.7866666666666666 --max 0.7933333333333333 --time: 5.805574417114258\n",
      "train acc:  1.0  train loss:  4.463645872538505e-05 --time: 4.888556480407715\n",
      "validation:  0.7833333333333333 --max 0.7933333333333333 --time: 5.525676488876343\n",
      "train acc:  1.0  train loss:  4.40406996779569e-05 --time: 4.794149398803711\n",
      "validation:  0.79 --max 0.7933333333333333 --time: 5.452211141586304\n",
      "train acc:  1.0  train loss:  4.332711234936774e-05 --time: 5.065409183502197\n",
      "validation:  0.78 --max 0.7933333333333333 --time: 5.844436883926392\n",
      "train acc:  1.0  train loss:  4.2575862449745685e-05 --time: 4.925143718719482\n",
      "validation:  0.78 --max 0.7933333333333333 --time: 5.671648979187012\n",
      "train acc:  1.0  train loss:  4.218797403154895e-05 --time: 5.159793376922607\n",
      "validation:  0.78 --max 0.7933333333333333 --time: 5.8679327964782715\n",
      "train acc:  1.0  train loss:  4.1570092434994876e-05 --time: 4.8174052238464355\n",
      "validation:  0.7833333333333333 --max 0.7933333333333333 --time: 5.465355157852173\n",
      "train acc:  1.0  train loss:  4.1280803523714774e-05 --time: 4.988617658615112\n",
      "validation:  0.7866666666666666 --max 0.7933333333333333 --time: 5.62773323059082\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5aab3af95490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss_accum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mbatch_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(train_language, test_language)\n",
    "max_acc = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    #print(\"epoch \", i)\n",
    "    loss_accum = 0.0\n",
    "    batch_cnt = 0\n",
    "\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch, (x, lengths, y) in enumerate(train_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "        loss_score = loss.cpu().item()\n",
    "\n",
    "        loss_accum += loss_score\n",
    "        batch_cnt += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        target_val, tar_indices = torch.max(y, dim=1)\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    print(\"train acc: \", acc_cnt/(err_cnt+acc_cnt), \" train loss: \", loss_accum / batch_cnt, '--time:', time.time() - start_time)\n",
    "\n",
    "    model.eval()\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    #start_time = time.time()\n",
    "    for x, lengths, y in valid_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        target_val, tar_indices = torch.max(y, dim=1)\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    current_acc = acc_cnt/(err_cnt+acc_cnt)\n",
    "    if current_acc > max_acc:\n",
    "        max_acc = current_acc\n",
    "                \n",
    "    print(\"validation: \", current_acc, '--max', max_acc, '--time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
