{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import psutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/ubuntu/Intents-Analysis/Analysis')\n",
    "#sys.path.insert(1, '/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_vocab import load_data, get_vocab\n",
    "from get_frequency import get_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is True\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Needed Functions\n",
    "def load_data(filename):\n",
    "    a_file = open(filename, \"rb\")\n",
    "    output = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_vocabulary(train_file):\n",
    "    '''This function creates an indexed vocabulary dictionary from the training file'''\n",
    "    \n",
    "    vocab, _ = get_vocab(1, train_file)\n",
    "    \n",
    "    phone_to_idx = {'unk': 1}#Padding indx = 0, unkown_idx = 1, indexing starts from 2\n",
    "    for i, phone in enumerate(vocab):\n",
    "        phone_to_idx[phone] = i + 2\n",
    "        \n",
    "    return phone_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_file, intent_labels, phone_to_idx):\n",
    "        data = load_data(data_file)\n",
    "        self.all_data = []\n",
    "        \n",
    "        for intent in data:\n",
    "            for utterance in data[intent]:\n",
    "                utterance_to_idx = []\n",
    "                \n",
    "                for phone in utterance:\n",
    "                    if phone not in phone_to_idx:\n",
    "                        phone = 'unk'\n",
    "    \n",
    "                    utterance_to_idx.append(phone_to_idx[phone])\n",
    "                \n",
    "                self.all_data.append([utterance_to_idx, intent_labels[intent]])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        input_vector = self.all_data[index][0]\n",
    "        label = self.all_data[index][1]\n",
    "\n",
    "        return input_vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_indic(tuple_lst):\n",
    "\n",
    "    x_lst = [x[0] for x in tuple_lst]\n",
    "    y_lst = [x[1] for x in tuple_lst]\n",
    "\n",
    "    # collate x\n",
    "    B = len(tuple_lst)#Number of training samples\n",
    "    T = max(len(x) for x in x_lst)#Max length of a sentence\n",
    "\n",
    "    # x values\n",
    "    x = torch.zeros([B, T], dtype=torch.int64)\n",
    "    lengths = torch.zeros(B, dtype=torch.int64)\n",
    "\n",
    "    for i, x_np in enumerate(x_lst):\n",
    "        lengths[i] = len(x_np)\n",
    "        x[i,:len(x_np)] = torch.tensor(x_np)\n",
    "\n",
    "    # collate y\n",
    "    y = torch.tensor(y_lst)\n",
    "\n",
    "    ids = torch.argsort(lengths, descending=True)\n",
    "\n",
    "    return x[ids], lengths[ids], y[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "#Defining constants and labels\n",
    "intent_labels = {'movie-tickets':0, 'auto-repair':1, 'restaurant-table':2, 'pizza-ordering':3, 'uber-lyft':4, 'coffee-ordering':5}\n",
    "train_language = 'hindi'\n",
    "test_language = 'hindi'\n",
    "\n",
    "#Loading data\n",
    "train_file = '/home/ubuntu/Intents-Analysis/TaskMasterData/Get_Phones_Combos/1_lang_train_split/taskmaster_training_' + train_language + '.pkl'\n",
    "test_file = '/home/ubuntu/Intents-Analysis/TaskMasterData/Get_Phones_Combos/1_language/taskmaster_testing_' + test_language + '.pkl'\n",
    "\n",
    "#create vocabulary and phone_to_idx\n",
    "phone_to_idx = create_vocabulary(train_file)\n",
    "print(len(phone_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_file, intent_labels, phone_to_idx)\n",
    "train_loader_args = dict(shuffle=True, batch_size=64, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=32)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args, collate_fn=collate_indic)\n",
    "\n",
    "test_dataset = MyDataset(test_file, intent_labels, phone_to_idx)\n",
    "test_loader_args = dict(shuffle=False, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "valid_loader = DataLoader(test_dataset, **test_loader_args, collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=63, embed_size=128, hidden_size=128, label_size=6):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "        #self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(embed_size*2)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_size*2, hidden_size, num_layers=1)\n",
    "        self.linear = nn.Linear(hidden_size, label_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "\n",
    "        # B,T,H\n",
    "        input = self.embed(x)\n",
    "\n",
    "        # (B,T,H) -> (B,H,T)\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        print(input.shape)\n",
    "        cnn_out1 = self.cnn(input)\n",
    "        print(cnn_out1.shape)\n",
    "        cnn_out2 = self.cnn2(input)\n",
    "        print(cnn_out2.shape)\n",
    "        \n",
    "        cnn_output = torch.cat([cnn_out1, cnn_out2] , dim = 1)\n",
    "        \n",
    "#        cnn_output = torch.cat([self.cnn(input), self.cnn2(input)], dim=1)\n",
    "\n",
    "        # (B,H,T)\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n",
    "\n",
    "        output, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        #output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        #output = torch.cat([hn[0], hn[1]], dim=1)\n",
    "        logits = self.linear(hn[0])\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNClassifier(\n",
       "  (embed): Embedding(63, 128)\n",
       "  (cnn): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (cnn2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lstm): LSTM(256, 128)\n",
       "  (linear): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNClassifier()\n",
    "opt = optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#opt = SGD(model.parameters(), lr=0.05)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hindi hindi\n",
      "torch.Size([64, 128, 114])\n",
      "torch.Size([64, 128, 114])\n",
      "torch.Size([64, 128, 114])\n",
      "torch.Size([64, 128, 126])\n",
      "torch.Size([64, 128, 126])\n",
      "torch.Size([64, 128, 126])\n",
      "torch.Size([64, 128, 197])\n",
      "torch.Size([64, 128, 197])\n",
      "torch.Size([64, 128, 197])\n",
      "torch.Size([64, 128, 140])\n",
      "torch.Size([64, 128, 140])\n",
      "torch.Size([64, 128, 140])\n",
      "torch.Size([64, 128, 148])\n",
      "torch.Size([64, 128, 148])\n",
      "torch.Size([64, 128, 148])\n",
      "torch.Size([64, 128, 264])\n",
      "torch.Size([64, 128, 264])\n",
      "torch.Size([64, 128, 264])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 149])\n",
      "torch.Size([64, 128, 149])\n",
      "torch.Size([64, 128, 149])\n",
      "torch.Size([64, 128, 157])\n",
      "torch.Size([64, 128, 157])\n",
      "torch.Size([64, 128, 157])\n",
      "torch.Size([64, 128, 166])\n",
      "torch.Size([64, 128, 166])\n",
      "torch.Size([64, 128, 166])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 189])\n",
      "torch.Size([64, 128, 189])\n",
      "torch.Size([64, 128, 189])\n",
      "torch.Size([64, 128, 251])\n",
      "torch.Size([64, 128, 251])\n",
      "torch.Size([64, 128, 251])\n",
      "torch.Size([64, 128, 154])\n",
      "torch.Size([64, 128, 154])\n",
      "torch.Size([64, 128, 154])\n",
      "torch.Size([64, 128, 219])\n",
      "torch.Size([64, 128, 219])\n",
      "torch.Size([64, 128, 219])\n",
      "torch.Size([64, 128, 243])\n",
      "torch.Size([64, 128, 243])\n",
      "torch.Size([64, 128, 243])\n",
      "torch.Size([64, 128, 177])\n",
      "torch.Size([64, 128, 177])\n",
      "torch.Size([64, 128, 177])\n",
      "torch.Size([64, 128, 127])\n",
      "torch.Size([64, 128, 127])\n",
      "torch.Size([64, 128, 127])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 120])\n",
      "torch.Size([64, 128, 120])\n",
      "torch.Size([64, 128, 120])\n",
      "torch.Size([64, 128, 137])\n",
      "torch.Size([64, 128, 137])\n",
      "torch.Size([64, 128, 137])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 118])\n",
      "torch.Size([64, 128, 118])\n",
      "torch.Size([64, 128, 118])\n",
      "torch.Size([64, 128, 114])\n",
      "torch.Size([64, 128, 114])\n",
      "torch.Size([64, 128, 114])\n",
      "torch.Size([64, 128, 173])\n",
      "torch.Size([64, 128, 173])\n",
      "torch.Size([64, 128, 173])\n",
      "torch.Size([64, 128, 174])\n",
      "torch.Size([64, 128, 174])\n",
      "torch.Size([64, 128, 174])\n",
      "torch.Size([64, 128, 122])\n",
      "torch.Size([64, 128, 122])\n",
      "torch.Size([64, 128, 122])\n",
      "torch.Size([64, 128, 135])\n",
      "torch.Size([64, 128, 135])\n",
      "torch.Size([64, 128, 135])\n",
      "torch.Size([64, 128, 128])\n",
      "torch.Size([64, 128, 128])\n",
      "torch.Size([64, 128, 128])\n",
      "torch.Size([64, 128, 159])\n",
      "torch.Size([64, 128, 159])\n",
      "torch.Size([64, 128, 159])\n",
      "torch.Size([64, 128, 134])\n",
      "torch.Size([64, 128, 134])\n",
      "torch.Size([64, 128, 134])\n",
      "torch.Size([64, 128, 113])\n",
      "torch.Size([64, 128, 113])\n",
      "torch.Size([64, 128, 113])\n",
      "torch.Size([64, 128, 200])\n",
      "torch.Size([64, 128, 200])\n",
      "torch.Size([64, 128, 200])\n",
      "torch.Size([64, 128, 142])\n",
      "torch.Size([64, 128, 142])\n",
      "torch.Size([64, 128, 142])\n",
      "torch.Size([64, 128, 128])\n",
      "torch.Size([64, 128, 128])\n",
      "torch.Size([64, 128, 128])\n",
      "torch.Size([64, 128, 169])\n",
      "torch.Size([64, 128, 169])\n",
      "torch.Size([64, 128, 169])\n",
      "torch.Size([64, 128, 104])\n",
      "torch.Size([64, 128, 104])\n",
      "torch.Size([64, 128, 104])\n",
      "torch.Size([64, 128, 229])\n",
      "torch.Size([64, 128, 229])\n",
      "torch.Size([64, 128, 229])\n",
      "torch.Size([64, 128, 156])\n",
      "torch.Size([64, 128, 156])\n",
      "torch.Size([64, 128, 156])\n",
      "torch.Size([64, 128, 117])\n",
      "torch.Size([64, 128, 117])\n",
      "torch.Size([64, 128, 117])\n",
      "torch.Size([64, 128, 218])\n",
      "torch.Size([64, 128, 218])\n",
      "torch.Size([64, 128, 218])\n",
      "torch.Size([64, 128, 213])\n",
      "torch.Size([64, 128, 213])\n",
      "torch.Size([64, 128, 213])\n",
      "torch.Size([64, 128, 231])\n",
      "torch.Size([64, 128, 231])\n",
      "torch.Size([64, 128, 231])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 206])\n",
      "torch.Size([64, 128, 206])\n",
      "torch.Size([64, 128, 206])\n",
      "torch.Size([63, 128, 152])\n",
      "torch.Size([63, 128, 152])\n",
      "torch.Size([63, 128, 152])\n",
      "train acc:  0.2973156642881414  train loss:  1.6864709283994592 --time: 1.176805019378662\n",
      "torch.Size([128, 128, 208])\n",
      "torch.Size([128, 128, 208])\n",
      "torch.Size([128, 128, 208])\n",
      "torch.Size([128, 128, 166])\n",
      "torch.Size([128, 128, 166])\n",
      "torch.Size([128, 128, 166])\n",
      "torch.Size([44, 128, 97])\n",
      "torch.Size([44, 128, 97])\n",
      "torch.Size([44, 128, 97])\n",
      "validation:  0.29333333333333333 --max 0.29333333333333333 --time: 1.3641867637634277\n",
      "torch.Size([64, 128, 142])\n",
      "torch.Size([64, 128, 142])\n",
      "torch.Size([64, 128, 142])\n",
      "torch.Size([64, 128, 174])\n",
      "torch.Size([64, 128, 174])\n",
      "torch.Size([64, 128, 174])\n",
      "torch.Size([64, 128, 131])\n",
      "torch.Size([64, 128, 131])\n",
      "torch.Size([64, 128, 131])\n",
      "torch.Size([64, 128, 206])\n",
      "torch.Size([64, 128, 206])\n",
      "torch.Size([64, 128, 206])\n",
      "torch.Size([64, 128, 229])\n",
      "torch.Size([64, 128, 229])\n",
      "torch.Size([64, 128, 229])\n",
      "torch.Size([64, 128, 149])\n",
      "torch.Size([64, 128, 149])\n",
      "torch.Size([64, 128, 149])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 218])\n",
      "torch.Size([64, 128, 218])\n",
      "torch.Size([64, 128, 218])\n",
      "torch.Size([64, 128, 141])\n",
      "torch.Size([64, 128, 141])\n",
      "torch.Size([64, 128, 141])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 152])\n",
      "torch.Size([64, 128, 152])\n",
      "torch.Size([64, 128, 152])\n",
      "torch.Size([64, 128, 129])\n",
      "torch.Size([64, 128, 129])\n",
      "torch.Size([64, 128, 129])\n",
      "torch.Size([64, 128, 264])\n",
      "torch.Size([64, 128, 264])\n",
      "torch.Size([64, 128, 264])\n",
      "torch.Size([64, 128, 200])\n",
      "torch.Size([64, 128, 200])\n",
      "torch.Size([64, 128, 200])\n",
      "torch.Size([64, 128, 185])\n",
      "torch.Size([64, 128, 185])\n",
      "torch.Size([64, 128, 185])\n",
      "torch.Size([64, 128, 131])\n",
      "torch.Size([64, 128, 131])\n",
      "torch.Size([64, 128, 131])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 154])\n",
      "torch.Size([64, 128, 154])\n",
      "torch.Size([64, 128, 154])\n",
      "torch.Size([64, 128, 197])\n",
      "torch.Size([64, 128, 197])\n",
      "torch.Size([64, 128, 197])\n",
      "torch.Size([64, 128, 132])\n",
      "torch.Size([64, 128, 132])\n",
      "torch.Size([64, 128, 132])\n",
      "torch.Size([64, 128, 110])\n",
      "torch.Size([64, 128, 110])\n",
      "torch.Size([64, 128, 110])\n",
      "torch.Size([64, 128, 157])\n",
      "torch.Size([64, 128, 157])\n",
      "torch.Size([64, 128, 157])\n",
      "torch.Size([64, 128, 143])\n",
      "torch.Size([64, 128, 143])\n",
      "torch.Size([64, 128, 143])\n",
      "torch.Size([64, 128, 114])\n",
      "torch.Size([64, 128, 114])\n",
      "torch.Size([64, 128, 114])\n",
      "torch.Size([64, 128, 121])\n",
      "torch.Size([64, 128, 121])\n",
      "torch.Size([64, 128, 121])\n",
      "torch.Size([64, 128, 166])\n",
      "torch.Size([64, 128, 166])\n",
      "torch.Size([64, 128, 166])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 231])\n",
      "torch.Size([64, 128, 231])\n",
      "torch.Size([64, 128, 231])\n",
      "torch.Size([64, 128, 141])\n",
      "torch.Size([64, 128, 141])\n",
      "torch.Size([64, 128, 141])\n",
      "torch.Size([64, 128, 133])\n",
      "torch.Size([64, 128, 133])\n",
      "torch.Size([64, 128, 133])\n",
      "torch.Size([64, 128, 177])\n",
      "torch.Size([64, 128, 177])\n",
      "torch.Size([64, 128, 177])\n",
      "torch.Size([64, 128, 243])\n",
      "torch.Size([64, 128, 243])\n",
      "torch.Size([64, 128, 243])\n",
      "torch.Size([64, 128, 136])\n",
      "torch.Size([64, 128, 136])\n",
      "torch.Size([64, 128, 136])\n",
      "torch.Size([64, 128, 135])\n",
      "torch.Size([64, 128, 135])\n",
      "torch.Size([64, 128, 135])\n",
      "torch.Size([64, 128, 251])\n",
      "torch.Size([64, 128, 251])\n",
      "torch.Size([64, 128, 251])\n",
      "torch.Size([64, 128, 128])\n",
      "torch.Size([64, 128, 128])\n",
      "torch.Size([64, 128, 128])\n",
      "torch.Size([64, 128, 133])\n",
      "torch.Size([64, 128, 133])\n",
      "torch.Size([64, 128, 133])\n",
      "torch.Size([64, 128, 201])\n",
      "torch.Size([64, 128, 201])\n",
      "torch.Size([64, 128, 201])\n",
      "torch.Size([64, 128, 110])\n",
      "torch.Size([64, 128, 110])\n",
      "torch.Size([64, 128, 110])\n",
      "torch.Size([64, 128, 148])\n",
      "torch.Size([64, 128, 148])\n",
      "torch.Size([64, 128, 148])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 141])\n",
      "torch.Size([64, 128, 141])\n",
      "torch.Size([64, 128, 141])\n",
      "torch.Size([64, 128, 202])\n",
      "torch.Size([64, 128, 202])\n",
      "torch.Size([64, 128, 202])\n",
      "torch.Size([64, 128, 129])\n",
      "torch.Size([64, 128, 129])\n",
      "torch.Size([64, 128, 129])\n",
      "torch.Size([64, 128, 189])\n",
      "torch.Size([64, 128, 189])\n",
      "torch.Size([64, 128, 189])\n",
      "torch.Size([63, 128, 156])\n",
      "torch.Size([63, 128, 156])\n",
      "torch.Size([63, 128, 156])\n",
      "train acc:  0.3944954128440367  train loss:  1.5314843887868135 --time: 0.9978337287902832\n",
      "torch.Size([128, 128, 208])\n",
      "torch.Size([128, 128, 208])\n",
      "torch.Size([128, 128, 208])\n",
      "torch.Size([128, 128, 166])\n",
      "torch.Size([128, 128, 166])\n",
      "torch.Size([128, 128, 166])\n",
      "torch.Size([44, 128, 97])\n",
      "torch.Size([44, 128, 97])\n",
      "torch.Size([44, 128, 97])\n",
      "validation:  0.39 --max 0.39 --time: 1.1879496574401855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128, 108])\n",
      "torch.Size([64, 128, 108])\n",
      "torch.Size([64, 128, 108])\n",
      "torch.Size([64, 128, 201])\n",
      "torch.Size([64, 128, 201])\n",
      "torch.Size([64, 128, 201])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 124])\n",
      "torch.Size([64, 128, 124])\n",
      "torch.Size([64, 128, 124])\n",
      "torch.Size([64, 128, 114])\n",
      "torch.Size([64, 128, 114])\n",
      "torch.Size([64, 128, 114])\n",
      "torch.Size([64, 128, 251])\n",
      "torch.Size([64, 128, 251])\n",
      "torch.Size([64, 128, 251])\n",
      "torch.Size([64, 128, 138])\n",
      "torch.Size([64, 128, 138])\n",
      "torch.Size([64, 128, 138])\n",
      "torch.Size([64, 128, 107])\n",
      "torch.Size([64, 128, 107])\n",
      "torch.Size([64, 128, 107])\n",
      "torch.Size([64, 128, 147])\n",
      "torch.Size([64, 128, 147])\n",
      "torch.Size([64, 128, 147])\n",
      "torch.Size([64, 128, 170])\n",
      "torch.Size([64, 128, 170])\n",
      "torch.Size([64, 128, 170])\n",
      "torch.Size([64, 128, 148])\n",
      "torch.Size([64, 128, 148])\n",
      "torch.Size([64, 128, 148])\n",
      "torch.Size([64, 128, 213])\n",
      "torch.Size([64, 128, 213])\n",
      "torch.Size([64, 128, 213])\n",
      "torch.Size([64, 128, 145])\n",
      "torch.Size([64, 128, 145])\n",
      "torch.Size([64, 128, 145])\n",
      "torch.Size([64, 128, 264])\n",
      "torch.Size([64, 128, 264])\n",
      "torch.Size([64, 128, 264])\n",
      "torch.Size([64, 128, 103])\n",
      "torch.Size([64, 128, 103])\n",
      "torch.Size([64, 128, 103])\n",
      "torch.Size([64, 128, 152])\n",
      "torch.Size([64, 128, 152])\n",
      "torch.Size([64, 128, 152])\n",
      "torch.Size([64, 128, 117])\n",
      "torch.Size([64, 128, 117])\n",
      "torch.Size([64, 128, 117])\n",
      "torch.Size([64, 128, 159])\n",
      "torch.Size([64, 128, 159])\n",
      "torch.Size([64, 128, 159])\n",
      "torch.Size([64, 128, 120])\n",
      "torch.Size([64, 128, 120])\n",
      "torch.Size([64, 128, 120])\n",
      "torch.Size([64, 128, 133])\n",
      "torch.Size([64, 128, 133])\n",
      "torch.Size([64, 128, 133])\n",
      "torch.Size([64, 128, 177])\n",
      "torch.Size([64, 128, 177])\n",
      "torch.Size([64, 128, 177])\n",
      "torch.Size([64, 128, 134])\n",
      "torch.Size([64, 128, 134])\n",
      "torch.Size([64, 128, 134])\n",
      "torch.Size([64, 128, 200])\n",
      "torch.Size([64, 128, 200])\n",
      "torch.Size([64, 128, 200])\n",
      "torch.Size([64, 128, 173])\n",
      "torch.Size([64, 128, 173])\n",
      "torch.Size([64, 128, 173])\n",
      "torch.Size([64, 128, 189])\n",
      "torch.Size([64, 128, 189])\n",
      "torch.Size([64, 128, 189])\n",
      "torch.Size([64, 128, 185])\n",
      "torch.Size([64, 128, 185])\n",
      "torch.Size([64, 128, 185])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 202])\n",
      "torch.Size([64, 128, 202])\n",
      "torch.Size([64, 128, 202])\n",
      "torch.Size([64, 128, 197])\n",
      "torch.Size([64, 128, 197])\n",
      "torch.Size([64, 128, 197])\n",
      "torch.Size([64, 128, 112])\n",
      "torch.Size([64, 128, 112])\n",
      "torch.Size([64, 128, 112])\n",
      "torch.Size([64, 128, 110])\n",
      "torch.Size([64, 128, 110])\n",
      "torch.Size([64, 128, 110])\n",
      "torch.Size([64, 128, 243])\n",
      "torch.Size([64, 128, 243])\n",
      "torch.Size([64, 128, 243])\n",
      "torch.Size([64, 128, 111])\n",
      "torch.Size([64, 128, 111])\n",
      "torch.Size([64, 128, 111])\n",
      "torch.Size([64, 128, 141])\n",
      "torch.Size([64, 128, 141])\n",
      "torch.Size([64, 128, 141])\n",
      "torch.Size([64, 128, 211])\n",
      "torch.Size([64, 128, 211])\n",
      "torch.Size([64, 128, 211])\n",
      "torch.Size([64, 128, 127])\n",
      "torch.Size([64, 128, 127])\n",
      "torch.Size([64, 128, 127])\n",
      "torch.Size([64, 128, 219])\n",
      "torch.Size([64, 128, 219])\n",
      "torch.Size([64, 128, 219])\n",
      "torch.Size([64, 128, 140])\n",
      "torch.Size([64, 128, 140])\n",
      "torch.Size([64, 128, 140])\n",
      "torch.Size([64, 128, 231])\n",
      "torch.Size([64, 128, 231])\n",
      "torch.Size([64, 128, 231])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 187])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 125])\n",
      "torch.Size([64, 128, 137])\n",
      "torch.Size([64, 128, 137])\n",
      "torch.Size([64, 128, 137])\n",
      "torch.Size([64, 128, 206])\n",
      "torch.Size([64, 128, 206])\n",
      "torch.Size([64, 128, 206])\n",
      "torch.Size([64, 128, 218])\n",
      "torch.Size([64, 128, 218])\n",
      "torch.Size([64, 128, 218])\n",
      "torch.Size([63, 128, 128])\n",
      "torch.Size([63, 128, 128])\n",
      "torch.Size([63, 128, 128])\n",
      "train acc:  0.5511382942575603  train loss:  1.183547617300697 --time: 1.0259172916412354\n",
      "torch.Size([128, 128, 208])\n",
      "torch.Size([128, 128, 208])\n",
      "torch.Size([128, 128, 208])\n",
      "torch.Size([128, 128, 166])\n",
      "torch.Size([128, 128, 166])\n",
      "torch.Size([128, 128, 166])\n",
      "torch.Size([44, 128, 97])\n",
      "torch.Size([44, 128, 97])\n",
      "torch.Size([44, 128, 97])\n",
      "validation:  0.53 --max 0.53 --time: 1.2434601783752441\n",
      "torch.Size([64, 128, 218])\n",
      "torch.Size([64, 128, 218])\n",
      "torch.Size([64, 128, 218])\n",
      "torch.Size([64, 128, 127])\n",
      "torch.Size([64, 128, 127])\n",
      "torch.Size([64, 128, 127])\n",
      "torch.Size([64, 128, 111])\n",
      "torch.Size([64, 128, 111])\n",
      "torch.Size([64, 128, 111])\n",
      "torch.Size([64, 128, 99])\n",
      "torch.Size([64, 128, 99])\n",
      "torch.Size([64, 128, 99])\n",
      "torch.Size([64, 128, 206])\n",
      "torch.Size([64, 128, 206])\n",
      "torch.Size([64, 128, 206])\n",
      "torch.Size([64, 128, 109])\n",
      "torch.Size([64, 128, 109])\n",
      "torch.Size([64, 128, 109])\n",
      "torch.Size([64, 128, 135])\n",
      "torch.Size([64, 128, 135])\n",
      "torch.Size([64, 128, 135])\n",
      "torch.Size([64, 128, 231])\n",
      "torch.Size([64, 128, 231])\n",
      "torch.Size([64, 128, 231])\n",
      "torch.Size([64, 128, 177])\n",
      "torch.Size([64, 128, 177])\n",
      "torch.Size([64, 128, 177])\n",
      "torch.Size([64, 128, 117])\n",
      "torch.Size([64, 128, 117])\n",
      "torch.Size([64, 128, 117])\n",
      "torch.Size([64, 128, 211])\n",
      "torch.Size([64, 128, 211])\n",
      "torch.Size([64, 128, 211])\n",
      "torch.Size([64, 128, 138])\n",
      "torch.Size([64, 128, 138])\n",
      "torch.Size([64, 128, 138])\n",
      "torch.Size([64, 128, 229])\n",
      "torch.Size([64, 128, 229])\n",
      "torch.Size([64, 128, 229])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 140])\n",
      "torch.Size([64, 128, 140])\n",
      "torch.Size([64, 128, 140])\n",
      "torch.Size([64, 128, 122])\n",
      "torch.Size([64, 128, 122])\n",
      "torch.Size([64, 128, 122])\n",
      "torch.Size([64, 128, 202])\n",
      "torch.Size([64, 128, 202])\n",
      "torch.Size([64, 128, 202])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 119])\n",
      "torch.Size([64, 128, 119])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-cb6c7a8ad996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss_accum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mbatch_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(train_language, test_language)\n",
    "max_acc = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    #print(\"epoch \", i)\n",
    "    loss_accum = 0.0\n",
    "    batch_cnt = 0\n",
    "\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch, (x, lengths, y) in enumerate(train_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        loss = criterion(logits, y)\n",
    "        loss_score = loss.cpu().item()\n",
    "\n",
    "        loss_accum += loss_score\n",
    "        batch_cnt += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    print(\"train acc: \", acc_cnt/(err_cnt+acc_cnt), \" train loss: \", loss_accum / batch_cnt, '--time:', time.time() - start_time)\n",
    "\n",
    "    model.eval()\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    #start_time = time.time()\n",
    "    for x, lengths, y in valid_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    current_acc = acc_cnt/(err_cnt+acc_cnt)\n",
    "    if current_acc > max_acc:\n",
    "        max_acc = current_acc\n",
    "                \n",
    "    print(\"validation: \", current_acc, '--max', max_acc, '--time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
