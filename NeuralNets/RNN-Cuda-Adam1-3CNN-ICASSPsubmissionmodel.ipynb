{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import psutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/ubuntu/Intents-Analysis/Analysis')\n",
    "#sys.path.insert(1, '/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_vocab import load_data, get_vocab\n",
    "from get_frequency import get_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is True\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Needed Functions\n",
    "def load_data(filename):\n",
    "    a_file = open(filename, \"rb\")\n",
    "    output = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_vocabulary(train_file):\n",
    "    '''This function creates an indexed vocabulary dictionary from the training file'''\n",
    "    \n",
    "    vocab, _ = get_vocab(1, train_file)\n",
    "    \n",
    "    phone_to_idx = {'unk': 1}#Padding indx = 0, unkown_idx = 1, indexing starts from 2\n",
    "    for i, phone in enumerate(vocab):\n",
    "        phone_to_idx[phone] = i + 2\n",
    "        \n",
    "    return phone_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_file, intent_labels, phone_to_idx):\n",
    "        data = load_data(data_file)\n",
    "        self.all_data = []\n",
    "        \n",
    "        for intent in data:\n",
    "            for utterance in data[intent]:\n",
    "                if len(utterance) != 0:\n",
    "                    utterance_to_idx = []\n",
    "\n",
    "                    for phone in utterance:\n",
    "                        if phone not in phone_to_idx:\n",
    "                            phone = 'unk'\n",
    "\n",
    "                        utterance_to_idx.append(phone_to_idx[phone])\n",
    "\n",
    "                    self.all_data.append([utterance_to_idx, intent_labels[intent]])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        input_vector = self.all_data[index][0]\n",
    "        label = self.all_data[index][1]\n",
    "\n",
    "        return input_vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_indic(tuple_lst):\n",
    "\n",
    "    x_lst = [x[0] for x in tuple_lst]\n",
    "    y_lst = [x[1] for x in tuple_lst]\n",
    "\n",
    "    # collate x\n",
    "    B = len(tuple_lst)#Number of training samples\n",
    "    T = max(len(x) for x in x_lst)#Max length of a sentence\n",
    "\n",
    "    # x values\n",
    "    x = torch.zeros([B, T], dtype=torch.int64)\n",
    "    lengths = torch.zeros(B, dtype=torch.int64)\n",
    "\n",
    "    for i, x_np in enumerate(x_lst):\n",
    "        lengths[i] = len(x_np)\n",
    "        x[i,:len(x_np)] = torch.tensor(x_np)\n",
    "\n",
    "    # collate y\n",
    "    y = torch.tensor(y_lst)\n",
    "\n",
    "    ids = torch.argsort(lengths, descending=True)\n",
    "\n",
    "    return x[ids], lengths[ids], y[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domains():\n",
    "    all_intents = ['increase', 'decrease', 'activate', 'deactivate', 'bring', 'change language']\n",
    "    return all_intents\n",
    "\n",
    "def get_intents():\n",
    "    all_intents = [\n",
    "        'activate|lamp',\n",
    "        'activate|lights|bedroom',\n",
    "        'activate|lights|kitchen',\n",
    "        'activate|lights|none',\n",
    "        'activate|lights|washroom',\n",
    "        'activate|music',\n",
    "        'bring|juice',\n",
    "        'bring|newspaper',\n",
    "        'bring|shoes',\n",
    "        'bring|socks',\n",
    "        'change language|Chinese',\n",
    "        'change language|English',\n",
    "        'change language|German',\n",
    "        'change language|Korean',\n",
    "        'change language|none',\n",
    "        'deactivate|lamp',\n",
    "        'deactivate|lights|bedroom',\n",
    "        'deactivate|lights|kitchen',\n",
    "        'deactivate|lights|none',\n",
    "        'deactivate|lights|washroom',\n",
    "        'deactivate|music',\n",
    "        'decrease|heat|bedroom',\n",
    "        'decrease|heat|kitchen',\n",
    "        'decrease|heat|none',\n",
    "        'decrease|heat|washroom',\n",
    "        'decrease|volume',\n",
    "        'increase|heat|bedroom',\n",
    "        'increase|heat|kitchen',\n",
    "        'increase|heat|none',\n",
    "        'increase|heat|washroom',\n",
    "        'increase|volume'\n",
    "        ]\n",
    "\n",
    "    return all_intents\n",
    "\n",
    "def get_intent_labels(class_type):\n",
    "    if class_type == 'domain':\n",
    "        all_intents = get_domains()\n",
    "    else:\n",
    "        all_intents = get_intents()\n",
    "        \n",
    "    intent_labels = {}\n",
    "    labels_to_intents = {}\n",
    "    for i, intent in enumerate(all_intents):\n",
    "        intent_labels[intent] = i\n",
    "        labels_to_intents[i] = intent\n",
    "        \n",
    "    return intent_labels, labels_to_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "class_type = 'intents'\n",
    "split = 'train'\n",
    "\n",
    "intent_labels, labels_to_intents = get_intent_labels(class_type)\n",
    "\n",
    "#Loading data\n",
    "train_file = '../FSC/fsc_' + class_type + '_' + split + '.pkl'\n",
    "test_file = '../FSC/fsc_' + class_type + '_test.pkl'\n",
    "#create vocabulary and phone_to_idx\n",
    "phone_to_idx = create_vocabulary(train_file)\n",
    "print(len(phone_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_file, intent_labels, phone_to_idx)\n",
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=32)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args, collate_fn=collate_indic)\n",
    "\n",
    "test_dataset = MyDataset(test_file, intent_labels, phone_to_idx)\n",
    "test_loader_args = dict(shuffle=False, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "valid_loader = DataLoader(test_dataset, **test_loader_args, collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=50, embed_size=128, hidden_size=128, label_size=31):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "        self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(embed_size*3)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_size*3, hidden_size, num_layers=1)\n",
    "        self.linear = nn.Linear(hidden_size, label_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "\n",
    "        # B,T,H\n",
    "        input = self.embed(x)\n",
    "\n",
    "        # (B,T,H) -> (B,H,T)\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input), self.cnn3(input)], dim=1)\n",
    "\n",
    "        # (B,H,T)\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n",
    "\n",
    "        output, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        #output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        #output = torch.cat([hn[0], hn[1]], dim=1)\n",
    "        logits = self.linear(hn[0])\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNClassifier(\n",
       "  (embed): Embedding(50, 128)\n",
       "  (cnn): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (cnn2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (cnn3): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  (batchnorm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lstm): LSTM(384, 128)\n",
       "  (linear): Linear(in_features=128, out_features=31, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNClassifier()\n",
    "opt = optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#opt = SGD(model.parameters(), lr=0.05)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intents train\n",
      "train acc:  0.5165866528264348  train loss:  1.6675398188401322 --time: 2.469726800918579\n",
      "validation:  0.7813818565400844 --max 0.7813818565400844 --time: 2.8529651165008545\n",
      "train acc:  0.7859954154232084  train loss:  0.718407125762813 --time: 2.4873828887939453\n",
      "validation:  0.8536392405063291 --max 0.8536392405063291 --time: 2.8632278442382812\n",
      "train acc:  0.8539855542580338  train loss:  0.48822656619614657 --time: 2.4400782585144043\n",
      "validation:  0.870253164556962 --max 0.870253164556962 --time: 2.822322130203247\n",
      "train acc:  0.8917866874270144  train loss:  0.3635806329342542 --time: 2.393261432647705\n",
      "validation:  0.8768459915611815 --max 0.8768459915611815 --time: 2.783095598220825\n",
      "train acc:  0.9157908394965616  train loss:  0.28415711487525075 --time: 2.3808517456054688\n",
      "validation:  0.8905590717299579 --max 0.8905590717299579 --time: 2.764533281326294\n",
      "train acc:  0.9341723973876562  train loss:  0.2266840956158401 --time: 2.4204747676849365\n",
      "validation:  0.890295358649789 --max 0.8905590717299579 --time: 2.808077573776245\n",
      "train acc:  0.9494399031183772  train loss:  0.17962409522981274 --time: 2.401740789413452\n",
      "validation:  0.8953059071729957 --max 0.8953059071729957 --time: 2.7811012268066406\n",
      "train acc:  0.9577872929371567  train loss:  0.14624140172867486 --time: 2.3882908821105957\n",
      "validation:  0.8921413502109705 --max 0.8953059071729957 --time: 2.7716522216796875\n",
      "train acc:  0.9710220146187448  train loss:  0.1122462936980619 --time: 2.3670966625213623\n",
      "validation:  0.8937236286919831 --max 0.8953059071729957 --time: 2.7482001781463623\n",
      "train acc:  0.9807966783443622  train loss:  0.0821147648133955 --time: 2.367591142654419\n",
      "validation:  0.8931962025316456 --max 0.8953059071729957 --time: 2.7457714080810547\n",
      "train acc:  0.9830889667401929  train loss:  0.07075674060052929 --time: 2.3855621814727783\n",
      "validation:  0.8971518987341772 --max 0.8971518987341772 --time: 2.7597782611846924\n",
      "train acc:  0.9850352493404264  train loss:  0.06562672890928568 --time: 2.4378671646118164\n",
      "validation:  0.8931962025316456 --max 0.8971518987341772 --time: 2.815556764602661\n",
      "train acc:  0.9833052203624411  train loss:  0.06766635640550055 --time: 2.3986408710479736\n",
      "validation:  0.8921413502109705 --max 0.8971518987341772 --time: 2.778646945953369\n",
      "train acc:  0.9880628000519008  train loss:  0.051484337148580764 --time: 2.4319353103637695\n",
      "validation:  0.8971518987341772 --max 0.8971518987341772 --time: 2.8122684955596924\n",
      "train acc:  0.9919121145279184  train loss:  0.03902407389813365 --time: 2.4456708431243896\n",
      "validation:  0.8929324894514767 --max 0.8971518987341772 --time: 2.8359320163726807\n",
      "train acc:  0.988884563816444  train loss:  0.0443033296923611 --time: 2.4375405311584473\n",
      "validation:  0.8963607594936709 --max 0.8971518987341772 --time: 2.8208723068237305\n",
      "train acc:  0.9877167942563038  train loss:  0.04861496386854029 --time: 2.4678266048431396\n",
      "validation:  0.8916139240506329 --max 0.8971518987341772 --time: 2.859687328338623\n",
      "train acc:  0.9860300160027681  train loss:  0.051726814287390496 --time: 2.444613456726074\n",
      "validation:  0.8895042194092827 --max 0.8971518987341772 --time: 2.8293418884277344\n",
      "train acc:  0.990052333376584  train loss:  0.03933823553752669 --time: 2.444298028945923\n",
      "validation:  0.8997890295358649 --max 0.8997890295358649 --time: 2.828716278076172\n",
      "train acc:  0.9948531637904935  train loss:  0.024918797001427875 --time: 2.4416000843048096\n",
      "validation:  0.8968881856540084 --max 0.8997890295358649 --time: 2.8250463008880615\n",
      "train acc:  0.9967561956662774  train loss:  0.016322509371495462 --time: 2.4385929107666016\n",
      "validation:  0.9032172995780591 --max 0.9032172995780591 --time: 2.820608615875244\n",
      "train acc:  0.9981834695731153  train loss:  0.009916735034775586 --time: 2.4612724781036377\n",
      "validation:  0.9032172995780591 --max 0.9032172995780591 --time: 2.8452365398406982\n",
      "train acc:  0.9979239652264176  train loss:  0.009155951478281856 --time: 2.453589916229248\n",
      "validation:  0.9077004219409283 --max 0.9077004219409283 --time: 2.8360424041748047\n",
      "train acc:  0.9983997231953635  train loss:  0.0071418684680858695 --time: 2.4578745365142822\n",
      "validation:  0.8982067510548524 --max 0.9077004219409283 --time: 2.8422911167144775\n",
      "train acc:  0.9737035595346222  train loss:  0.0812776385490057 --time: 2.4295225143432617\n",
      "validation:  0.8699894514767933 --max 0.9077004219409283 --time: 2.8151752948760986\n",
      "train acc:  0.9728817957700792  train loss:  0.08452480594056416 --time: 2.4436779022216797\n",
      "validation:  0.8931962025316456 --max 0.9077004219409283 --time: 2.8270392417907715\n",
      "train acc:  0.9892738203364906  train loss:  0.036384762372842154 --time: 2.4520304203033447\n",
      "validation:  0.8945147679324894 --max 0.9077004219409283 --time: 2.838777780532837\n",
      "train acc:  0.9965399420440293  train loss:  0.01602876051817892 --time: 2.4240198135375977\n",
      "validation:  0.9018987341772152 --max 0.9077004219409283 --time: 2.807060718536377\n",
      "train acc:  0.9981834695731153  train loss:  0.008014422771263642 --time: 2.445284605026245\n",
      "validation:  0.9040084388185654 --max 0.9077004219409283 --time: 2.8275091648101807\n",
      "train acc:  0.9982699710220146  train loss:  0.006583885310953534 --time: 2.419710159301758\n",
      "validation:  0.9008438818565401 --max 0.9077004219409283 --time: 2.807814359664917\n",
      "train acc:  0.9983564724709139  train loss:  0.005438037773334416 --time: 2.401606321334839\n",
      "validation:  0.9058544303797469 --max 0.9077004219409283 --time: 2.7952027320861816\n",
      "train acc:  0.9984429739198132  train loss:  0.0049296764493534 --time: 2.46012544631958\n",
      "validation:  0.9042721518987342 --max 0.9077004219409283 --time: 2.8458173274993896\n",
      "train acc:  0.998226720297565  train loss:  0.0054892167305568675 --time: 2.4664952754974365\n",
      "validation:  0.9066455696202531 --max 0.9077004219409283 --time: 2.852283000946045\n",
      "train acc:  0.9979239652264176  train loss:  0.006464266083177529 --time: 2.4297056198120117\n",
      "validation:  0.9032172995780591 --max 0.9077004219409283 --time: 2.8128392696380615\n",
      "train acc:  0.9979672159508671  train loss:  0.007733727710769198 --time: 2.486832618713379\n",
      "validation:  0.9003164556962026 --max 0.9077004219409283 --time: 2.871182441711426\n",
      "train acc:  0.9968426971151767  train loss:  0.01021921752986771 --time: 2.423173427581787\n",
      "validation:  0.8852848101265823 --max 0.9077004219409283 --time: 2.8072049617767334\n",
      "train acc:  0.9477531248648415  train loss:  0.15626390953419617 --time: 2.516820192337036\n",
      "validation:  0.8924050632911392 --max 0.9077004219409283 --time: 2.9005675315856934\n",
      "train acc:  0.9819644479045024  train loss:  0.05798814300632938 --time: 2.421386241912842\n",
      "validation:  0.892668776371308 --max 0.9077004219409283 --time: 2.807419776916504\n",
      "train acc:  0.9953289217594394  train loss:  0.01901385957858839 --time: 2.4301130771636963\n",
      "validation:  0.8958333333333334 --max 0.9077004219409283 --time: 2.8226654529571533\n",
      "train acc:  0.997750962328619  train loss:  0.009320705120570092 --time: 2.441577434539795\n",
      "validation:  0.8987341772151899 --max 0.9077004219409283 --time: 2.832066297531128\n",
      "train acc:  0.9982699710220146  train loss:  0.005965241207226658 --time: 2.42937970161438\n",
      "validation:  0.9016350210970464 --max 0.9077004219409283 --time: 2.8191628456115723\n",
      "train acc:  0.9983997231953635  train loss:  0.004880381218744288 --time: 2.459160089492798\n",
      "validation:  0.9011075949367089 --max 0.9077004219409283 --time: 2.845731019973755\n",
      "train acc:  0.9983564724709139  train loss:  0.004655416814021211 --time: 2.46903395652771\n",
      "validation:  0.9024261603375527 --max 0.9077004219409283 --time: 2.8687000274658203\n",
      "train acc:  0.9982699710220146  train loss:  0.0043798872988120505 --time: 2.4603917598724365\n",
      "validation:  0.9029535864978903 --max 0.9077004219409283 --time: 2.853057384490967\n",
      "train acc:  0.9983997231953635  train loss:  0.004293680103246164 --time: 2.4555063247680664\n",
      "validation:  0.8997890295358649 --max 0.9077004219409283 --time: 2.842214345932007\n",
      "train acc:  0.9983997231953635  train loss:  0.004225534098306465 --time: 2.447300910949707\n",
      "validation:  0.9032172995780591 --max 0.9077004219409283 --time: 2.8308026790618896\n",
      "train acc:  0.9982699710220146  train loss:  0.0042377011028815635 --time: 2.475274085998535\n",
      "validation:  0.9013713080168776 --max 0.9077004219409283 --time: 2.864867925643921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc:  0.9983997231953635  train loss:  0.003991841839450201 --time: 2.4491934776306152\n",
      "validation:  0.9011075949367089 --max 0.9077004219409283 --time: 2.840744972229004\n",
      "train acc:  0.9983132217464643  train loss:  0.003972621772564351 --time: 2.445578098297119\n",
      "validation:  0.9021624472573839 --max 0.9077004219409283 --time: 2.8278565406799316\n",
      "train acc:  0.9982699710220146  train loss:  0.0037838076739777804 --time: 2.464376926422119\n",
      "validation:  0.9016350210970464 --max 0.9077004219409283 --time: 2.8417773246765137\n",
      "train acc:  0.9983564724709139  train loss:  0.0036544866167048753 --time: 2.454164743423462\n",
      "validation:  0.9024261603375527 --max 0.9077004219409283 --time: 2.838174819946289\n",
      "train acc:  0.9983132217464643  train loss:  0.0038223079574880967 --time: 2.4409687519073486\n",
      "validation:  0.9005801687763713 --max 0.9077004219409283 --time: 2.826876163482666\n",
      "train acc:  0.9983997231953635  train loss:  0.003731739500026831 --time: 2.4211947917938232\n",
      "validation:  0.8997890295358649 --max 0.9077004219409283 --time: 2.802250385284424\n",
      "train acc:  0.9984429739198132  train loss:  0.0037017074808026844 --time: 2.4175007343292236\n",
      "validation:  0.8995253164556962 --max 0.9077004219409283 --time: 2.8069934844970703\n",
      "train acc:  0.9983132217464643  train loss:  0.004278632592797686 --time: 2.481870651245117\n",
      "validation:  0.897415611814346 --max 0.9077004219409283 --time: 2.8614439964294434\n",
      "train acc:  0.9542839842567363  train loss:  0.14312811329309927 --time: 2.4395272731781006\n",
      "validation:  0.8757911392405063 --max 0.9077004219409283 --time: 2.8322765827178955\n",
      "train acc:  0.9570520306215129  train loss:  0.12762332116948308 --time: 2.4408180713653564\n",
      "validation:  0.8921413502109705 --max 0.9077004219409283 --time: 2.8220627307891846\n",
      "train acc:  0.9904848406210804  train loss:  0.03215262447406656 --time: 2.4563100337982178\n",
      "validation:  0.8992616033755274 --max 0.9077004219409283 --time: 2.8374693393707275\n",
      "train acc:  0.9980537173997664  train loss:  0.009886403180895507 --time: 2.4197921752929688\n",
      "validation:  0.9024261603375527 --max 0.9077004219409283 --time: 2.7982337474823\n",
      "train acc:  0.998226720297565  train loss:  0.0061824967202251955 --time: 2.4802985191345215\n",
      "validation:  0.9034810126582279 --max 0.9077004219409283 --time: 2.8673782348632812\n",
      "train acc:  0.9983997231953635  train loss:  0.004936761464293306 --time: 2.4504241943359375\n",
      "validation:  0.9063818565400844 --max 0.9077004219409283 --time: 2.8403165340423584\n",
      "train acc:  0.9983132217464643  train loss:  0.004529201630142759 --time: 2.475466728210449\n",
      "validation:  0.9050632911392406 --max 0.9077004219409283 --time: 2.8707025051116943\n",
      "train acc:  0.9983564724709139  train loss:  0.004281890576156062 --time: 2.450232982635498\n",
      "validation:  0.9071729957805907 --max 0.9077004219409283 --time: 2.840616464614868\n",
      "train acc:  0.9981402188486657  train loss:  0.004223645302963582 --time: 2.4591481685638428\n",
      "validation:  0.9058544303797469 --max 0.9077004219409283 --time: 2.854280948638916\n",
      "train acc:  0.9985294753687124  train loss:  0.003917137199809559 --time: 2.437833309173584\n",
      "validation:  0.9042721518987342 --max 0.9077004219409283 --time: 2.825040340423584\n",
      "train acc:  0.998226720297565  train loss:  0.003792317048550033 --time: 2.420119047164917\n",
      "validation:  0.9066455696202531 --max 0.9077004219409283 --time: 2.801751136779785\n",
      "train acc:  0.9981834695731153  train loss:  0.003793030960848092 --time: 2.4493021965026855\n",
      "validation:  0.9058544303797469 --max 0.9077004219409283 --time: 2.836085557937622\n",
      "train acc:  0.9984862246442628  train loss:  0.0037030150846305474 --time: 2.480297565460205\n",
      "validation:  0.9037447257383966 --max 0.9077004219409283 --time: 2.866495132446289\n",
      "train acc:  0.9983564724709139  train loss:  0.0035146863620409237 --time: 2.4344210624694824\n",
      "validation:  0.9047995780590717 --max 0.9077004219409283 --time: 2.8247790336608887\n",
      "train acc:  0.9984429739198132  train loss:  0.0037488275540745637 --time: 2.5058891773223877\n",
      "validation:  0.9042721518987342 --max 0.9077004219409283 --time: 2.897002935409546\n",
      "train acc:  0.9984429739198132  train loss:  0.0036403252450538316 --time: 2.44238018989563\n",
      "validation:  0.9055907172995781 --max 0.9077004219409283 --time: 2.830980062484741\n",
      "train acc:  0.9983132217464643  train loss:  0.0033865479843431146 --time: 2.4391586780548096\n",
      "validation:  0.9045358649789029 --max 0.9077004219409283 --time: 2.8219101428985596\n",
      "train acc:  0.9983132217464643  train loss:  0.0038098789569349363 --time: 2.462876558303833\n",
      "validation:  0.9026898734177216 --max 0.9077004219409283 --time: 2.844411849975586\n",
      "train acc:  0.9983564724709139  train loss:  0.0034919479757821374 --time: 2.4328479766845703\n",
      "validation:  0.9045358649789029 --max 0.9077004219409283 --time: 2.824349880218506\n",
      "train acc:  0.9984862246442628  train loss:  0.0034934422799588042 --time: 2.4298791885375977\n",
      "validation:  0.9018987341772152 --max 0.9077004219409283 --time: 2.8150975704193115\n",
      "train acc:  0.9983997231953635  train loss:  0.0035712983211932075 --time: 2.4141526222229004\n",
      "validation:  0.9032172995780591 --max 0.9077004219409283 --time: 2.799447536468506\n",
      "train acc:  0.9441200640110722  train loss:  0.16731236437856584 --time: 2.5018112659454346\n",
      "validation:  0.8895042194092827 --max 0.9077004219409283 --time: 2.8894762992858887\n",
      "train acc:  0.9822239522512002  train loss:  0.05510337602408881 --time: 2.4324703216552734\n",
      "validation:  0.8931962025316456 --max 0.9077004219409283 --time: 2.8222622871398926\n",
      "train acc:  0.995847930452835  train loss:  0.015358347356324574 --time: 2.4309375286102295\n",
      "validation:  0.9029535864978903 --max 0.9077004219409283 --time: 2.8193163871765137\n",
      "train acc:  0.9980537173997664  train loss:  0.007557286061500894 --time: 2.385451078414917\n",
      "validation:  0.9005801687763713 --max 0.9077004219409283 --time: 2.7726540565490723\n",
      "train acc:  0.9981834695731153  train loss:  0.004944879286382244 --time: 2.4058096408843994\n",
      "validation:  0.9011075949367089 --max 0.9077004219409283 --time: 2.7805399894714355\n",
      "train acc:  0.9982699710220146  train loss:  0.0043023036180568335 --time: 2.4111037254333496\n",
      "validation:  0.9021624472573839 --max 0.9077004219409283 --time: 2.7993392944335938\n",
      "train acc:  0.998572726093162  train loss:  0.003900303747517813 --time: 2.428941011428833\n",
      "validation:  0.9040084388185654 --max 0.9077004219409283 --time: 2.826125144958496\n",
      "train acc:  0.9985294753687124  train loss:  0.0036923929031755652 --time: 2.457571029663086\n",
      "validation:  0.9024261603375527 --max 0.9077004219409283 --time: 2.8403728008270264\n",
      "train acc:  0.9983132217464643  train loss:  0.0037713910206040955 --time: 2.4425103664398193\n",
      "validation:  0.9040084388185654 --max 0.9077004219409283 --time: 2.8297905921936035\n",
      "train acc:  0.9985294753687124  train loss:  0.00363171299728462 --time: 2.390331268310547\n",
      "validation:  0.9050632911392406 --max 0.9077004219409283 --time: 2.7697813510894775\n",
      "train acc:  0.9983564724709139  train loss:  0.0035196627128112916 --time: 2.408787250518799\n",
      "validation:  0.9040084388185654 --max 0.9077004219409283 --time: 2.784487724304199\n",
      "train acc:  0.9983997231953635  train loss:  0.003476422159155594 --time: 2.378643751144409\n",
      "validation:  0.9026898734177216 --max 0.9077004219409283 --time: 2.750808000564575\n",
      "train acc:  0.9983997231953635  train loss:  0.003637840625722584 --time: 2.38179874420166\n",
      "validation:  0.9018987341772152 --max 0.9077004219409283 --time: 2.759061813354492\n",
      "train acc:  0.9982699710220146  train loss:  0.003561413295705962 --time: 2.395127296447754\n",
      "validation:  0.9034810126582279 --max 0.9077004219409283 --time: 2.7757956981658936\n",
      "train acc:  0.9982699710220146  train loss:  0.0036379958209337266 --time: 2.4076309204101562\n",
      "validation:  0.9026898734177216 --max 0.9077004219409283 --time: 2.788959264755249\n",
      "train acc:  0.998226720297565  train loss:  0.0035738972089162033 --time: 2.39680814743042\n",
      "validation:  0.9026898734177216 --max 0.9077004219409283 --time: 2.778866767883301\n",
      "train acc:  0.9984862246442628  train loss:  0.0033196527951458747 --time: 2.3923473358154297\n",
      "validation:  0.9032172995780591 --max 0.9077004219409283 --time: 2.7745003700256348\n",
      "train acc:  0.9986159768176117  train loss:  0.0033519458293738563 --time: 2.3761487007141113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:  0.9058544303797469 --max 0.9077004219409283 --time: 2.7563092708587646\n",
      "train acc:  0.9983132217464643  train loss:  0.00340975134055264 --time: 2.426187038421631\n",
      "validation:  0.9011075949367089 --max 0.9077004219409283 --time: 2.805589199066162\n",
      "train acc:  0.9984862246442628  train loss:  0.003330391525141046 --time: 2.4181902408599854\n",
      "validation:  0.9018987341772152 --max 0.9077004219409283 --time: 2.803863286972046\n",
      "train acc:  0.9983132217464643  train loss:  0.0032967320486269017 --time: 2.3692355155944824\n",
      "validation:  0.9013713080168776 --max 0.9077004219409283 --time: 2.7492141723632812\n",
      "train acc:  0.9983997231953635  train loss:  0.0032081733979844327 --time: 2.418705940246582\n",
      "validation:  0.9032172995780591 --max 0.9077004219409283 --time: 2.801574230194092\n",
      "train acc:  0.9983997231953635  train loss:  0.003298589139044779 --time: 2.355790853500366\n",
      "validation:  0.9029535864978903 --max 0.9077004219409283 --time: 2.7329015731811523\n",
      "train acc:  0.9983132217464643  train loss:  0.0033370044259840074 --time: 2.401599168777466\n",
      "validation:  0.9040084388185654 --max 0.9077004219409283 --time: 2.776829957962036\n",
      "train acc:  0.9983997231953635  train loss:  0.0031788094933672155 --time: 2.411398410797119\n",
      "validation:  0.9016350210970464 --max 0.9077004219409283 --time: 2.787289619445801\n",
      "train acc:  0.9983997231953635  train loss:  0.003122679604836791 --time: 2.4260456562042236\n",
      "validation:  0.9032172995780591 --max 0.9077004219409283 --time: 2.8046071529388428\n",
      "train acc:  0.9638423943601055  train loss:  0.10946204335263478 --time: 2.397536039352417\n",
      "validation:  0.8800105485232067 --max 0.9077004219409283 --time: 2.7709925174713135\n",
      "train acc:  0.9682972189784179  train loss:  0.09445349898868503 --time: 2.3821680545806885\n",
      "validation:  0.8976793248945147 --max 0.9077004219409283 --time: 2.765336275100708\n",
      "train acc:  0.9935988927814541  train loss:  0.02272376646828009 --time: 2.4152936935424805\n",
      "validation:  0.9011075949367089 --max 0.9077004219409283 --time: 2.8050029277801514\n",
      "train acc:  0.9980104666753168  train loss:  0.007964278851090339 --time: 2.4041237831115723\n",
      "validation:  0.9053270042194093 --max 0.9077004219409283 --time: 2.7866857051849365\n",
      "train acc:  0.9983564724709139  train loss:  0.004905768892681483 --time: 2.4373416900634766\n",
      "validation:  0.9063818565400844 --max 0.9077004219409283 --time: 2.8202290534973145\n",
      "train acc:  0.9983997231953635  train loss:  0.004260968928899389 --time: 2.414443016052246\n",
      "validation:  0.9050632911392406 --max 0.9077004219409283 --time: 2.803678035736084\n",
      "train acc:  0.9986592275420614  train loss:  0.003799804250930966 --time: 2.3847639560699463\n",
      "validation:  0.9050632911392406 --max 0.9077004219409283 --time: 2.7679178714752197\n",
      "train acc:  0.9983564724709139  train loss:  0.0036764329108628264 --time: 2.409841299057007\n",
      "validation:  0.9055907172995781 --max 0.9077004219409283 --time: 2.7870213985443115\n",
      "train acc:  0.998572726093162  train loss:  0.0034842563525179287 --time: 2.370717763900757\n",
      "validation:  0.9074367088607594 --max 0.9077004219409283 --time: 2.751067638397217\n",
      "train acc:  0.9984862246442628  train loss:  0.003568975251998999 --time: 2.385117292404175\n",
      "validation:  0.9071729957805907 --max 0.9077004219409283 --time: 2.75878643989563\n",
      "train acc:  0.9985294753687124  train loss:  0.0034213967384797528 --time: 2.358684539794922\n",
      "validation:  0.9053270042194093 --max 0.9077004219409283 --time: 2.7413384914398193\n",
      "train acc:  0.9984429739198132  train loss:  0.0033848101394739804 --time: 2.3945016860961914\n",
      "validation:  0.9050632911392406 --max 0.9077004219409283 --time: 2.77807354927063\n",
      "train acc:  0.9984429739198132  train loss:  0.0033469270291392184 --time: 2.3749725818634033\n",
      "validation:  0.9047995780590717 --max 0.9077004219409283 --time: 2.7494163513183594\n",
      "train acc:  0.9981834695731153  train loss:  0.003286431942942928 --time: 2.381345510482788\n",
      "validation:  0.9042721518987342 --max 0.9077004219409283 --time: 2.7563059329986572\n",
      "train acc:  0.9985294753687124  train loss:  0.0033649163103105437 --time: 2.376723527908325\n",
      "validation:  0.9042721518987342 --max 0.9077004219409283 --time: 2.754526376724243\n",
      "train acc:  0.9983564724709139  train loss:  0.0033407575033253924 --time: 2.4101455211639404\n",
      "validation:  0.9042721518987342 --max 0.9077004219409283 --time: 2.785158634185791\n",
      "train acc:  0.9983997231953635  train loss:  0.0035264614522643642 --time: 2.3770675659179688\n",
      "validation:  0.9071729957805907 --max 0.9077004219409283 --time: 2.754018783569336\n",
      "train acc:  0.9983132217464643  train loss:  0.003546162320539556 --time: 2.378260850906372\n",
      "validation:  0.9058544303797469 --max 0.9077004219409283 --time: 2.7583463191986084\n",
      "train acc:  0.9983997231953635  train loss:  0.003428703083950018 --time: 2.3823635578155518\n",
      "validation:  0.9053270042194093 --max 0.9077004219409283 --time: 2.757866144180298\n",
      "train acc:  0.9984862246442628  train loss:  0.003390718986378669 --time: 2.4212629795074463\n",
      "validation:  0.9082278481012658 --max 0.9082278481012658 --time: 2.7982447147369385\n",
      "train acc:  0.998226720297565  train loss:  0.00327514603062538 --time: 2.4441676139831543\n",
      "validation:  0.9061181434599156 --max 0.9082278481012658 --time: 2.8280680179595947\n",
      "train acc:  0.9983132217464643  train loss:  0.003415580524444562 --time: 2.474774122238159\n",
      "validation:  0.9063818565400844 --max 0.9082278481012658 --time: 2.8510234355926514\n",
      "train acc:  0.9984862246442628  train loss:  0.0030793393740590628 --time: 2.4252545833587646\n",
      "validation:  0.9053270042194093 --max 0.9082278481012658 --time: 2.8124027252197266\n",
      "train acc:  0.9983132217464643  train loss:  0.003235162981521809 --time: 2.456395149230957\n",
      "validation:  0.9066455696202531 --max 0.9082278481012658 --time: 2.840421438217163\n",
      "train acc:  0.9983132217464643  train loss:  0.003153840529204035 --time: 2.4723706245422363\n",
      "validation:  0.9066455696202531 --max 0.9082278481012658 --time: 2.864243268966675\n",
      "train acc:  0.9983997231953635  train loss:  0.0030149796523233534 --time: 2.4364187717437744\n",
      "validation:  0.9050632911392406 --max 0.9082278481012658 --time: 2.824991464614868\n",
      "train acc:  0.998572726093162  train loss:  0.003103829024746134 --time: 2.4672794342041016\n",
      "validation:  0.9050632911392406 --max 0.9082278481012658 --time: 2.8563594818115234\n",
      "train acc:  0.9982699710220146  train loss:  0.0031047006303207172 --time: 2.4160544872283936\n",
      "validation:  0.9050632911392406 --max 0.9082278481012658 --time: 2.805870532989502\n",
      "train acc:  0.9983997231953635  train loss:  0.003017332289059671 --time: 2.4418370723724365\n",
      "validation:  0.9053270042194093 --max 0.9082278481012658 --time: 2.832606077194214\n",
      "train acc:  0.9984862246442628  train loss:  0.0029875720585490584 --time: 2.4228854179382324\n",
      "validation:  0.9077004219409283 --max 0.9082278481012658 --time: 2.811143636703491\n",
      "train acc:  0.979758660957571  train loss:  0.060325712535497525 --time: 2.464089870452881\n",
      "validation:  0.875 --max 0.9082278481012658 --time: 2.849726915359497\n",
      "train acc:  0.9669564465204792  train loss:  0.10335710514028099 --time: 2.460543394088745\n",
      "validation:  0.8979430379746836 --max 0.9082278481012658 --time: 2.85479474067688\n",
      "train acc:  0.9923878724968643  train loss:  0.023449429456216607 --time: 2.4321632385253906\n",
      "validation:  0.9000527426160337 --max 0.9082278481012658 --time: 2.829468011856079\n",
      "train acc:  0.997404956533022  train loss:  0.008955228216727444 --time: 2.436277151107788\n",
      "validation:  0.9034810126582279 --max 0.9082278481012658 --time: 2.8212881088256836\n",
      "train acc:  0.9984429739198132  train loss:  0.004833152831547498 --time: 2.4588069915771484\n",
      "validation:  0.9029535864978903 --max 0.9082278481012658 --time: 2.8447353839874268\n",
      "train acc:  0.9983997231953635  train loss:  0.003917301477264943 --time: 2.48293399810791\n",
      "validation:  0.9045358649789029 --max 0.9082278481012658 --time: 2.8668177127838135\n",
      "train acc:  0.9985294753687124  train loss:  0.0035279073336969505 --time: 2.4755475521087646\n",
      "validation:  0.9066455696202531 --max 0.9082278481012658 --time: 2.867021322250366\n",
      "train acc:  0.9984862246442628  train loss:  0.0035560614217486934 --time: 2.428535223007202\n",
      "validation:  0.9050632911392406 --max 0.9082278481012658 --time: 2.814114570617676\n",
      "train acc:  0.9983997231953635  train loss:  0.003371503426164687 --time: 2.4742538928985596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:  0.9050632911392406 --max 0.9082278481012658 --time: 2.86078143119812\n",
      "train acc:  0.9983132217464643  train loss:  0.0037262644496545688 --time: 2.4235265254974365\n",
      "validation:  0.9026898734177216 --max 0.9082278481012658 --time: 2.801935911178589\n",
      "train acc:  0.9984862246442628  train loss:  0.0033912495420525333 --time: 2.457669496536255\n",
      "validation:  0.9021624472573839 --max 0.9082278481012658 --time: 2.8417608737945557\n",
      "train acc:  0.9983132217464643  train loss:  0.0033525224773146376 --time: 2.473712205886841\n",
      "validation:  0.9050632911392406 --max 0.9082278481012658 --time: 2.8593592643737793\n",
      "train acc:  0.9984429739198132  train loss:  0.003186234424324212 --time: 2.44598126411438\n",
      "validation:  0.9034810126582279 --max 0.9082278481012658 --time: 2.8314342498779297\n",
      "train acc:  0.9984862246442628  train loss:  0.0031847296344876567 --time: 2.476224660873413\n",
      "validation:  0.9047995780590717 --max 0.9082278481012658 --time: 2.8610434532165527\n",
      "train acc:  0.9983132217464643  train loss:  0.0032547685794129667 --time: 2.4453577995300293\n",
      "validation:  0.9040084388185654 --max 0.9082278481012658 --time: 2.831449270248413\n",
      "train acc:  0.9982699710220146  train loss:  0.003135423626135186 --time: 2.4468419551849365\n",
      "validation:  0.9045358649789029 --max 0.9082278481012658 --time: 2.84139347076416\n",
      "train acc:  0.9984429739198132  train loss:  0.003073787105556588 --time: 2.4915671348571777\n",
      "validation:  0.9024261603375527 --max 0.9082278481012658 --time: 2.8746230602264404\n",
      "train acc:  0.9983997231953635  train loss:  0.0032737488161437393 --time: 2.4095656871795654\n",
      "validation:  0.9029535864978903 --max 0.9082278481012658 --time: 2.793912172317505\n",
      "train acc:  0.9983564724709139  train loss:  0.0030574617761966144 --time: 2.418860912322998\n",
      "validation:  0.9021624472573839 --max 0.9082278481012658 --time: 2.8063607215881348\n",
      "train acc:  0.998572726093162  train loss:  0.003036233076694851 --time: 2.408017158508301\n",
      "validation:  0.9037447257383966 --max 0.9082278481012658 --time: 2.7941229343414307\n",
      "train acc:  0.9986592275420614  train loss:  0.002989526970317788 --time: 2.43748140335083\n",
      "validation:  0.9003164556962026 --max 0.9082278481012658 --time: 2.815401554107666\n",
      "train acc:  0.9983997231953635  train loss:  0.00316425216253506 --time: 2.450071334838867\n",
      "validation:  0.9042721518987342 --max 0.9082278481012658 --time: 2.833946466445923\n",
      "train acc:  0.9983564724709139  train loss:  0.003085967065918887 --time: 2.400692939758301\n",
      "validation:  0.9000527426160337 --max 0.9082278481012658 --time: 2.777243137359619\n",
      "train acc:  0.9985294753687124  train loss:  0.003135084792024852 --time: 2.434762716293335\n",
      "validation:  0.9029535864978903 --max 0.9082278481012658 --time: 2.8212616443634033\n",
      "train acc:  0.9983997231953635  train loss:  0.0031020343072940106 --time: 2.4429163932800293\n",
      "validation:  0.9032172995780591 --max 0.9082278481012658 --time: 2.822723865509033\n",
      "train acc:  0.9984429739198132  train loss:  0.0030126051898246237 --time: 2.4328765869140625\n",
      "validation:  0.9024261603375527 --max 0.9082278481012658 --time: 2.817552089691162\n",
      "train acc:  0.9983997231953635  train loss:  0.003218077594494429 --time: 2.4052577018737793\n",
      "validation:  0.9034810126582279 --max 0.9082278481012658 --time: 2.7936766147613525\n",
      "train acc:  0.9983132217464643  train loss:  0.003064520255196518 --time: 2.412243366241455\n",
      "validation:  0.9024261603375527 --max 0.9082278481012658 --time: 2.8075733184814453\n",
      "train acc:  0.9820509493534016  train loss:  0.053639599480880075 --time: 2.4559166431427\n",
      "validation:  0.8781645569620253 --max 0.9082278481012658 --time: 2.847404956817627\n",
      "train acc:  0.9690757320185113  train loss:  0.08967037558123388 --time: 2.448287010192871\n",
      "validation:  0.8913502109704642 --max 0.9082278481012658 --time: 2.8369691371917725\n",
      "train acc:  0.993728644954803  train loss:  0.020100446241696813 --time: 2.4262681007385254\n",
      "validation:  0.8945147679324894 --max 0.9082278481012658 --time: 2.811046838760376\n",
      "train acc:  0.9980537173997664  train loss:  0.006793706198686023 --time: 2.4455931186676025\n",
      "validation:  0.9005801687763713 --max 0.9082278481012658 --time: 2.8253655433654785\n",
      "train acc:  0.9984429739198132  train loss:  0.004424924601399397 --time: 2.448186159133911\n",
      "validation:  0.9005801687763713 --max 0.9082278481012658 --time: 2.8274664878845215\n",
      "train acc:  0.9984862246442628  train loss:  0.0037467129514372564 --time: 2.4385459423065186\n",
      "validation:  0.9013713080168776 --max 0.9082278481012658 --time: 2.8247621059417725\n",
      "train acc:  0.9984429739198132  train loss:  0.003432819440971175 --time: 2.430802583694458\n",
      "validation:  0.9008438818565401 --max 0.9082278481012658 --time: 2.8138961791992188\n",
      "train acc:  0.9984862246442628  train loss:  0.0034265071380361195 --time: 2.4456841945648193\n",
      "validation:  0.9013713080168776 --max 0.9082278481012658 --time: 2.8372490406036377\n",
      "train acc:  0.9985294753687124  train loss:  0.0032180739237537134 --time: 2.4566307067871094\n",
      "validation:  0.9018987341772152 --max 0.9082278481012658 --time: 2.8518264293670654\n",
      "train acc:  0.9984429739198132  train loss:  0.003202493651207274 --time: 2.4521939754486084\n",
      "validation:  0.9026898734177216 --max 0.9082278481012658 --time: 2.8490209579467773\n",
      "train acc:  0.9985294753687124  train loss:  0.0031030507039829305 --time: 2.4226298332214355\n",
      "validation:  0.9021624472573839 --max 0.9082278481012658 --time: 2.8101742267608643\n",
      "train acc:  0.9986159768176117  train loss:  0.0030904635388239476 --time: 2.4322593212127686\n",
      "validation:  0.9018987341772152 --max 0.9082278481012658 --time: 2.8179268836975098\n",
      "train acc:  0.998226720297565  train loss:  0.0031417181706284328 --time: 2.441350221633911\n",
      "validation:  0.9026898734177216 --max 0.9082278481012658 --time: 2.830305814743042\n",
      "train acc:  0.998572726093162  train loss:  0.0030255778172492043 --time: 2.4429986476898193\n",
      "validation:  0.9016350210970464 --max 0.9082278481012658 --time: 2.8320209980010986\n",
      "train acc:  0.9985294753687124  train loss:  0.0030447722763017344 --time: 2.4270083904266357\n",
      "validation:  0.9029535864978903 --max 0.9082278481012658 --time: 2.8060405254364014\n",
      "train acc:  0.9986159768176117  train loss:  0.0030410315995236465 --time: 2.3940749168395996\n",
      "validation:  0.9037447257383966 --max 0.9082278481012658 --time: 2.7855188846588135\n",
      "train acc:  0.9983564724709139  train loss:  0.00317268868298392 --time: 2.442577362060547\n",
      "validation:  0.9026898734177216 --max 0.9082278481012658 --time: 2.8259947299957275\n",
      "train acc:  0.9983997231953635  train loss:  0.003005562369931664 --time: 2.4483797550201416\n",
      "validation:  0.9021624472573839 --max 0.9082278481012658 --time: 2.8399434089660645\n",
      "train acc:  0.9984862246442628  train loss:  0.0029215288470860684 --time: 2.493875026702881\n",
      "validation:  0.9016350210970464 --max 0.9082278481012658 --time: 2.875950813293457\n",
      "train acc:  0.9983564724709139  train loss:  0.002983303285491375 --time: 2.458211660385132\n",
      "validation:  0.9008438818565401 --max 0.9082278481012658 --time: 2.842590093612671\n",
      "train acc:  0.9986159768176117  train loss:  0.0030357725079346947 --time: 2.4769299030303955\n",
      "validation:  0.9021624472573839 --max 0.9082278481012658 --time: 2.866311550140381\n",
      "train acc:  0.9984429739198132  train loss:  0.002999712987981405 --time: 2.457327127456665\n",
      "validation:  0.9016350210970464 --max 0.9082278481012658 --time: 2.846731424331665\n",
      "train acc:  0.9983997231953635  train loss:  0.0030368248539242265 --time: 2.490999221801758\n",
      "validation:  0.9032172995780591 --max 0.9082278481012658 --time: 2.8772549629211426\n",
      "train acc:  0.9984429739198132  train loss:  0.003000119656045569 --time: 2.4518814086914062\n",
      "validation:  0.9016350210970464 --max 0.9082278481012658 --time: 2.834005832672119\n",
      "train acc:  0.9983564724709139  train loss:  0.003017563213543125 --time: 2.44401216506958\n",
      "validation:  0.9024261603375527 --max 0.9082278481012658 --time: 2.830477714538574\n",
      "train acc:  0.997404956533022  train loss:  0.006162094199439532 --time: 2.4373598098754883\n",
      "validation:  0.8847573839662447 --max 0.9082278481012658 --time: 2.827935218811035\n",
      "train acc:  0.9612041001686779  train loss:  0.11470871809767096 --time: 2.445915937423706\n",
      "validation:  0.8910864978902954 --max 0.9082278481012658 --time: 2.828183650970459\n",
      "train acc:  0.9917391116301199  train loss:  0.027304447690817368 --time: 2.4777894020080566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:  0.8968881856540084 --max 0.9082278481012658 --time: 2.8755671977996826\n",
      "train acc:  0.9970589507374249  train loss:  0.009772756586214064 --time: 2.421661615371704\n",
      "validation:  0.8989978902953587 --max 0.9082278481012658 --time: 2.8114850521087646\n",
      "train acc:  0.9985294753687124  train loss:  0.004576945293100438 --time: 2.4468605518341064\n",
      "validation:  0.9013713080168776 --max 0.9082278481012658 --time: 2.832581043243408\n",
      "train acc:  0.9985294753687124  train loss:  0.0036801248845111743 --time: 2.422215700149536\n",
      "validation:  0.9024261603375527 --max 0.9082278481012658 --time: 2.8136274814605713\n",
      "train acc:  0.9983997231953635  train loss:  0.0034389081631352333 --time: 2.4193460941314697\n",
      "validation:  0.9024261603375527 --max 0.9082278481012658 --time: 2.8198909759521484\n",
      "train acc:  0.9983564724709139  train loss:  0.003360388387098795 --time: 2.4316534996032715\n",
      "validation:  0.9016350210970464 --max 0.9082278481012658 --time: 2.815040349960327\n",
      "train acc:  0.9984862246442628  train loss:  0.0031774082709584922 --time: 2.4261744022369385\n",
      "validation:  0.9024261603375527 --max 0.9082278481012658 --time: 2.8096561431884766\n",
      "train acc:  0.9983997231953635  train loss:  0.003140255155521625 --time: 2.411184310913086\n",
      "validation:  0.9029535864978903 --max 0.9082278481012658 --time: 2.7925822734832764\n",
      "train acc:  0.9983132217464643  train loss:  0.003231387917603268 --time: 2.4364733695983887\n",
      "validation:  0.9034810126582279 --max 0.9082278481012658 --time: 2.8198258876800537\n",
      "train acc:  0.9983997231953635  train loss:  0.003134168731595405 --time: 2.438321590423584\n",
      "validation:  0.9037447257383966 --max 0.9082278481012658 --time: 2.8314616680145264\n",
      "train acc:  0.9984862246442628  train loss:  0.003045198650714216 --time: 2.4318172931671143\n",
      "validation:  0.9029535864978903 --max 0.9082278481012658 --time: 2.8159844875335693\n",
      "train acc:  0.9983997231953635  train loss:  0.0029613939355106933 --time: 2.402874708175659\n",
      "validation:  0.9045358649789029 --max 0.9082278481012658 --time: 2.7752232551574707\n",
      "train acc:  0.9984862246442628  train loss:  0.003109890920896654 --time: 2.386598587036133\n",
      "validation:  0.9042721518987342 --max 0.9082278481012658 --time: 2.764617919921875\n",
      "train acc:  0.9984429739198132  train loss:  0.0030899108613044336 --time: 2.3689398765563965\n",
      "validation:  0.9029535864978903 --max 0.9082278481012658 --time: 2.748185157775879\n",
      "train acc:  0.9984429739198132  train loss:  0.0029089498327281556 --time: 2.40012264251709\n",
      "validation:  0.9034810126582279 --max 0.9082278481012658 --time: 2.7779083251953125\n",
      "train acc:  0.9984429739198132  train loss:  0.002968848575328191 --time: 2.348025321960449\n",
      "validation:  0.9047995780590717 --max 0.9082278481012658 --time: 2.7333686351776123\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b9c73acfc874>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss_accum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mbatch_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(class_type, split)\n",
    "max_acc = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    #print(\"epoch \", i)\n",
    "    loss_accum = 0.0\n",
    "    batch_cnt = 0\n",
    "\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch, (x, lengths, y) in enumerate(train_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        loss = criterion(logits, y)\n",
    "        loss_score = loss.cpu().item()\n",
    "\n",
    "        loss_accum += loss_score\n",
    "        batch_cnt += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "                    \n",
    "\n",
    "    print(\"train acc: \", acc_cnt/(err_cnt+acc_cnt), \" train loss: \", loss_accum / batch_cnt, '--time:', time.time() - start_time)\n",
    "\n",
    "    model.eval()\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    #start_time = time.time()\n",
    "    for x, lengths, y in valid_loader:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    current_acc = acc_cnt/(err_cnt+acc_cnt)\n",
    "    if current_acc > max_acc:\n",
    "        max_acc = current_acc\n",
    "                \n",
    "    print(\"validation: \", current_acc, '--max', max_acc, '--time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
