{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "#import psutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/akshatgu/Intents-Analysis/Analysis')\n",
    "#sys.path.insert(1, '/Users/manjugupta/Desktop/CMU_Courses/Intents/getting_intents/Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_vocab import load_data, get_vocab\n",
    "from get_frequency import get_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is False\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshatgu/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Needed Functions\n",
    "def load_data(filename):\n",
    "    a_file = open(filename, \"rb\")\n",
    "    output = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_vocabulary(train_file):\n",
    "    '''This function creates an indexed vocabulary dictionary from the training file'''\n",
    "    \n",
    "    vocab, _ = get_vocab(1, train_file)\n",
    "    \n",
    "    phone_to_idx = {'unk': 1}#Padding indx = 0, eos = 1, unkown_idx = 2, indexing starts from 3\n",
    "    for i, phone in enumerate(vocab):\n",
    "        phone_to_idx[phone] = i + 3\n",
    "        \n",
    "    return phone_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_file, intent_labels, phone_to_idx):\n",
    "        data = load_data(data_file)\n",
    "        self.all_data = []\n",
    "        \n",
    "        for intent in data:\n",
    "            for utterance in data[intent]:\n",
    "                if len(utterance) != 0:\n",
    "                    utterance_to_idx = []\n",
    "\n",
    "                    for phone in utterance:\n",
    "                        if phone not in phone_to_idx:\n",
    "                            phone = 'unk'\n",
    "\n",
    "                        utterance_to_idx.append(phone_to_idx[phone])\n",
    "\n",
    "                    self.all_data.append([utterance_to_idx, intent_labels[intent]])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        input_vector = self.all_data[index][0]\n",
    "        label = self.all_data[index][1]\n",
    "\n",
    "        return input_vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLMDataset(Dataset):\n",
    "    def __init__(self, data_file, intent_labels, phone_to_idx):\n",
    "        data = load_data(data_file)\n",
    "        self.all_data = []\n",
    "        \n",
    "        for intent in data:\n",
    "            for utterance in data[intent]:\n",
    "                if len(utterance) != 0:\n",
    "                    utterance_to_idx = []\n",
    "\n",
    "                    for phone in utterance:\n",
    "                        if phone not in phone_to_idx:\n",
    "                            phone = 'unk'\n",
    "\n",
    "                        utterance_to_idx.append(phone_to_idx[phone])\n",
    "\n",
    "                    self.all_data.append([utterance_to_idx, intent_labels[intent]])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        input_vector = self.all_data[index][0]\n",
    "        output_vector = self.all_data[index][0][1:] + [1]\n",
    "        print('Input:', input_vector)\n",
    "        print('Output:', output_vector)\n",
    "\n",
    "        return input_vector, output_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyLMDataset(train_file, intent_labels, phone_to_idx)\n",
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=64)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args, collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [14, 25, 38, 41, 15, 25, 16, 33, 7, 23, 32, 12]\n",
      "Output: [25, 38, 41, 15, 25, 16, 33, 7, 23, 32, 12, 1]\n",
      "Input: [10, 25, 6, 25, 10, 25, 36, 25, 8, 38, 12, 15, 25, 36, 25, 7, 12]\n",
      "Output: [25, 6, 25, 10, 25, 36, 25, 8, 38, 12, 15, 25, 36, 25, 7, 12, 1]\n",
      "Input: [14, 25, 29, 38, 39, 16, 12, 34, 26, 39, 38, 33, 26, 25, 32, 25, 10, 16, 39]\n",
      "Output: [25, 29, 38, 39, 16, 12, 34, 26, 39, 38, 33, 26, 25, 32, 25, 10, 16, 39, 1]\n",
      "Input: [14, 25, 38, 12, 10, 25, 12, 26, 12, 38, 25, 33, 10, 25, 12, 32, 16, 27, 18]\n",
      "Output: [25, 38, 12, 10, 25, 12, 26, 12, 38, 25, 33, 10, 25, 12, 32, 16, 27, 18, 1]\n",
      "Input: [6, 25, 38, 5, 12, 2, 30, 6, 33, 7, 33, 32]\n",
      "Output: [25, 38, 5, 12, 2, 30, 6, 33, 7, 33, 32, 1]\n",
      "Input: [14, 25, 32, 8, 25, 14, 23, 15, 34, 16, 34, 33, 36, 25, 32]\n",
      "Output: [25, 32, 8, 25, 14, 23, 15, 34, 16, 34, 33, 36, 25, 32, 1]\n",
      "Input: [32, 7, 33, 6, 12, 36, 34, 16, 25, 2, 25, 2, 39, 14, 25, 14, 25, 4, 33, 36, 15, 39]\n",
      "Output: [7, 33, 6, 12, 36, 34, 16, 25, 2, 25, 2, 39, 14, 25, 14, 25, 4, 33, 36, 15, 39, 1]\n",
      "Input: [33, 14, 25, 27, 15, 10, 25, 36, 12, 15, 25, 10, 25, 36, 25, 10, 12]\n",
      "Output: [14, 25, 27, 15, 10, 25, 36, 12, 15, 25, 10, 25, 36, 25, 10, 12, 1]\n",
      "Input: [14, 25, 38, 33, 15, 23, 24, 25, 36, 12, 14, 39, 23, 36, 41, 39]\n",
      "Output: [25, 38, 33, 15, 23, 24, 25, 36, 12, 14, 39, 23, 36, 41, 39, 1]\n",
      "Input: [12, 14, 39, 32, 17, 25, 7, 17]\n",
      "Output: [14, 39, 32, 17, 25, 7, 17, 1]\n",
      "Input: [12, 14, 25, 32, 15, 34, 7, 12, 39, 36, 23]\n",
      "Output: [14, 25, 32, 15, 34, 7, 12, 39, 36, 23, 1]\n",
      "Input: [14, 25, 38, 33, 29, 30, 14, 25, 22, 25, 42, 39, 32]\n",
      "Output: [25, 38, 33, 29, 30, 14, 25, 22, 25, 42, 39, 32, 1]\n",
      "Input: [14, 25, 2, 12, 38, 14, 25, 2, 14, 25, 38, 12, 31, 25, 2, 4, 25, 7, 23, 32, 27]\n",
      "Output: [25, 2, 12, 38, 14, 25, 2, 14, 25, 38, 12, 31, 25, 2, 4, 25, 7, 23, 32, 27, 1]\n",
      "Input: [12, 32, 16, 2, 25, 15, 34, 2, 36, 33, 39, 2, 39, 14, 25, 14, 25, 4, 33, 36, 39, 15, 39, 38]\n",
      "Output: [32, 16, 2, 25, 15, 34, 2, 36, 33, 39, 2, 39, 14, 25, 14, 25, 4, 33, 36, 39, 15, 39, 38, 1]\n",
      "Input: [14, 25, 38, 33, 2, 12, 26, 14, 27, 32, 12, 15]\n",
      "Output: [25, 38, 33, 2, 12, 26, 14, 27, 32, 12, 15, 1]\n",
      "Input: [14, 25, 43, 5, 36, 25, 12, 26, 12, 4, 33, 6, 33, 29, 25, 12, 36, 16, 39]\n",
      "Output: [25, 43, 5, 36, 25, 12, 26, 12, 4, 33, 6, 33, 29, 25, 12, 36, 16, 39, 1]\n",
      "Input: [33, 14, 25, 10, 25, 36, 27, 15, 38, 25, 6, 41, 36, 25, 6, 12]\n",
      "Output: [14, 25, 10, 25, 36, 27, 15, 38, 25, 6, 41, 36, 25, 6, 12, 1]\n",
      "Input: [33, 14, 39, 32, 4, 36, 33, 34, 2, 14, 2, 33, 14, 25, 38, 33, 7, 33, 12, 41, 2, 33, 14, 39, 32, 39]\n",
      "Output: [14, 39, 32, 4, 36, 33, 34, 2, 14, 2, 33, 14, 25, 38, 33, 7, 33, 12, 41, 2, 33, 14, 39, 32, 39, 1]\n",
      "Input: [33, 14, 25, 32, 16, 25, 12, 36, 25, 15, 38, 27, 7, 25, 36, 25]\n",
      "Output: [14, 25, 32, 16, 25, 12, 36, 25, 15, 38, 27, 7, 25, 36, 25, 1]\n",
      "Input: [14, 39, 29, 43, 29, 25, 8, 32, 12, 26, 23, 7, 23, 8, 39]\n",
      "Output: [39, 29, 43, 29, 25, 8, 32, 12, 26, 23, 7, 23, 8, 39, 1]\n",
      "Input: [14, 25, 32, 31, 36, 34, 2, 14, 2, 25, 14, 25, 43, 33, 39, 2, 12, 14, 25, 32, 41, 15]\n",
      "Output: [25, 32, 31, 36, 34, 2, 14, 2, 25, 14, 25, 43, 33, 39, 2, 12, 14, 25, 32, 41, 15, 1]\n",
      "Input: [33, 14, 39, 32, 15, 12, 36, 12, 33, 36, 39]\n",
      "Output: [14, 39, 32, 15, 12, 36, 12, 33, 36, 39, 1]\n",
      "Input: [33, 14, 25, 32, 10, 25, 2, 25, 32, 31, 33, 32]\n",
      "Output: [14, 25, 32, 10, 25, 2, 25, 32, 31, 33, 32, 1]\n",
      "Input: [14, 25, 38, 33, 36, 5, 14, 27, 32, 5]\n",
      "Output: [25, 38, 33, 36, 5, 14, 27, 32, 5, 1]\n",
      "Input: [30, 32, 16, 25, 14, 39, 32, 36, 25, 12, 2, 39, 32, 7, 12, 15, 25, 4, 25, 14, 39, 32, 16, 23, 14, 25, 38, 10, 39, 36, 25]\n",
      "Output: [32, 16, 25, 14, 39, 32, 36, 25, 12, 2, 39, 32, 7, 12, 15, 25, 4, 25, 14, 39, 32, 16, 23, 14, 25, 38, 10, 39, 36, 25, 1]\n",
      "Input: [14, 25, 38, 33, 16, 33, 10, 39, 38, 12, 6, 26, 25, 15, 25, 10, 12, 32, 16, 15]\n",
      "Output: [25, 38, 33, 16, 33, 10, 39, 38, 12, 6, 26, 25, 15, 25, 10, 12, 32, 16, 15, 1]\n",
      "Input: [14, 25, 38, 33, 7, 33, 12, 33, 26, 23, 38, 33, 2, 34, 33, 2, 10, 2, 25, 12, 8, 6, 2]\n",
      "Output: [25, 38, 33, 7, 33, 12, 33, 26, 23, 38, 33, 2, 34, 33, 2, 10, 2, 25, 12, 8, 6, 2, 1]\n",
      "Input: [26, 25, 35, 25, 38, 41, 6, 5, 15, 25, 12, 38, 26, 25, 6, 5, 2, 33, 2, 12, 9]\n",
      "Output: [25, 35, 25, 38, 41, 6, 5, 15, 25, 12, 38, 26, 25, 6, 5, 2, 33, 2, 12, 9, 1]\n",
      "Input: [25, 14, 39, 32, 10, 25, 36, 33, 32, 43, 39, 26, 36, 39]\n",
      "Output: [14, 39, 32, 10, 25, 36, 33, 32, 43, 39, 26, 36, 39, 1]\n",
      "Input: [25, 38, 14, 25, 8, 15, 12, 16, 30, 25, 28, 25, 36, 25]\n",
      "Output: [38, 14, 25, 8, 15, 12, 16, 30, 25, 28, 25, 36, 25, 1]\n",
      "Input: [10, 12, 36, 14, 25, 38, 39, 31, 25, 4, 25, 7, 25, 12, 32]\n",
      "Output: [12, 36, 14, 25, 38, 39, 31, 25, 4, 25, 7, 25, 12, 32, 1]\n",
      "Input: [36, 34, 26, 39, 38, 34, 14, 25, 38, 33, 26, 39, 2, 25, 39]\n",
      "Output: [34, 26, 39, 38, 34, 14, 25, 38, 33, 26, 39, 2, 25, 39, 1]\n",
      "Input: [7, 25, 2, 30, 43, 25, 4, 30, 36, 26, 25]\n",
      "Output: [25, 2, 30, 43, 25, 4, 30, 36, 26, 25, 1]\n",
      "Input: [33, 2, 7, 12, 14, 25, 14, 25, 38, 4, 30, 9, 25, 14, 33, 10, 23, 32]\n",
      "Output: [2, 7, 12, 14, 25, 14, 25, 38, 4, 30, 9, 25, 14, 33, 10, 23, 32, 1]\n",
      "Input: [14, 25, 38, 12, 36, 12, 26, 39, 38, 12, 26, 25, 8, 25, 7, 25, 17, 39, 32]\n",
      "Output: [25, 38, 12, 36, 12, 26, 39, 38, 12, 26, 25, 8, 25, 7, 25, 17, 39, 32, 1]\n",
      "Input: [25, 14, 25, 36, 38, 15, 12, 7, 17, 25, 36, 25, 27]\n",
      "Output: [14, 25, 36, 38, 15, 12, 7, 17, 25, 36, 25, 27, 1]\n",
      "Input: [25, 7, 25, 14, 5, 15, 34, 7, 30, 25, 10, 23, 36, 25, 7, 12]\n",
      "Output: [7, 25, 14, 5, 15, 34, 7, 30, 25, 10, 23, 36, 25, 7, 12, 1]\n",
      "Input: [26, 12, 32, 12, 38, 14, 25, 4, 33, 26, 25, 32, 15, 39, 32, 5]\n",
      "Output: [12, 32, 12, 38, 14, 25, 4, 33, 26, 25, 32, 15, 39, 32, 5, 1]\n",
      "Input: [33, 14, 39, 32, 10, 25, 12, 42, 33, 32, 38, 12, 6, 33, 36, 25, 7, 23]\n",
      "Output: [14, 39, 32, 10, 25, 12, 42, 33, 32, 38, 12, 6, 33, 36, 25, 7, 23, 1]\n",
      "Input: [14, 25, 2, 12, 15, 39, 25, 4, 25, 7, 23, 32, 39]\n",
      "Output: [25, 2, 12, 15, 39, 25, 4, 25, 7, 23, 32, 39, 1]\n",
      "Input: [14, 25, 38, 33, 2, 30, 38, 33, 7, 23, 8, 39]\n",
      "Output: [25, 38, 33, 2, 30, 38, 33, 7, 23, 8, 39, 1]\n",
      "Input: [12, 32, 16, 33, 25, 14, 39, 41, 16, 30, 36, 33, 34, 7, 32, 16, 33, 15, 25, 4, 33, 14, 25, 15, 39, 40, 33, 14, 39, 14, 25, 38, 23, 14, 39, 15, 39, 2, 25, 7, 39, 32, 25]\n",
      "Output: [32, 16, 33, 25, 14, 39, 41, 16, 30, 36, 33, 34, 7, 32, 16, 33, 15, 25, 4, 33, 14, 25, 15, 39, 40, 33, 14, 39, 14, 25, 38, 23, 14, 39, 15, 39, 2, 25, 7, 39, 32, 25, 1]\n",
      "Input: [14, 25, 43, 41, 4, 39, 7, 39, 32, 39]\n",
      "Output: [25, 43, 41, 4, 39, 7, 39, 32, 39, 1]\n",
      "Input: [33, 14, 39, 32, 26, 33, 2, 25, 32, 33, 4, 33, 6, 39, 2, 25, 7, 23]\n",
      "Output: [14, 39, 32, 26, 33, 2, 25, 32, 33, 4, 33, 6, 39, 2, 25, 7, 23, 1]\n",
      "Input: [25, 14, 25, 8, 15, 30, 7, 30, 25, 36, 25]\n",
      "Output: [14, 25, 8, 15, 30, 7, 30, 25, 36, 25, 1]\n",
      "Input: [14, 25, 38, 34, 32, 39, 2, 33, 14, 39, 16, 39, 14, 25, 15, 25, 4, 25, 39]\n",
      "Output: [25, 38, 34, 32, 39, 2, 33, 14, 39, 16, 39, 14, 25, 15, 25, 4, 25, 39, 1]\n",
      "Input: [25, 14, 25, 27, 15, 30, 7, 12, 25, 22, 25, 36, 25, 32]\n",
      "Output: [14, 25, 27, 15, 30, 7, 12, 25, 22, 25, 36, 25, 32, 1]\n",
      "Input: [25, 18, 14, 39, 32, 10, 33, 12, 8, 33, 32, 43, 33, 6, 25, 36, 39]\n",
      "Output: [18, 14, 39, 32, 10, 33, 12, 8, 33, 32, 43, 33, 6, 25, 36, 39, 1]\n",
      "Input: [9, 25, 9, 25, 7, 12, 16, 17, 30, 17, 26, 25, 2, 7, 17, 33, 17, 26, 25, 32, 8, 25, 15, 25, 17, 33, 8, 16, 39, 38, 33, 38, 30]\n",
      "Output: [25, 9, 25, 7, 12, 16, 17, 30, 17, 26, 25, 2, 7, 17, 33, 17, 26, 25, 32, 8, 25, 15, 25, 17, 33, 8, 16, 39, 38, 33, 38, 30, 1]\n",
      "Input: [10, 12, 36, 12, 38, 4, 14, 25, 38, 5, 14, 25, 4, 16, 33, 7, 12, 2]\n",
      "Output: [12, 36, 12, 38, 4, 14, 25, 38, 5, 14, 25, 4, 16, 33, 7, 12, 2, 1]\n",
      "Input: [15, 25, 14, 12, 15, 12, 16, 17, 39, 10, 23, 36, 39]\n",
      "Output: [25, 14, 12, 15, 12, 16, 17, 39, 10, 23, 36, 39, 1]\n",
      "Input: [14, 25, 32, 25, 14, 23, 15, 34, 7, 17, 33, 6, 39, 36, 25, 23]\n",
      "Output: [25, 32, 25, 14, 23, 15, 34, 7, 17, 33, 6, 39, 36, 25, 23, 1]\n",
      "Input: [12, 32, 16, 25, 10, 12, 29, 33, 2, 33, 4, 25, 4, 25, 14, 33, 36, 15, 39]\n",
      "Output: [32, 16, 25, 10, 12, 29, 33, 2, 33, 4, 25, 4, 25, 14, 33, 36, 15, 39, 1]\n",
      "Input: [14, 25, 38, 28, 25, 12, 4, 11, 39, 38, 33, 6, 25, 32, 16, 39]\n",
      "Output: [25, 38, 28, 25, 12, 4, 11, 39, 38, 33, 6, 25, 32, 16, 39, 1]\n",
      "Input: [14, 33, 36, 12, 14, 25, 2, 14, 25, 38, 33, 36, 25, 12, 2, 4, 25, 6, 25, 8]\n",
      "Output: [33, 36, 12, 14, 25, 2, 14, 25, 38, 33, 36, 25, 12, 2, 4, 25, 6, 25, 8, 1]\n",
      "Input: [14, 39, 32, 10, 25, 36, 25, 32, 38, 33, 8, 12]\n",
      "Output: [39, 32, 10, 25, 36, 25, 32, 38, 33, 8, 12, 1]\n",
      "Input: [25, 4, 39, 16, 12, 26, 25, 38, 12, 4, 31, 25, 37, 25, 10, 25, 32]\n",
      "Output: [4, 39, 16, 12, 26, 25, 38, 12, 4, 31, 25, 37, 25, 10, 25, 32, 1]\n",
      "Input: [36, 39, 36, 12, 14, 25, 14, 25, 4, 39, 10, 33, 12, 32, 39]\n",
      "Output: [39, 36, 12, 14, 25, 14, 25, 4, 39, 10, 33, 12, 32, 39, 1]\n",
      "Input: [10, 12, 36, 14, 25, 4, 25, 10, 25, 32]\n",
      "Output: [12, 36, 14, 25, 4, 25, 10, 25, 32, 1]\n",
      "Input: [2, 33, 7, 30, 14, 25, 38, 14, 25, 38, 41, 38, 25, 26, 33, 7, 25, 32, 39]\n",
      "Output: [33, 7, 30, 14, 25, 38, 14, 25, 38, 41, 38, 25, 26, 33, 7, 25, 32, 39, 1]\n",
      "Input: [14, 23, 2, 12, 14, 25, 14, 25, 38, 26, 25, 2, 4, 25, 7, 32, 27, 15, 34]\n",
      "Output: [23, 2, 12, 14, 25, 14, 25, 38, 26, 25, 2, 4, 25, 7, 32, 27, 15, 34, 1]\n",
      "Input: [14, 33, 12, 9, 10, 39, 16, 25, 32, 23]\n",
      "Output: [33, 12, 9, 10, 39, 16, 25, 32, 23, 1]\n",
      "Input: [6, 25, 29, 38, 23, 15, 25, 32, 4, 23, 10, 23, 32, 5]\n",
      "Output: [25, 29, 38, 23, 15, 25, 32, 4, 23, 10, 23, 32, 5, 1]\n",
      "Input: [31, 25, 32, 25, 14, 39, 15, 34, 7, 12, 25, 7, 25, 36, 25, 10, 12]\n",
      "Output: [25, 32, 25, 14, 39, 15, 34, 7, 12, 25, 7, 25, 36, 25, 10, 12, 1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 12 at dim 1 (got 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-72d62b675dcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-ad4f74fb0dff>\u001b[0m in \u001b[0;36mcollate_indic\u001b[0;34m(tuple_lst)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# collate y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 12 at dim 1 (got 17)"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_indic(tuple_lst):\n",
    "\n",
    "    x_lst = [x[0] for x in tuple_lst]\n",
    "    y_lst = [x[1] for x in tuple_lst]\n",
    "\n",
    "    # collate x\n",
    "    B = len(tuple_lst)#Number of training samples\n",
    "    T = max(len(x) for x in x_lst)#Max length of a sentence\n",
    "\n",
    "    # x values\n",
    "    x = torch.zeros([B, T], dtype=torch.int64)\n",
    "    lengths = torch.zeros(B, dtype=torch.int64)\n",
    "\n",
    "    for i, x_np in enumerate(x_lst):\n",
    "        lengths[i] = len(x_np)\n",
    "        x[i,:len(x_np)] = torch.tensor(x_np)\n",
    "\n",
    "    # collate y\n",
    "    y = torch.tensor(y_lst)\n",
    "\n",
    "    ids = torch.argsort(lengths, descending=True)\n",
    "\n",
    "    return x[ids], lengths[ids], y[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_LM(tuple_lst):\n",
    "\n",
    "    x_lst = [x[0] for x in tuple_lst]\n",
    "    y_lst = [x[1] for x in tuple_lst]\n",
    "\n",
    "    # collate x\n",
    "    B = len(tuple_lst)#Number of training samples\n",
    "    T = max(len(x) for x in x_lst)#Max length of a sentence\n",
    "\n",
    "    # x values\n",
    "    x = torch.zeros([B, T], dtype=torch.int64)\n",
    "    lengths = torch.zeros(B, dtype=torch.int64)\n",
    "\n",
    "    for i, x_np in enumerate(x_lst):\n",
    "        lengths[i] = len(x_np)\n",
    "        x[i,:len(x_np)] = torch.tensor(x_np)\n",
    "\n",
    "    # collate y\n",
    "    y = torch.tensor(y_lst)\n",
    "\n",
    "    ids = torch.argsort(lengths, descending=True)\n",
    "\n",
    "    return x[ids], lengths[ids], y[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intents():\n",
    "    all_intents = ['1', '2', '3', '4', '5', '6']\n",
    "    return all_intents\n",
    "\n",
    "def get_intent_labels(class_type):\n",
    "    all_intents = get_intents()\n",
    "        \n",
    "    intent_labels = {}\n",
    "    labels_to_intents = {}\n",
    "    for i, intent in enumerate(all_intents):\n",
    "        intent_labels[intent] = i\n",
    "        labels_to_intents[i] = intent\n",
    "        \n",
    "    return intent_labels, labels_to_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "class_type = 'intents'\n",
    "\n",
    "intent_labels, labels_to_intents = get_intent_labels(class_type)\n",
    "\n",
    "#Loading data\n",
    "split = '1'\n",
    "train_file = '../../Tamil_Dataset/datasplit1/tamil_train_split_' + split + '.pkl'\n",
    "test_file = '../../Tamil_Dataset/datasplit1/tamil_test_split_' + split + '.pkl'\n",
    "#create vocabulary and phone_to_idx\n",
    "phone_to_idx = create_vocabulary(train_file)\n",
    "print(len(phone_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_file, intent_labels, phone_to_idx)\n",
    "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=64)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args, collate_fn=collate_indic)\n",
    "\n",
    "test_dataset = MyDataset(test_file, intent_labels, phone_to_idx)\n",
    "test_loader_args = dict(shuffle=False, batch_size=128, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "valid_loader = DataLoader(test_dataset, **test_loader_args, collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=45, embed_size=128, hidden_size=256, label_size=6):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "        #self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(embed_size*2)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_size*2, hidden_size, num_layers=2)\n",
    "        self.linear = nn.Linear(hidden_size, label_size)\n",
    "\n",
    "    def forward(self, x, lengths, lm = True):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "        # B,T,H\n",
    "        \n",
    "        input = self.embed(x)\n",
    "\n",
    "        # (B,T,H) -> (B,H,T)\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        #cnn_output = torch.cat([self.cnn(input), self.cnn2(input), self.cnn3(input)], dim=1)\n",
    "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input)], dim=1)\n",
    "        \n",
    "        # (B,H,T)\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "        \n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n",
    "\n",
    "        output, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        if lm:\n",
    "            logits = self.linear(output)\n",
    "        else:\n",
    "            logits = self.linear(hn[0])\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNClassifier(\n",
       "  (embed): Embedding(45, 128)\n",
       "  (cnn): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (cnn2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lstm): LSTM(256, 256, num_layers=2)\n",
       "  (linear): Linear(in_features=256, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNClassifier()\n",
    "opt = optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#opt = SGD(model.parameters(), lr=0.05)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intents 1\n",
      "torch.Size([64, 48, 256])\n",
      "torch.Size([64, 48]) torch.Size([64, 48, 6])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected target size (64, 6), got torch.Size([64, 48])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f1c7b4ed5bd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 962\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2273\u001b[0m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[0;32m-> 2274\u001b[0;31m                 out_size, target.size()))\n\u001b[0m\u001b[1;32m   2275\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2276\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected target size (64, 6), got torch.Size([64, 48])"
     ]
    }
   ],
   "source": [
    "#Train language model\n",
    "print(class_type, split)\n",
    "max_acc = 0\n",
    "\n",
    "for j in range(200):\n",
    "    #print(\"epoch \", i)\n",
    "    loss_accum = 0.0\n",
    "    batch_cnt = 0\n",
    "\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch, (x, lengths, y) in enumerate(train_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        logits = model(x, lengths)\n",
    "        logits \n",
    "        print(x.shape, logits.shape)\n",
    "        loss = criterion(logits, x)\n",
    "        loss_score = loss.cpu().item()\n",
    "\n",
    "        loss_accum += loss_score\n",
    "        batch_cnt += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "                    \n",
    "\n",
    "    print(\"train acc: \", acc_cnt/(err_cnt+acc_cnt), \" train loss: \", loss_accum / batch_cnt, '--time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intents 1\n",
      "torch.Size([64, 34])\n",
      "torch.Size([64, 34, 256])\n",
      "torch.Size([64, 34, 6])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected target size (64, 6), got torch.Size([64])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f94ac7ac77e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mloss_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 962\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2273\u001b[0m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[0;32m-> 2274\u001b[0;31m                 out_size, target.size()))\n\u001b[0m\u001b[1;32m   2275\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2276\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected target size (64, 6), got torch.Size([64])"
     ]
    }
   ],
   "source": [
    "print(class_type, split)\n",
    "max_acc = 0\n",
    "\n",
    "for j in range(200):\n",
    "    #print(\"epoch \", i)\n",
    "    loss_accum = 0.0\n",
    "    batch_cnt = 0\n",
    "\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch, (x, lengths, y) in enumerate(train_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        loss = criterion(logits, y)\n",
    "        loss_score = loss.cpu().item()\n",
    "\n",
    "        loss_accum += loss_score\n",
    "        batch_cnt += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "                    \n",
    "\n",
    "    print(\"train acc: \", acc_cnt/(err_cnt+acc_cnt), \" train loss: \", loss_accum / batch_cnt, '--time:', time.time() - start_time)\n",
    "\n",
    "    model.eval()\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "\n",
    "    #start_time = time.time()\n",
    "    for x, lengths, y in valid_loader:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        logits = model(x, lengths)\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "\n",
    "    current_acc = acc_cnt/(err_cnt+acc_cnt)\n",
    "    if current_acc > max_acc:\n",
    "        max_acc = current_acc\n",
    "                \n",
    "    print(j, \"validation: \", current_acc, '--max', max_acc, '--time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 layer, 512, only 2 CNN contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
